{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishaanpaul98/Sentiment-Analysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "pGQVQfr0b3SS"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen, Request\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "import time\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "WSgZEvuikgTn"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "9hbdUWDKkgv_"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "Eqvj106lkgyU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stock Data Helper Functions #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting stock data for stock $AAPL\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-21</th>\n",
              "      <td>132.979996</td>\n",
              "      <td>136.809998</td>\n",
              "      <td>132.750000</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>85928000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-22</th>\n",
              "      <td>134.350006</td>\n",
              "      <td>134.559998</td>\n",
              "      <td>130.300003</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>77852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-23</th>\n",
              "      <td>130.919998</td>\n",
              "      <td>132.419998</td>\n",
              "      <td>129.639999</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>63814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>131.380005</td>\n",
              "      <td>131.410004</td>\n",
              "      <td>128.720001</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>69007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>129.669998</td>\n",
              "      <td>131.029999</td>\n",
              "      <td>125.870003</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>85438400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>127.989998</td>\n",
              "      <td>130.479996</td>\n",
              "      <td>127.730003</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>75703700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>128.410004</td>\n",
              "      <td>129.949997</td>\n",
              "      <td>127.430000</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>76960600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>130.279999</td>\n",
              "      <td>130.899994</td>\n",
              "      <td>124.169998</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>112117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>126.889999</td>\n",
              "      <td>128.660004</td>\n",
              "      <td>125.080002</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>89113600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>127.129997</td>\n",
              "      <td>127.769997</td>\n",
              "      <td>124.760002</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>80962700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>126.010002</td>\n",
              "      <td>130.289993</td>\n",
              "      <td>124.889999</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>87686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>130.470001</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>129.889999</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>70790800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-10</th>\n",
              "      <td>130.259995</td>\n",
              "      <td>131.259995</td>\n",
              "      <td>128.119995</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>63896200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-11</th>\n",
              "      <td>131.250000</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>130.460007</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>69458900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-12</th>\n",
              "      <td>133.880005</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>71379600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-13</th>\n",
              "      <td>132.029999</td>\n",
              "      <td>134.919998</td>\n",
              "      <td>131.660004</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>57758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17</th>\n",
              "      <td>134.830002</td>\n",
              "      <td>137.289993</td>\n",
              "      <td>134.130005</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>63646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-18</th>\n",
              "      <td>136.815002</td>\n",
              "      <td>138.610001</td>\n",
              "      <td>135.029999</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>69459809</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High         Low       Close   Adj Close  \\\n",
              "Date                                                                     \n",
              "2022-12-21  132.979996  136.809998  132.750000  135.449997  135.449997   \n",
              "2022-12-22  134.350006  134.559998  130.300003  132.229996  132.229996   \n",
              "2022-12-23  130.919998  132.419998  129.639999  131.860001  131.860001   \n",
              "2022-12-27  131.380005  131.410004  128.720001  130.029999  130.029999   \n",
              "2022-12-28  129.669998  131.029999  125.870003  126.040001  126.040001   \n",
              "2022-12-29  127.989998  130.479996  127.730003  129.610001  129.610001   \n",
              "2022-12-30  128.410004  129.949997  127.430000  129.929993  129.929993   \n",
              "2023-01-03  130.279999  130.899994  124.169998  125.070000  125.070000   \n",
              "2023-01-04  126.889999  128.660004  125.080002  126.360001  126.360001   \n",
              "2023-01-05  127.129997  127.769997  124.760002  125.019997  125.019997   \n",
              "2023-01-06  126.010002  130.289993  124.889999  129.619995  129.619995   \n",
              "2023-01-09  130.470001  133.410004  129.889999  130.149994  130.149994   \n",
              "2023-01-10  130.259995  131.259995  128.119995  130.729996  130.729996   \n",
              "2023-01-11  131.250000  133.509995  130.460007  133.490005  133.490005   \n",
              "2023-01-12  133.880005  134.259995  131.440002  133.410004  133.410004   \n",
              "2023-01-13  132.029999  134.919998  131.660004  134.759995  134.759995   \n",
              "2023-01-17  134.830002  137.289993  134.130005  135.940002  135.940002   \n",
              "2023-01-18  136.815002  138.610001  135.029999  135.210007  135.210007   \n",
              "\n",
              "               Volume  \n",
              "Date                   \n",
              "2022-12-21   85928000  \n",
              "2022-12-22   77852100  \n",
              "2022-12-23   63814900  \n",
              "2022-12-27   69007800  \n",
              "2022-12-28   85438400  \n",
              "2022-12-29   75703700  \n",
              "2022-12-30   76960600  \n",
              "2023-01-03  112117500  \n",
              "2023-01-04   89113600  \n",
              "2023-01-05   80962700  \n",
              "2023-01-06   87686600  \n",
              "2023-01-09   70790800  \n",
              "2023-01-10   63896200  \n",
              "2023-01-11   69458900  \n",
              "2023-01-12   71379600  \n",
              "2023-01-13   57758000  \n",
              "2023-01-17   63646600  \n",
              "2023-01-18   69459809  "
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getStockDataDaily(symbol, day):\n",
        "    print(\"Getting stock data for stock $\"+symbol)\n",
        "    df = yf.download(symbol, start=day, period = \"1d\")\n",
        "    return df\n",
        "\n",
        "getStockDataDaily('AAPL', \"2022-12-21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [],
      "source": [
        "def arrayToString(arr):\n",
        "    print(\"Starting array to list\")\n",
        "    listToStr = ' '.join([str(elem) for elem in arr])\n",
        "    return listToStr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of symbols array is more than 1. STARTING ARRAYTOSTRING\n",
            "Starting array to list\n",
            "Getting stock data for stock $AAPL TSLA\n",
            "[*********************100%***********************]  2 of 2 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">TSLA</th>\n",
              "      <th colspan=\"6\" halign=\"left\">AAPL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-21</th>\n",
              "      <td>139.339996</td>\n",
              "      <td>141.259995</td>\n",
              "      <td>135.889999</td>\n",
              "      <td>137.570007</td>\n",
              "      <td>137.570007</td>\n",
              "      <td>145417400</td>\n",
              "      <td>132.979996</td>\n",
              "      <td>136.809998</td>\n",
              "      <td>132.750000</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>85928000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-22</th>\n",
              "      <td>136.000000</td>\n",
              "      <td>136.630005</td>\n",
              "      <td>122.260002</td>\n",
              "      <td>125.349998</td>\n",
              "      <td>125.349998</td>\n",
              "      <td>210090300</td>\n",
              "      <td>134.350006</td>\n",
              "      <td>134.559998</td>\n",
              "      <td>130.300003</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>77852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-23</th>\n",
              "      <td>126.370003</td>\n",
              "      <td>128.619995</td>\n",
              "      <td>121.019997</td>\n",
              "      <td>123.150002</td>\n",
              "      <td>123.150002</td>\n",
              "      <td>166989700</td>\n",
              "      <td>130.919998</td>\n",
              "      <td>132.419998</td>\n",
              "      <td>129.639999</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>63814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>117.500000</td>\n",
              "      <td>119.669998</td>\n",
              "      <td>108.760002</td>\n",
              "      <td>109.099998</td>\n",
              "      <td>109.099998</td>\n",
              "      <td>208643400</td>\n",
              "      <td>131.380005</td>\n",
              "      <td>131.410004</td>\n",
              "      <td>128.720001</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>69007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>110.349998</td>\n",
              "      <td>116.269997</td>\n",
              "      <td>108.239998</td>\n",
              "      <td>112.709999</td>\n",
              "      <td>112.709999</td>\n",
              "      <td>221070500</td>\n",
              "      <td>129.669998</td>\n",
              "      <td>131.029999</td>\n",
              "      <td>125.870003</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>85438400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>120.389999</td>\n",
              "      <td>123.570000</td>\n",
              "      <td>117.500000</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>221923300</td>\n",
              "      <td>127.989998</td>\n",
              "      <td>130.479996</td>\n",
              "      <td>127.730003</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>75703700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>119.949997</td>\n",
              "      <td>124.480003</td>\n",
              "      <td>119.750000</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>157304500</td>\n",
              "      <td>128.410004</td>\n",
              "      <td>129.949997</td>\n",
              "      <td>127.430000</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>76960600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>118.470001</td>\n",
              "      <td>118.800003</td>\n",
              "      <td>104.639999</td>\n",
              "      <td>108.099998</td>\n",
              "      <td>108.099998</td>\n",
              "      <td>231402800</td>\n",
              "      <td>130.279999</td>\n",
              "      <td>130.899994</td>\n",
              "      <td>124.169998</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>112117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>109.110001</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>113.639999</td>\n",
              "      <td>113.639999</td>\n",
              "      <td>180389000</td>\n",
              "      <td>126.889999</td>\n",
              "      <td>128.660004</td>\n",
              "      <td>125.080002</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>89113600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>110.510002</td>\n",
              "      <td>111.750000</td>\n",
              "      <td>107.160004</td>\n",
              "      <td>110.339996</td>\n",
              "      <td>110.339996</td>\n",
              "      <td>157986300</td>\n",
              "      <td>127.129997</td>\n",
              "      <td>127.769997</td>\n",
              "      <td>124.760002</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>80962700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>103.000000</td>\n",
              "      <td>114.389999</td>\n",
              "      <td>101.809998</td>\n",
              "      <td>113.059998</td>\n",
              "      <td>113.059998</td>\n",
              "      <td>220575900</td>\n",
              "      <td>126.010002</td>\n",
              "      <td>130.289993</td>\n",
              "      <td>124.889999</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>87686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>118.959999</td>\n",
              "      <td>123.519997</td>\n",
              "      <td>117.110001</td>\n",
              "      <td>119.769997</td>\n",
              "      <td>119.769997</td>\n",
              "      <td>190284000</td>\n",
              "      <td>130.470001</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>129.889999</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>70790800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-10</th>\n",
              "      <td>121.070000</td>\n",
              "      <td>122.760002</td>\n",
              "      <td>114.919998</td>\n",
              "      <td>118.849998</td>\n",
              "      <td>118.849998</td>\n",
              "      <td>167642500</td>\n",
              "      <td>130.259995</td>\n",
              "      <td>131.259995</td>\n",
              "      <td>128.119995</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>63896200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-11</th>\n",
              "      <td>122.089996</td>\n",
              "      <td>125.949997</td>\n",
              "      <td>120.510002</td>\n",
              "      <td>123.220001</td>\n",
              "      <td>123.220001</td>\n",
              "      <td>183810800</td>\n",
              "      <td>131.250000</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>130.460007</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>69458900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-12</th>\n",
              "      <td>122.559998</td>\n",
              "      <td>124.129997</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>123.559998</td>\n",
              "      <td>123.559998</td>\n",
              "      <td>169400900</td>\n",
              "      <td>133.880005</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>71379600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-13</th>\n",
              "      <td>116.550003</td>\n",
              "      <td>122.629997</td>\n",
              "      <td>115.599998</td>\n",
              "      <td>122.400002</td>\n",
              "      <td>122.400002</td>\n",
              "      <td>180439300</td>\n",
              "      <td>132.029999</td>\n",
              "      <td>134.919998</td>\n",
              "      <td>131.660004</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>57758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17</th>\n",
              "      <td>125.699997</td>\n",
              "      <td>131.699997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>131.490005</td>\n",
              "      <td>131.490005</td>\n",
              "      <td>186477000</td>\n",
              "      <td>134.830002</td>\n",
              "      <td>137.289993</td>\n",
              "      <td>134.130005</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>63646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-18</th>\n",
              "      <td>136.554993</td>\n",
              "      <td>136.679993</td>\n",
              "      <td>127.010002</td>\n",
              "      <td>128.779999</td>\n",
              "      <td>128.779999</td>\n",
              "      <td>193774108</td>\n",
              "      <td>136.815002</td>\n",
              "      <td>138.610001</td>\n",
              "      <td>135.029999</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>69459809</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  TSLA                                                  \\\n",
              "                  Open        High         Low       Close   Adj Close   \n",
              "Date                                                                     \n",
              "2022-12-21  139.339996  141.259995  135.889999  137.570007  137.570007   \n",
              "2022-12-22  136.000000  136.630005  122.260002  125.349998  125.349998   \n",
              "2022-12-23  126.370003  128.619995  121.019997  123.150002  123.150002   \n",
              "2022-12-27  117.500000  119.669998  108.760002  109.099998  109.099998   \n",
              "2022-12-28  110.349998  116.269997  108.239998  112.709999  112.709999   \n",
              "2022-12-29  120.389999  123.570000  117.500000  121.820000  121.820000   \n",
              "2022-12-30  119.949997  124.480003  119.750000  123.180000  123.180000   \n",
              "2023-01-03  118.470001  118.800003  104.639999  108.099998  108.099998   \n",
              "2023-01-04  109.110001  114.589996  107.519997  113.639999  113.639999   \n",
              "2023-01-05  110.510002  111.750000  107.160004  110.339996  110.339996   \n",
              "2023-01-06  103.000000  114.389999  101.809998  113.059998  113.059998   \n",
              "2023-01-09  118.959999  123.519997  117.110001  119.769997  119.769997   \n",
              "2023-01-10  121.070000  122.760002  114.919998  118.849998  118.849998   \n",
              "2023-01-11  122.089996  125.949997  120.510002  123.220001  123.220001   \n",
              "2023-01-12  122.559998  124.129997  117.000000  123.559998  123.559998   \n",
              "2023-01-13  116.550003  122.629997  115.599998  122.400002  122.400002   \n",
              "2023-01-17  125.699997  131.699997  125.019997  131.490005  131.490005   \n",
              "2023-01-18  136.554993  136.679993  127.010002  128.779999  128.779999   \n",
              "\n",
              "                             AAPL                                      \\\n",
              "               Volume        Open        High         Low       Close   \n",
              "Date                                                                    \n",
              "2022-12-21  145417400  132.979996  136.809998  132.750000  135.449997   \n",
              "2022-12-22  210090300  134.350006  134.559998  130.300003  132.229996   \n",
              "2022-12-23  166989700  130.919998  132.419998  129.639999  131.860001   \n",
              "2022-12-27  208643400  131.380005  131.410004  128.720001  130.029999   \n",
              "2022-12-28  221070500  129.669998  131.029999  125.870003  126.040001   \n",
              "2022-12-29  221923300  127.989998  130.479996  127.730003  129.610001   \n",
              "2022-12-30  157304500  128.410004  129.949997  127.430000  129.929993   \n",
              "2023-01-03  231402800  130.279999  130.899994  124.169998  125.070000   \n",
              "2023-01-04  180389000  126.889999  128.660004  125.080002  126.360001   \n",
              "2023-01-05  157986300  127.129997  127.769997  124.760002  125.019997   \n",
              "2023-01-06  220575900  126.010002  130.289993  124.889999  129.619995   \n",
              "2023-01-09  190284000  130.470001  133.410004  129.889999  130.149994   \n",
              "2023-01-10  167642500  130.259995  131.259995  128.119995  130.729996   \n",
              "2023-01-11  183810800  131.250000  133.509995  130.460007  133.490005   \n",
              "2023-01-12  169400900  133.880005  134.259995  131.440002  133.410004   \n",
              "2023-01-13  180439300  132.029999  134.919998  131.660004  134.759995   \n",
              "2023-01-17  186477000  134.830002  137.289993  134.130005  135.940002   \n",
              "2023-01-18  193774108  136.815002  138.610001  135.029999  135.210007   \n",
              "\n",
              "                                   \n",
              "             Adj Close     Volume  \n",
              "Date                               \n",
              "2022-12-21  135.449997   85928000  \n",
              "2022-12-22  132.229996   77852100  \n",
              "2022-12-23  131.860001   63814900  \n",
              "2022-12-27  130.029999   69007800  \n",
              "2022-12-28  126.040001   85438400  \n",
              "2022-12-29  129.610001   75703700  \n",
              "2022-12-30  129.929993   76960600  \n",
              "2023-01-03  125.070000  112117500  \n",
              "2023-01-04  126.360001   89113600  \n",
              "2023-01-05  125.019997   80962700  \n",
              "2023-01-06  129.619995   87686600  \n",
              "2023-01-09  130.149994   70790800  \n",
              "2023-01-10  130.729996   63896200  \n",
              "2023-01-11  133.490005   69458900  \n",
              "2023-01-12  133.410004   71379600  \n",
              "2023-01-13  134.759995   57758000  \n",
              "2023-01-17  135.940002   63646600  \n",
              "2023-01-18  135.210007   69459809  "
            ]
          },
          "execution_count": 231,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getMultiStockDataDaily(symbols, day):\n",
        "    if len(symbols) > 1:\n",
        "        print(\"Length of symbols array is more than 1. STARTING ARRAYTOSTRING\")\n",
        "        symbols = arrayToString(symbols)\n",
        "    print(\"Getting stock data for stock $\"+symbols)\n",
        "    df = yf.download(symbols, start=day, period = \"1d\", group_by='ticker')\n",
        "    return df\n",
        "\n",
        "getMultiStockDataDaily(['AAPL', 'TSLA'], \"2022-12-21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting stock close for stock $AAPL\n",
            "AAPL 135.2100067138672\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "135.2100067138672"
            ]
          },
          "execution_count": 232,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getStockClose(symbol):\n",
        "    print(\"Getting stock close for stock $\"+symbol)\n",
        "    ticker = yf.Ticker(symbol)\n",
        "    data = ticker.history()\n",
        "    #print(data)\n",
        "    last_price = data['Close'].iloc[-1]\n",
        "    print(symbol, last_price)\n",
        "    return last_price\n",
        "\n",
        "getStockClose(\"AAPL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting stock open for stock $AAPL\n",
            "AAPL 136.81500244140625\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "136.81500244140625"
            ]
          },
          "execution_count": 233,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getStockOpen(symbol):\n",
        "    print(\"Getting stock open for stock $\"+symbol)\n",
        "    ticker = yf.Ticker(symbol)\n",
        "    data = ticker.history()\n",
        "    #print(data)\n",
        "    last_price = data['Open'].iloc[-1]\n",
        "    print(symbol, last_price)\n",
        "    return last_price\n",
        "\n",
        "getStockOpen(\"AAPL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting stock high for stock $AAPL\n",
            "AAPL 138.61000061035156\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "138.61000061035156"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getStockHigh(symbol):\n",
        "    print(\"Getting stock high for stock $\"+symbol)\n",
        "    ticker = yf.Ticker(symbol)\n",
        "    data = ticker.history()\n",
        "    #print(data)\n",
        "    last_price = data['High'].iloc[-1]\n",
        "    print(symbol, last_price)\n",
        "    return last_price\n",
        "\n",
        "getStockHigh(\"AAPL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting stock low for stock $AAPL\n",
            "AAPL 135.02999877929688\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "135.02999877929688"
            ]
          },
          "execution_count": 235,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getStockLow(symbol):\n",
        "    print(\"Getting stock low for stock $\"+symbol)\n",
        "    ticker = yf.Ticker(symbol)\n",
        "    data = ticker.history()\n",
        "    #print(data)\n",
        "    last_price = data['Low'].iloc[-1]\n",
        "    print(symbol, last_price)\n",
        "    return last_price\n",
        "\n",
        "getStockLow(\"AAPL\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathering FinViz Data (Today's News) #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters \n",
        "n = 3 #the # of article headlines displayed per ticker\n",
        "tickers = ['AAPL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'news':        Date                                              Title  \\\n",
              " 0   07:14PM        Stocks Fall After Retail and Inflation Data   \n",
              " 1   07:07PM  Asian Stocks to Drop on Deepening Growth Conce...   \n",
              " 2   07:05PM  HMRC trials answer by text system to cut call ...   \n",
              " 3   07:04PM  Why inflation is falling but prices are still ...   \n",
              " 4   06:43PM  Filing reveals eye-popping amount former Disne...   \n",
              " ..      ...                                                ...   \n",
              " 85  08:15AM  Irish House Price Growth Slows Adding to Signs...   \n",
              " 86  08:02AM  Stocks making the biggest moves premarket: Uni...   \n",
              " 87  08:00AM  Foreign Investors Pulled $91 Billion From Chin...   \n",
              " 88  07:58AM          Trump slams evangelical Christian leaders   \n",
              " 89  07:41AM  Taylor Swift Gave Universal Music a $230 Milli...   \n",
              " \n",
              "                Source                                               Link  \n",
              " 0         www.wsj.com  https://www.wsj.com/articles/global-stocks-mar...  \n",
              " 1   www.bloomberg.com  https://www.bloomberg.com/news/articles/2023-0...  \n",
              " 2       www.bbc.co.uk  https://www.bbc.co.uk/news/business-64322140?a...  \n",
              " 3       www.bbc.co.uk  https://www.bbc.co.uk/news/business-64290160?a...  \n",
              " 4     foxbusiness.com  https://foxbusiness.com/markets/filing-reveals...  \n",
              " ..                ...                                                ...  \n",
              " 85  www.bloomberg.com  https://www.bloomberg.com/news/articles/2023-0...  \n",
              " 86       www.cnbc.com  https://www.cnbc.com/2023/01/18/stocks-making-...  \n",
              " 87        www.wsj.com  https://www.wsj.com/articles/foreign-investors...  \n",
              " 88        www.cnn.com  https://www.cnn.com/videos/politics/2023/01/18...  \n",
              " 89  www.bloomberg.com  https://www.bloomberg.com/news/articles/2023-0...  \n",
              " \n",
              " [90 rows x 4 columns],\n",
              " 'blogs':        Date                                              Title  \\\n",
              " 0   06:55PM  Reps. Marjorie Taylor Greene, Paul Gosar Back ...   \n",
              " 1   06:35PM  Tesla Video Depicting Self-Driving Car Was Sta...   \n",
              " 2   06:15PM  Texas Brewery Cancels Kyle Rittenhouse Fundrai...   \n",
              " 3   05:55PM  Buyer Cancellation Rate At Top US Homebuilder ...   \n",
              " 4   05:35PM  Illinois' Newest Suicide Attempt: Wealth-Tax L...   \n",
              " ..      ...                                                ...   \n",
              " 85   Dec-06   The Three Essential Sources of Your Trading Edge   \n",
              " 86   Nov-24                                Trading Consciously   \n",
              " 87   Nov-18  Relapse Prevention:  A Neglected Topic In Trad...   \n",
              " 88   Nov-13            Strong Two Day Rally:  What Comes Next?   \n",
              " 89   May-21  New Issue Now Available: What Hedge Funds Boug...   \n",
              " \n",
              "                      Source                                               Link  \n",
              " 0         www.zerohedge.com  https://www.zerohedge.com/political/reps-marjo...  \n",
              " 1         www.zerohedge.com  https://www.zerohedge.com/technology/tesla-vid...  \n",
              " 2         www.zerohedge.com  https://www.zerohedge.com/political/texas-brew...  \n",
              " 3         www.zerohedge.com  https://www.zerohedge.com/markets/buyer-cancel...  \n",
              " 4         www.zerohedge.com  https://www.zerohedge.com/personal-finance/ill...  \n",
              " ..                      ...                                                ...  \n",
              " 85  traderfeed.blogspot.com  http://traderfeed.blogspot.com/2022/12/the-thr...  \n",
              " 86  traderfeed.blogspot.com  http://traderfeed.blogspot.com/2022/11/trading...  \n",
              " 87  traderfeed.blogspot.com  http://traderfeed.blogspot.com/2022/11/relapse...  \n",
              " 88  traderfeed.blogspot.com  http://traderfeed.blogspot.com/2022/11/strong-...  \n",
              " 89      www.marketfolly.com  http://www.marketfolly.com/2022/05/new-issue-n...  \n",
              " \n",
              " [90 rows x 4 columns]}"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from finvizfinance.news import News\n",
        "fnews = News()\n",
        "all_news = fnews.get_news()\n",
        "all_news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current url is: https://finviz.com/quote.ashx?t=AAPL\n",
            "\n",
            "\n",
            "Recent News Headlines for AAPL: \n",
            "Dow Jones Reverses Lower On Fed, Recession Fears; Tesla, Megacaps Hit Resistance ( Jan-18-23 07:28PM )\n",
            "Stocks trending in after hours: Alcoa, Discover Financial, Vroom, Apple ( 05:04PM )\n",
            "Apple delays development of AR glasses indefinitely: report ( 05:02PM )\n"
          ]
        }
      ],
      "source": [
        "# Get Data\n",
        "finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
        "news_tables = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    url = finwiz_url + ticker\n",
        "    print(\"current url is: \" +url)\n",
        "    header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36.\"}\n",
        "    req = Request(url=url,headers=header) \n",
        "    resp = urlopen(req)    \n",
        "    html = BeautifulSoup(resp, features=\"lxml\")\n",
        "    news_table = html.find(id='news-table')\n",
        "    news_tables[ticker] = news_table\n",
        "\n",
        "try:\n",
        "    for ticker in tickers:\n",
        "        df = news_tables[ticker]\n",
        "        df_tr = df.findAll('tr')\n",
        "    \n",
        "        print ('\\n')\n",
        "        print ('Recent News Headlines for {}: '.format(ticker))\n",
        "        \n",
        "        for i, table_row in enumerate(df_tr):\n",
        "            a_text = table_row.a.text\n",
        "            td_text = table_row.td.text\n",
        "            td_text = td_text.strip()\n",
        "            print(a_text,'(',td_text,')')\n",
        "            if i == n-1:\n",
        "                break\n",
        "except KeyError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jan-18-23 07:28PMDow Jones Reverses Lower On Fed, Recession Fears; Tesla, Megacaps Hit Resistance Investor's Business Daily\n",
            "05:04PMStocks trending in after hours: Alcoa, Discover Financial, Vroom, Apple Yahoo Finance Video\n",
            "05:02PMApple delays development of AR glasses indefinitely: report Fox Business\n",
            "04:32PMApple to Expand Smart-Home Lineup, Taking On Amazon and Google Bloomberg\n",
            "04:19PMBrazil antitrust agency to investigate MercadoLibre complaint against Apple Reuters\n",
            "\n",
            "02:35PM\n",
            "Loading…\n",
            "\n",
            "02:35PMBig Tech braces for dismal profits, more job cuts Reuters\n",
            "02:30PMApple wants to control everything from its chips to screens Yahoo Finance\n",
            "02:20PMApple doing audit related to its human rights policy and labor practices this year Fox Business\n",
            "02:11PMApple Could Boost Profits by Designing Its Own iPhone Parts, Analyst Says Barrons.com\n",
            "02:10PMSpotify launches new attack on Apple for abusive behaviors MarketWatch\n",
            "01:08PMApple Resurrects the Full-Size HomePod With a $299 Price Tag The Wall Street Journal\n",
            "12:45PMGoogle Reportedly Working on Apple AirTag Alternative As Personal Tracker Market Sees Growth and Consolidation Benzinga\n",
            "12:30PMWhy Apples Mac Pricing Is Bad For Customersand Bad for Business Barrons.com\n",
            "11:20AMApple Brings Back the HomePod Smart Speaker Barrons.com\n",
            "10:46AMApple Delays AR Glasses, Plans Cheaper Mixed-Reality Headset Bloomberg\n",
            "\n",
            "10:42AM\n",
            "Loading…\n",
            "\n",
            "10:42AMWhat Apple's move to in-house M2 chips means for the stock Yahoo Finance Video\n",
            "10:42AMSpotify Teams Up With European Companies For Regulatory Action Against Apple Benzinga\n",
            "10:11AMU.S. corporate greed has gone too far, says Norway fund manager who voted against Apple CEOs pay MarketWatch\n",
            "10:00AMBetter Buy in 2023: Apple Stock vs. Amazon Stock Motley Fool\n",
            "09:50AM10 Best Vanguard ETFs for Portfolio Diversification Insider Monkey\n",
            "09:45AMDown 22% to 30%, 3 Warren Buffett Dividend Stocks to Buy Right Now Motley Fool\n",
            "09:23AMApple Is Taking on Meta in Virtual Reality. Its Not Going to Be Easy. Barrons.com\n",
            "09:01AMSpotify joins media firms to urge EU action against Apple's 'unfair' practices Reuters\n",
            "09:00AMApple introduces the new HomePod with breakthrough sound and intelligence Business Wire\n",
            "08:54AMSpotify joins media firms to urge EU action against Apple's 'unfair' practices Reuters\n",
            "08:27AMApple Wants to Play in the Metaverse. Dont Expect It to Be Easy. Barrons.com\n",
            "08:15AM2 Top Stocks to Buy in 2023 and Hold Forever Motley Fool\n",
            "06:39AM3 Reasons to Buy The Trade Desk Stock, and 1 Reason to Sell Motley Fool\n",
            "06:31AM3 Stocks to Buy if They Take a Dip Motley Fool\n",
            "06:30AMApple CEO Tim Cook asked for  and got  a major pay cut this year. Is there ever a time when some of us should accept one too? The answer is yes. MarketWatch\n",
            "\n",
            "06:00AM\n",
            "Loading…\n",
            "\n",
            "06:00AMApple (NASDAQ:AAPL) Could Easily Take On More Debt Simply Wall St.\n",
            "05:15AMIn a Stunning Move, Apple Plans to Ditch Highly Valued Wireless Component Suppliers Motley Fool\n",
            "05:10AM3 Rock-Solid Dividend Stocks to Buy in 2023 Motley Fool\n",
            "04:43AMApple's Chinese Suppliers Win Expansion Permits In India As iPhone-Maker Attempts To Reduce Dependence On China Benzinga\n",
            "01:12AMApple/chips: homemade chips does not mean homemade fabs Financial Times\n",
            "12:00AMWhat it would take for Apple to disentangle itself from China Financial Times\n",
            "Jan-17-23 11:28PMApple Gets a Boost in India as Chinese Suppliers Given Clearance Bloomberg\n",
            "10:47PMApple indefinitely postpones launch of AR glasses - Bloomberg News Reuters\n",
            "10:44PMApple indefinitely postpones launch of AR glasses - Bloomberg News Reuters\n",
            "10:06PMApple will delay AR glasses, focus instead on cheaper mixed-reality headset: report MarketWatch\n",
            "06:16PMApple Introduces Faster MacBook Pros and Mac Minis Bloomberg\n",
            "05:45PMApple (AAPL) Gains As Market Dips: What You Should Know Zacks\n",
            "04:57PMThe ongoing big tech antitrust cases to watch in 2023 Quartz\n",
            "04:39PMSupreme Court Asks U.S. Government to Weigh In on Apple Patent Dispute The Wall Street Journal\n",
            "04:02PMChina sees record population declines amid GDP growth Yahoo Finance Video\n",
            "03:42PMApple unveils M2 chips in new Mac Mini, MacBook Pro Yahoo Finance Video\n",
            "02:41PMApple Rolls Out Latest MacBook Pro With New M2 Chips The Wall Street Journal\n",
            "02:07PMThree big questions facing tech stocks this earnings season Yahoo Finance\n",
            "12:48PMU.S. Supreme Court asks for gov't views on blockbuster Apple/Caltech patent dispute Reuters\n",
            "12:03PMApple AirTags and Bluetooth Trackers Are Officially a Billion-Dollar Industry  Here's What To Know, Trends, and the Best Ways To Invest Benzinga\n",
            "10:52AMApple debuts MacBook Pro and Mac Mini with new high-powered M2 Pro and M2 Max chips Yahoo Finance\n",
            "10:43AMTikTok: Here's how Washington could take it on (even without banning the app) Yahoo Finance\n",
            "10:36AMApple Launches New MacBooks and Minis, Updates M2 Processors Barrons.com\n",
            "10:12AMApple unveils latest M2 chips for MacBook Pro and more Yahoo Finance Video\n",
            "10:10AMWill Warren Buffett Own a Virtual Reality Stock in 2023? Motley Fool\n",
            "10:04AMApple launches faster MacBook Pro laptops with new custom chips MarketWatch\n",
            "09:45AMMetas 54% Stock Comeback Is Still on Shaky Ground Bloomberg\n",
            "09:23AMUPDATE 2-Apple launches faster M2 chips, powerful laptops in rare January launch Reuters\n",
            "09:18AMApple unveils new macbooks, Mac mini in rare January launch Reuters\n",
            "09:00AMApple unveils MacBook Pro featuring M2 Pro and M2 Max, with more game-changing performance and the longest battery life ever in a Mac Business Wire\n",
            "09:00AMApple unveils M2 Pro and M2 Max: next-generation chips for next-level workflows Business Wire\n",
            "09:00AMApple introduces new Mac mini with M2 and M2 Pro  more powerful, capable, and versatile than ever Business Wire\n",
            "08:19AMMicrosoft Just Acquired a Chip Design Start-Up. Here's What Semiconductor Investors Need to Know. Motley Fool\n",
            "05:21AMWarren Buffett Is Raking in $4.84 Billion in Annual Dividend Income From These 6 Stocks Motley Fool\n",
            "12:51AMUPDATE 1-Apple supplier Foxconn replaces iPhone business chief- Bloomberg News Reuters\n",
            "12:00AMHow Apple tied its fortunes to China Financial Times\n",
            "Jan-16-23 11:35PMApple supplier Foxconn replaces iPhone business chief- Bloomberg News Reuters\n",
            "11:07PMFoxconn Replaces iPhone Business Chief After Tumultuous Year Bloomberg\n",
            "08:33PMUPDATE 1-Investor Ryan Cohen builds Alibaba stake, pushes for more share buybacks Reuters\n",
            "01:27PM2 FAANG Stocks to Buy in 2023 and 1 to Avoid: Here's Why Motley Fool\n",
            "11:51AMThe Regulatory Threat to Tech Is Growing. What It Means for Stocks. Barrons.com\n",
            "11:05AMQualcomm: A Rare Technology Value Play TheStreet.com\n",
            "11:00AMBetter Growth Stock in 2023: Apple vs. AMD Motley Fool\n",
            "10:37AM2 Top Tech Stocks to Buy for the Long Haul Motley Fool\n",
            "10:30AMTarget, Amazon and 4 More Retailers That Will Reward You for Turning in Your Old Stuff GOBankingRates\n",
            "09:53AM3 Tech Stocks Approved by Warren Buffett Motley Fool\n",
            "09:34AMIs TSMC Stock a Buy Now? Motley Fool\n",
            "08:33AMThe Zacks Analyst Blog Highlights Lenovo Group, HP, Dell Technologies and Apple Zacks\n",
            "07:10AMHistory Says the Nasdaq Could Soar in 2023 -- 5 Stocks You'll Wish You'd Bought if It Does Motley Fool\n",
            "Jan-15-23 04:25PMBusiness class: Apple hires workers in India as it looks to open first flagship stores Financial Times\n",
            "10:07AMBetter Buy: Costco Vs. Target Stock Motley Fool\n",
            "08:24AMTake Warren Buffett's Advice: Buy Stocks With These 3 Attributes Motley Fool\n",
            "08:20AM2 Cheap Tech Stocks to Buy Right Now Motley Fool\n",
            "06:18AMKey Apple Partners Plan Expansion in Southeast Asia in 2023 Bloomberg\n",
            "05:30AMBig Tech Companies Prep for a Tough Year The Wall Street Journal\n",
            "Jan-14-23 01:31PMApple CEO Tim Cook's Pay Cut in Half TheStreet.com\n",
            "11:48AM\"Rule Breaker Investing\": Old, New, Borrowed, and Blue Motley Fool\n",
            "09:44AMBig Tech CEOs Give Investors Something to Think About Motley Fool\n",
            "09:15AMHere Are 2 Technology Stocks of the Future You Can Buy Right Now Motley Fool\n",
            "09:00AM281 Billion Reasons Why You May Regret Not Buying Apple Stock Motley Fool\n",
            "07:50AM3 Top Stocks to Buy for the Long Haul Motley Fool\n",
            "07:20AMIs It Time to Buy the Dow Jones' 3 Worst-Performing December Stocks? Motley Fool\n",
            "07:01AMGreat week for Apple Inc. (NASDAQ:AAPL) institutional investors after losing 22% over the previous year Simply Wall St.\n",
            "04:30AMTech war: Apple looks to India, Vietnam as iPhone maker's supply chain comes under the spotlight in US-China decoupling South China Morning Post\n",
            "Jan-13-23 06:23PMWeekly Roundup TheStreet.com\n",
            "05:19PMContract manufactuer Jabil  whose biggest customer is Apple  is cutting more than 200 workers in the Bay Area American City Business Journals\n",
            "05:00PMQualcomm Continues to Hover Near Its 52-Week Low. Is Now the Time to Buy? Motley Fool\n",
            "04:39PMDon't Ignore These Companies' Cash-Generating Abilities Zacks\n",
            "04:30PMApple CEO Tim Cook agrees to 40% pay cut, stores begin contract negotiations amid union push Yahoo Finance Video\n",
            "03:28PMApple will examine commitment to workers rights after shareholder push MarketWatch\n"
          ]
        }
      ],
      "source": [
        "# Iterate through the news\n",
        "parsed_news = []\n",
        "for file_name, news_table in news_tables.items():\n",
        "    for x in news_table.findAll('tr'):\n",
        "        print(x.get_text())\n",
        "        text = x.get_text() \n",
        "        date_scrape = x.td.text.split()\n",
        "\n",
        "        if len(date_scrape) == 1:\n",
        "            time = date_scrape[0]\n",
        "            \n",
        "        else:\n",
        "            date = date_scrape[0]\n",
        "            time = date_scrape[1]\n",
        "\n",
        "        ticker = file_name.split('_')[0]\n",
        "        \n",
        "        parsed_news.append([ticker, date, time, text ])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathering Data From AlphaAdvantage for Historical News #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [],
      "source": [
        "from decouple import config\n",
        "import requests\n",
        "import urllib.parse\n",
        "import json\n",
        "AAapikey = config('AAKey')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to convert user provided date to date required by AlphaAdvantage\n",
        "def toAADate(oldDate):\n",
        "    newDate = str(oldDate) + 'T0001'\n",
        "    return newDate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Date                                           Headline Ticker\n",
            "0   20230118   Apple HomePod Second-Gen: First Listen, Hands-On   AAPL\n",
            "1   20230118            Why Qualcomm Stock Defied Gravity Today   AAPL\n",
            "2   20230118  Dow Reverses Lower On Hawkish Fed, Weak Econom...   AAPL\n",
            "3   20230118  Alphabet  ( GOOGL )  to Expand Portfolio With ...   AAPL\n",
            "4   20230118  Apple Could Boost Profits by Designing Its Own...   AAPL\n",
            "5   20230118  Dow Jones Falls Despite Cooling Inflation Sign...   AAPL\n",
            "6   20230118  Microsoft Is Laying Off Thousands. Here's What...   AAPL\n",
            "7   20230118  Sharply Lower PPI, Retail Sales Data Further S...   AAPL\n",
            "8   20230118  Google Reportedly Working on Apple AirTag Alte...   AAPL\n",
            "9   20230118                Here Come the FAANG Earnings Charts   AAPL\n",
            "10  20230118  Apple HomePod  ( 2nd Gen ) : Pricing, Features...   AAPL\n",
            "11  20230118  Roblox's  ( RBLX )  December Metrics Indicate ...   AAPL\n",
            "12  20230118  GE Has Been One of the Best Stocks of 2023. Ca...   AAPL\n",
            "13  20230118  Spotify Teams Up With European Companies For R...   AAPL\n",
            "14  20230118             Apple Resurrects the Full-Size HomePod   AAPL\n",
            "15  20230118  2 Million Bikes Are Stolen Every Year - This S...   AAPL\n",
            "16  20230118  U.S. corporate greed has gone too far, says No...   AAPL\n",
            "17  20230118   Better Buy in 2023: Apple Stock vs. Amazon Stock   AAPL\n",
            "18  20230118  Down 22% to 30%, 3 Warren Buffett Dividend Sto...   AAPL\n",
            "19  20230118  Apple introduces the new HomePod with breakthr...   AAPL\n",
            "20  20230118  Tesla Has the Most Valuable Car Brand, but It ...   AAPL\n",
            "21  20230118  Apple Is Taking on Meta in Virtual Reality. It...   AAPL\n",
            "22  20230118  Jim Cramer's top 10 things to watch in the mar...   AAPL\n",
            "23  20230118  Spotify joins media firms to urge EU action ag...   AAPL\n",
            "24  20230118   OPEX Looms: 3 Reasons Markets May Need to Digest   AAPL\n",
            "25  20230118  Apple Is Taking on Meta in Virtual Reality. It...   AAPL\n",
            "26  20230118  Futures Rise Ahead Of Wholesale Inflation Repo...   AAPL\n",
            "27  20230118  Tesla Has the Most Valuable Car Brand, but It ...   AAPL\n",
            "28  20230118       2 Top Stocks to Buy in 2023 and Hold Forever   AAPL\n",
            "29  20230118  Wearable Payment Device Market will value USD ...   AAPL\n",
            "30  20230118  Viral TikTok: Can Anyone Really See Where You'...   AAPL\n",
            "31  20230118  Bill Gates Opts For Samsung Over Apple As 'Dai...   AAPL\n",
            "32  20230118  YouTube Beats Apple, Spotify As Top Podcast Pl...   AAPL\n",
            "33  20230118  Apple Is Taking on Meta in Virtual Reality. It...   AAPL\n",
            "34  20230118                 3 Stocks to Buy if They Take a Dip   AAPL\n",
            "35  20230118  Should Vanguard Russell 1000 Growth ETF  ( VON...   AAPL\n",
            "36  20230118  Is Invesco FTSE RAFI US 1000 ETF  ( PRF )  a S...   AAPL\n",
            "37  20230118  Opinion: After the recession, a new dynamism w...   AAPL\n",
            "38  20230118  In a Stunning Move, Apple Plans to Ditch Highl...   AAPL\n",
            "39  20230118        3 Rock-Solid Dividend Stocks to Buy in 2023   AAPL\n",
            "40  20230118  Apple's Chinese Suppliers Win Expansion Permit...   AAPL\n",
            "41  20230118  Taiwan Q4 GDP unexpectedly shrinks, worst perf...   AAPL\n",
            "42  20230118  Apple's Faster Chips Alone Can Boost Mac Growt...   AAPL\n",
            "43  20230118    Apple Plans Cheaper MR Headset For Wider Market   AAPL\n",
            "44  20230118  Apple Effect? Decentraland  ( MANA )  Soars 73...   AAPL\n",
            "45  20230118  Apple will delay AR glasses, focus instead on ...   AAPL\n",
            "46  20230117  The 5 tech earnings to watch as holiday-season...   AAPL\n",
            "47  20230117  John Chambers expects a 'tough' 2023 but plent...   AAPL\n",
            "48  20230117  Apple  ( AAPL )  Gains As Market Dips: What Yo...   AAPL\n",
            "49  20230117  Supreme Court asks U.S. government to weigh in...   AAPL\n"
          ]
        }
      ],
      "source": [
        "# Get data from AlphaAdvantage for one ticker for a particular day\n",
        "def getHistoricNewsData(ticker, startDate = None, endDate = None):\n",
        "    url = 'https://www.alphavantage.co/query?'\n",
        "    if startDate and endDate:\n",
        "        startDate = toAADate(startDate)\n",
        "        endDate = toAADate(endDate)\n",
        "        Myparams = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'time_from': startDate, 'time_to': endDate, 'sort': 'LATEST','limit': 100, 'apikey': AAapikey}\n",
        "    else:\n",
        "        Myparams = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'sort': 'LATEST','limit': 100, 'apikey': AAapikey}\n",
        "    r = requests.get(url, params = Myparams)\n",
        "    data = r.json()\n",
        "    #return data\n",
        "    historic_news = pd.DataFrame(columns=['Date', 'Headline', 'Ticker'])\n",
        "    for i in data.get(\"feed\"):\n",
        "        test_date = i.get(\"time_published\")\n",
        "        test_date = test_date[:8]\n",
        "        row = [test_date, i.get(\"title\"), ticker]\n",
        "        new_df = pd.DataFrame([row],columns=['Date', 'Headline', 'Ticker'])\n",
        "        historic_news = pd.concat([historic_news, new_df], axis=0, ignore_index=True)\n",
        "    return historic_news\n",
        "\n",
        "historic_news = getHistoricNewsData('AAPL', '2023012', '20230117')\n",
        "print(historic_news)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis of News data #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [],
      "source": [
        "def SentimentAnalysisNewsData(parsedNews):\n",
        "    nltk.download('vader_lexicon')\n",
        "    # Sentiment Analysis\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
        "    news = pd.DataFrame(parsedNews, columns=columns)\n",
        "    scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
        "\n",
        "    df_scores = pd.DataFrame(scores)\n",
        "    news = news.join(df_scores, rsuffix='_right')\n",
        "    news['Date'] = pd.to_datetime(news.Date).dt.date\n",
        "\n",
        "    unique_ticker = news['Ticker'].unique().tolist()\n",
        "    news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}\n",
        "\n",
        "    values = []\n",
        "    for ticker in tickers: \n",
        "        dataframe = news_dict[ticker]\n",
        "        dataframe = dataframe.set_index('Ticker')\n",
        "        dataframe = dataframe.drop(columns = ['Headline'])\n",
        "        print ('\\n')\n",
        "        print (dataframe.head())\n",
        "        \n",
        "        mean = round(dataframe['compound'].mean(), 2)\n",
        "        values.append(mean)\n",
        "        \n",
        "    df = pd.DataFrame(list(zip(tickers, values)), columns =['Ticker', 'Mean Sentiment']) \n",
        "    df = df.set_index('Ticker')\n",
        "    df = df.sort_values('Mean Sentiment', ascending=False)\n",
        "    print ('\\n')\n",
        "    print (df)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "              Date  Time    neg    neu    pos  compound\n",
            "Ticker                                                 \n",
            "AAPL    2023-01-18   NaN  0.000  1.000  0.000    0.0000\n",
            "AAPL    2023-01-18   NaN  0.000  1.000  0.000    0.0000\n",
            "AAPL    2023-01-18   NaN  0.421  0.579  0.000   -0.6249\n",
            "AAPL    2023-01-18   NaN  0.000  0.753  0.247    0.3182\n",
            "AAPL    2023-01-18   NaN  0.000  0.641  0.359    0.6808\n",
            "\n",
            "\n",
            "        Mean Sentiment\n",
            "Ticker                \n",
            "AAPL              0.13\n",
            "\n",
            "\n",
            "              Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                    \n",
            "AAPL    2023-01-18  07:28PM  0.375  0.625  0.000   -0.7783\n",
            "AAPL    2023-01-18  05:04PM  0.000  1.000  0.000    0.0000\n",
            "AAPL    2023-01-18  05:02PM  0.000  1.000  0.000    0.0000\n",
            "AAPL    2023-01-18  04:32PM  0.000  0.692  0.308    0.4588\n",
            "AAPL    2023-01-18  04:19PM  0.196  0.804  0.000   -0.2960\n",
            "\n",
            "\n",
            "        Mean Sentiment\n",
            "Ticker                \n",
            "AAPL             -0.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\Ishaan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\Ishaan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "HistoricSentiment = SentimentAnalysisNewsData(historic_news)\n",
        "TodaysSentiment = SentimentAnalysisNewsData(parsed_news)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating Dataset #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO2ChGGwJkijmmb0vDcCR40",
      "include_colab_link": true,
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
