{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishaanpaul98/Sentiment-Analysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pGQVQfr0b3SS"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen, Request\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "import time\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WSgZEvuikgTn"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9hbdUWDKkgv_"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Eqvj106lkgyU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stock Data Helper Functions #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting stock data for stock $AAPL\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-21</th>\n",
              "      <td>132.979996</td>\n",
              "      <td>136.809998</td>\n",
              "      <td>132.750000</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>85928000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-22</th>\n",
              "      <td>134.350006</td>\n",
              "      <td>134.559998</td>\n",
              "      <td>130.300003</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>77852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-23</th>\n",
              "      <td>130.919998</td>\n",
              "      <td>132.419998</td>\n",
              "      <td>129.639999</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>63814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>131.380005</td>\n",
              "      <td>131.410004</td>\n",
              "      <td>128.720001</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>69007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>129.669998</td>\n",
              "      <td>131.029999</td>\n",
              "      <td>125.870003</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>85438400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>127.989998</td>\n",
              "      <td>130.479996</td>\n",
              "      <td>127.730003</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>75703700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>128.410004</td>\n",
              "      <td>129.949997</td>\n",
              "      <td>127.430000</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>76960600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>130.279999</td>\n",
              "      <td>130.899994</td>\n",
              "      <td>124.169998</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>112117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>126.889999</td>\n",
              "      <td>128.660004</td>\n",
              "      <td>125.080002</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>89113600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>127.129997</td>\n",
              "      <td>127.769997</td>\n",
              "      <td>124.760002</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>80962700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>126.010002</td>\n",
              "      <td>130.289993</td>\n",
              "      <td>124.889999</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>87686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>130.470001</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>129.889999</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>70790800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-10</th>\n",
              "      <td>130.259995</td>\n",
              "      <td>131.259995</td>\n",
              "      <td>128.119995</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>63896200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-11</th>\n",
              "      <td>131.250000</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>130.460007</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>69458900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-12</th>\n",
              "      <td>133.880005</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>71379600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-13</th>\n",
              "      <td>132.029999</td>\n",
              "      <td>134.919998</td>\n",
              "      <td>131.660004</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>57758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17</th>\n",
              "      <td>134.830002</td>\n",
              "      <td>137.289993</td>\n",
              "      <td>134.130005</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>63646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-18</th>\n",
              "      <td>136.820007</td>\n",
              "      <td>138.610001</td>\n",
              "      <td>135.029999</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>69672800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-19</th>\n",
              "      <td>134.080002</td>\n",
              "      <td>136.250000</td>\n",
              "      <td>133.770004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>58280400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20</th>\n",
              "      <td>135.279999</td>\n",
              "      <td>138.020004</td>\n",
              "      <td>134.220001</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>79972200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-23</th>\n",
              "      <td>138.119995</td>\n",
              "      <td>143.320007</td>\n",
              "      <td>137.899994</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>81760300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-24</th>\n",
              "      <td>140.309998</td>\n",
              "      <td>143.160004</td>\n",
              "      <td>140.300003</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>66435100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-25</th>\n",
              "      <td>140.889999</td>\n",
              "      <td>142.429993</td>\n",
              "      <td>138.809998</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>65799300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-26</th>\n",
              "      <td>143.169998</td>\n",
              "      <td>144.250000</td>\n",
              "      <td>141.899994</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>54105100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-27</th>\n",
              "      <td>143.160004</td>\n",
              "      <td>147.229996</td>\n",
              "      <td>143.080002</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>70492800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-30</th>\n",
              "      <td>144.960007</td>\n",
              "      <td>145.550003</td>\n",
              "      <td>142.850006</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>63947600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High         Low       Close   Adj Close  \\\n",
              "Date                                                                     \n",
              "2022-12-21  132.979996  136.809998  132.750000  135.449997  135.449997   \n",
              "2022-12-22  134.350006  134.559998  130.300003  132.229996  132.229996   \n",
              "2022-12-23  130.919998  132.419998  129.639999  131.860001  131.860001   \n",
              "2022-12-27  131.380005  131.410004  128.720001  130.029999  130.029999   \n",
              "2022-12-28  129.669998  131.029999  125.870003  126.040001  126.040001   \n",
              "2022-12-29  127.989998  130.479996  127.730003  129.610001  129.610001   \n",
              "2022-12-30  128.410004  129.949997  127.430000  129.929993  129.929993   \n",
              "2023-01-03  130.279999  130.899994  124.169998  125.070000  125.070000   \n",
              "2023-01-04  126.889999  128.660004  125.080002  126.360001  126.360001   \n",
              "2023-01-05  127.129997  127.769997  124.760002  125.019997  125.019997   \n",
              "2023-01-06  126.010002  130.289993  124.889999  129.619995  129.619995   \n",
              "2023-01-09  130.470001  133.410004  129.889999  130.149994  130.149994   \n",
              "2023-01-10  130.259995  131.259995  128.119995  130.729996  130.729996   \n",
              "2023-01-11  131.250000  133.509995  130.460007  133.490005  133.490005   \n",
              "2023-01-12  133.880005  134.259995  131.440002  133.410004  133.410004   \n",
              "2023-01-13  132.029999  134.919998  131.660004  134.759995  134.759995   \n",
              "2023-01-17  134.830002  137.289993  134.130005  135.940002  135.940002   \n",
              "2023-01-18  136.820007  138.610001  135.029999  135.210007  135.210007   \n",
              "2023-01-19  134.080002  136.250000  133.770004  135.270004  135.270004   \n",
              "2023-01-20  135.279999  138.020004  134.220001  137.869995  137.869995   \n",
              "2023-01-23  138.119995  143.320007  137.899994  141.110001  141.110001   \n",
              "2023-01-24  140.309998  143.160004  140.300003  142.529999  142.529999   \n",
              "2023-01-25  140.889999  142.429993  138.809998  141.860001  141.860001   \n",
              "2023-01-26  143.169998  144.250000  141.899994  143.960007  143.960007   \n",
              "2023-01-27  143.160004  147.229996  143.080002  145.929993  145.929993   \n",
              "2023-01-30  144.960007  145.550003  142.850006  143.000000  143.000000   \n",
              "\n",
              "               Volume  \n",
              "Date                   \n",
              "2022-12-21   85928000  \n",
              "2022-12-22   77852100  \n",
              "2022-12-23   63814900  \n",
              "2022-12-27   69007800  \n",
              "2022-12-28   85438400  \n",
              "2022-12-29   75703700  \n",
              "2022-12-30   76960600  \n",
              "2023-01-03  112117500  \n",
              "2023-01-04   89113600  \n",
              "2023-01-05   80962700  \n",
              "2023-01-06   87686600  \n",
              "2023-01-09   70790800  \n",
              "2023-01-10   63896200  \n",
              "2023-01-11   69458900  \n",
              "2023-01-12   71379600  \n",
              "2023-01-13   57758000  \n",
              "2023-01-17   63646600  \n",
              "2023-01-18   69672800  \n",
              "2023-01-19   58280400  \n",
              "2023-01-20   79972200  \n",
              "2023-01-23   81760300  \n",
              "2023-01-24   66435100  \n",
              "2023-01-25   65799300  \n",
              "2023-01-26   54105100  \n",
              "2023-01-27   70492800  \n",
              "2023-01-30   63947600  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getStockDataDaily(symbol, day):\n",
        "    print(\"Getting stock data for stock $\"+symbol)\n",
        "    df = yf.download(symbol, start=day, period = \"1d\")\n",
        "    return df\n",
        "\n",
        "getStockDataDaily('AAPL', \"2022-12-21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def arrayToString(arr):\n",
        "    print(\"Starting array to list\")\n",
        "    listToStr = ' '.join([str(elem) for elem in arr])\n",
        "    return listToStr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of symbols array is more than 1. STARTING ARRAYTOSTRING\n",
            "Starting array to list\n",
            "Getting stock data for stock $AAPL TSLA\n",
            "[*********************100%***********************]  2 of 2 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">TSLA</th>\n",
              "      <th colspan=\"6\" halign=\"left\">AAPL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-21</th>\n",
              "      <td>139.339996</td>\n",
              "      <td>141.259995</td>\n",
              "      <td>135.889999</td>\n",
              "      <td>137.570007</td>\n",
              "      <td>137.570007</td>\n",
              "      <td>145417400</td>\n",
              "      <td>132.979996</td>\n",
              "      <td>136.809998</td>\n",
              "      <td>132.750000</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>85928000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-22</th>\n",
              "      <td>136.000000</td>\n",
              "      <td>136.630005</td>\n",
              "      <td>122.260002</td>\n",
              "      <td>125.349998</td>\n",
              "      <td>125.349998</td>\n",
              "      <td>210090300</td>\n",
              "      <td>134.350006</td>\n",
              "      <td>134.559998</td>\n",
              "      <td>130.300003</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>77852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-23</th>\n",
              "      <td>126.370003</td>\n",
              "      <td>128.619995</td>\n",
              "      <td>121.019997</td>\n",
              "      <td>123.150002</td>\n",
              "      <td>123.150002</td>\n",
              "      <td>166989700</td>\n",
              "      <td>130.919998</td>\n",
              "      <td>132.419998</td>\n",
              "      <td>129.639999</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>63814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>117.500000</td>\n",
              "      <td>119.669998</td>\n",
              "      <td>108.760002</td>\n",
              "      <td>109.099998</td>\n",
              "      <td>109.099998</td>\n",
              "      <td>208643400</td>\n",
              "      <td>131.380005</td>\n",
              "      <td>131.410004</td>\n",
              "      <td>128.720001</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>69007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>110.349998</td>\n",
              "      <td>116.269997</td>\n",
              "      <td>108.239998</td>\n",
              "      <td>112.709999</td>\n",
              "      <td>112.709999</td>\n",
              "      <td>221070500</td>\n",
              "      <td>129.669998</td>\n",
              "      <td>131.029999</td>\n",
              "      <td>125.870003</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>85438400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>120.389999</td>\n",
              "      <td>123.570000</td>\n",
              "      <td>117.500000</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>221923300</td>\n",
              "      <td>127.989998</td>\n",
              "      <td>130.479996</td>\n",
              "      <td>127.730003</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>75703700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>119.949997</td>\n",
              "      <td>124.480003</td>\n",
              "      <td>119.750000</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>157304500</td>\n",
              "      <td>128.410004</td>\n",
              "      <td>129.949997</td>\n",
              "      <td>127.430000</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>76960600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>118.470001</td>\n",
              "      <td>118.800003</td>\n",
              "      <td>104.639999</td>\n",
              "      <td>108.099998</td>\n",
              "      <td>108.099998</td>\n",
              "      <td>231402800</td>\n",
              "      <td>130.279999</td>\n",
              "      <td>130.899994</td>\n",
              "      <td>124.169998</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>112117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>109.110001</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>113.639999</td>\n",
              "      <td>113.639999</td>\n",
              "      <td>180389000</td>\n",
              "      <td>126.889999</td>\n",
              "      <td>128.660004</td>\n",
              "      <td>125.080002</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>89113600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>110.510002</td>\n",
              "      <td>111.750000</td>\n",
              "      <td>107.160004</td>\n",
              "      <td>110.339996</td>\n",
              "      <td>110.339996</td>\n",
              "      <td>157986300</td>\n",
              "      <td>127.129997</td>\n",
              "      <td>127.769997</td>\n",
              "      <td>124.760002</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>80962700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>103.000000</td>\n",
              "      <td>114.389999</td>\n",
              "      <td>101.809998</td>\n",
              "      <td>113.059998</td>\n",
              "      <td>113.059998</td>\n",
              "      <td>220575900</td>\n",
              "      <td>126.010002</td>\n",
              "      <td>130.289993</td>\n",
              "      <td>124.889999</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>87686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>118.959999</td>\n",
              "      <td>123.519997</td>\n",
              "      <td>117.110001</td>\n",
              "      <td>119.769997</td>\n",
              "      <td>119.769997</td>\n",
              "      <td>190284000</td>\n",
              "      <td>130.470001</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>129.889999</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>70790800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-10</th>\n",
              "      <td>121.070000</td>\n",
              "      <td>122.760002</td>\n",
              "      <td>114.919998</td>\n",
              "      <td>118.849998</td>\n",
              "      <td>118.849998</td>\n",
              "      <td>167642500</td>\n",
              "      <td>130.259995</td>\n",
              "      <td>131.259995</td>\n",
              "      <td>128.119995</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>63896200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-11</th>\n",
              "      <td>122.089996</td>\n",
              "      <td>125.949997</td>\n",
              "      <td>120.510002</td>\n",
              "      <td>123.220001</td>\n",
              "      <td>123.220001</td>\n",
              "      <td>183810800</td>\n",
              "      <td>131.250000</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>130.460007</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>69458900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-12</th>\n",
              "      <td>122.559998</td>\n",
              "      <td>124.129997</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>123.559998</td>\n",
              "      <td>123.559998</td>\n",
              "      <td>169400900</td>\n",
              "      <td>133.880005</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>71379600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-13</th>\n",
              "      <td>116.550003</td>\n",
              "      <td>122.629997</td>\n",
              "      <td>115.599998</td>\n",
              "      <td>122.400002</td>\n",
              "      <td>122.400002</td>\n",
              "      <td>180439300</td>\n",
              "      <td>132.029999</td>\n",
              "      <td>134.919998</td>\n",
              "      <td>131.660004</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>57758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17</th>\n",
              "      <td>125.699997</td>\n",
              "      <td>131.699997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>131.490005</td>\n",
              "      <td>131.490005</td>\n",
              "      <td>186477000</td>\n",
              "      <td>134.830002</td>\n",
              "      <td>137.289993</td>\n",
              "      <td>134.130005</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>63646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-18</th>\n",
              "      <td>136.559998</td>\n",
              "      <td>136.679993</td>\n",
              "      <td>127.010002</td>\n",
              "      <td>128.779999</td>\n",
              "      <td>128.779999</td>\n",
              "      <td>195680300</td>\n",
              "      <td>136.820007</td>\n",
              "      <td>138.610001</td>\n",
              "      <td>135.029999</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>69672800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-19</th>\n",
              "      <td>127.260002</td>\n",
              "      <td>129.990005</td>\n",
              "      <td>124.309998</td>\n",
              "      <td>127.169998</td>\n",
              "      <td>127.169998</td>\n",
              "      <td>170291900</td>\n",
              "      <td>134.080002</td>\n",
              "      <td>136.250000</td>\n",
              "      <td>133.770004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>58280400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20</th>\n",
              "      <td>128.679993</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>127.349998</td>\n",
              "      <td>133.419998</td>\n",
              "      <td>133.419998</td>\n",
              "      <td>138429900</td>\n",
              "      <td>135.279999</td>\n",
              "      <td>138.020004</td>\n",
              "      <td>134.220001</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>79972200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-23</th>\n",
              "      <td>135.869995</td>\n",
              "      <td>145.380005</td>\n",
              "      <td>134.270004</td>\n",
              "      <td>143.750000</td>\n",
              "      <td>143.750000</td>\n",
              "      <td>203119200</td>\n",
              "      <td>138.119995</td>\n",
              "      <td>143.320007</td>\n",
              "      <td>137.899994</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>81760300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-24</th>\n",
              "      <td>143.000000</td>\n",
              "      <td>146.500000</td>\n",
              "      <td>141.100006</td>\n",
              "      <td>143.889999</td>\n",
              "      <td>143.889999</td>\n",
              "      <td>158699100</td>\n",
              "      <td>140.309998</td>\n",
              "      <td>143.160004</td>\n",
              "      <td>140.300003</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>66435100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-25</th>\n",
              "      <td>141.910004</td>\n",
              "      <td>146.410004</td>\n",
              "      <td>138.070007</td>\n",
              "      <td>144.429993</td>\n",
              "      <td>144.429993</td>\n",
              "      <td>192734300</td>\n",
              "      <td>140.889999</td>\n",
              "      <td>142.429993</td>\n",
              "      <td>138.809998</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>65799300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-26</th>\n",
              "      <td>159.970001</td>\n",
              "      <td>161.419998</td>\n",
              "      <td>154.759995</td>\n",
              "      <td>160.270004</td>\n",
              "      <td>160.270004</td>\n",
              "      <td>234815100</td>\n",
              "      <td>143.169998</td>\n",
              "      <td>144.250000</td>\n",
              "      <td>141.899994</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>54105100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-27</th>\n",
              "      <td>162.429993</td>\n",
              "      <td>180.679993</td>\n",
              "      <td>161.169998</td>\n",
              "      <td>177.899994</td>\n",
              "      <td>177.899994</td>\n",
              "      <td>305632100</td>\n",
              "      <td>143.160004</td>\n",
              "      <td>147.229996</td>\n",
              "      <td>143.080002</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>70492800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-30</th>\n",
              "      <td>178.050003</td>\n",
              "      <td>179.770004</td>\n",
              "      <td>166.500000</td>\n",
              "      <td>166.660004</td>\n",
              "      <td>166.660004</td>\n",
              "      <td>230203200</td>\n",
              "      <td>144.960007</td>\n",
              "      <td>145.550003</td>\n",
              "      <td>142.850006</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>63947600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  TSLA                                                  \\\n",
              "                  Open        High         Low       Close   Adj Close   \n",
              "Date                                                                     \n",
              "2022-12-21  139.339996  141.259995  135.889999  137.570007  137.570007   \n",
              "2022-12-22  136.000000  136.630005  122.260002  125.349998  125.349998   \n",
              "2022-12-23  126.370003  128.619995  121.019997  123.150002  123.150002   \n",
              "2022-12-27  117.500000  119.669998  108.760002  109.099998  109.099998   \n",
              "2022-12-28  110.349998  116.269997  108.239998  112.709999  112.709999   \n",
              "2022-12-29  120.389999  123.570000  117.500000  121.820000  121.820000   \n",
              "2022-12-30  119.949997  124.480003  119.750000  123.180000  123.180000   \n",
              "2023-01-03  118.470001  118.800003  104.639999  108.099998  108.099998   \n",
              "2023-01-04  109.110001  114.589996  107.519997  113.639999  113.639999   \n",
              "2023-01-05  110.510002  111.750000  107.160004  110.339996  110.339996   \n",
              "2023-01-06  103.000000  114.389999  101.809998  113.059998  113.059998   \n",
              "2023-01-09  118.959999  123.519997  117.110001  119.769997  119.769997   \n",
              "2023-01-10  121.070000  122.760002  114.919998  118.849998  118.849998   \n",
              "2023-01-11  122.089996  125.949997  120.510002  123.220001  123.220001   \n",
              "2023-01-12  122.559998  124.129997  117.000000  123.559998  123.559998   \n",
              "2023-01-13  116.550003  122.629997  115.599998  122.400002  122.400002   \n",
              "2023-01-17  125.699997  131.699997  125.019997  131.490005  131.490005   \n",
              "2023-01-18  136.559998  136.679993  127.010002  128.779999  128.779999   \n",
              "2023-01-19  127.260002  129.990005  124.309998  127.169998  127.169998   \n",
              "2023-01-20  128.679993  133.509995  127.349998  133.419998  133.419998   \n",
              "2023-01-23  135.869995  145.380005  134.270004  143.750000  143.750000   \n",
              "2023-01-24  143.000000  146.500000  141.100006  143.889999  143.889999   \n",
              "2023-01-25  141.910004  146.410004  138.070007  144.429993  144.429993   \n",
              "2023-01-26  159.970001  161.419998  154.759995  160.270004  160.270004   \n",
              "2023-01-27  162.429993  180.679993  161.169998  177.899994  177.899994   \n",
              "2023-01-30  178.050003  179.770004  166.500000  166.660004  166.660004   \n",
              "\n",
              "                             AAPL                                      \\\n",
              "               Volume        Open        High         Low       Close   \n",
              "Date                                                                    \n",
              "2022-12-21  145417400  132.979996  136.809998  132.750000  135.449997   \n",
              "2022-12-22  210090300  134.350006  134.559998  130.300003  132.229996   \n",
              "2022-12-23  166989700  130.919998  132.419998  129.639999  131.860001   \n",
              "2022-12-27  208643400  131.380005  131.410004  128.720001  130.029999   \n",
              "2022-12-28  221070500  129.669998  131.029999  125.870003  126.040001   \n",
              "2022-12-29  221923300  127.989998  130.479996  127.730003  129.610001   \n",
              "2022-12-30  157304500  128.410004  129.949997  127.430000  129.929993   \n",
              "2023-01-03  231402800  130.279999  130.899994  124.169998  125.070000   \n",
              "2023-01-04  180389000  126.889999  128.660004  125.080002  126.360001   \n",
              "2023-01-05  157986300  127.129997  127.769997  124.760002  125.019997   \n",
              "2023-01-06  220575900  126.010002  130.289993  124.889999  129.619995   \n",
              "2023-01-09  190284000  130.470001  133.410004  129.889999  130.149994   \n",
              "2023-01-10  167642500  130.259995  131.259995  128.119995  130.729996   \n",
              "2023-01-11  183810800  131.250000  133.509995  130.460007  133.490005   \n",
              "2023-01-12  169400900  133.880005  134.259995  131.440002  133.410004   \n",
              "2023-01-13  180439300  132.029999  134.919998  131.660004  134.759995   \n",
              "2023-01-17  186477000  134.830002  137.289993  134.130005  135.940002   \n",
              "2023-01-18  195680300  136.820007  138.610001  135.029999  135.210007   \n",
              "2023-01-19  170291900  134.080002  136.250000  133.770004  135.270004   \n",
              "2023-01-20  138429900  135.279999  138.020004  134.220001  137.869995   \n",
              "2023-01-23  203119200  138.119995  143.320007  137.899994  141.110001   \n",
              "2023-01-24  158699100  140.309998  143.160004  140.300003  142.529999   \n",
              "2023-01-25  192734300  140.889999  142.429993  138.809998  141.860001   \n",
              "2023-01-26  234815100  143.169998  144.250000  141.899994  143.960007   \n",
              "2023-01-27  305632100  143.160004  147.229996  143.080002  145.929993   \n",
              "2023-01-30  230203200  144.960007  145.550003  142.850006  143.000000   \n",
              "\n",
              "                                   \n",
              "             Adj Close     Volume  \n",
              "Date                               \n",
              "2022-12-21  135.449997   85928000  \n",
              "2022-12-22  132.229996   77852100  \n",
              "2022-12-23  131.860001   63814900  \n",
              "2022-12-27  130.029999   69007800  \n",
              "2022-12-28  126.040001   85438400  \n",
              "2022-12-29  129.610001   75703700  \n",
              "2022-12-30  129.929993   76960600  \n",
              "2023-01-03  125.070000  112117500  \n",
              "2023-01-04  126.360001   89113600  \n",
              "2023-01-05  125.019997   80962700  \n",
              "2023-01-06  129.619995   87686600  \n",
              "2023-01-09  130.149994   70790800  \n",
              "2023-01-10  130.729996   63896200  \n",
              "2023-01-11  133.490005   69458900  \n",
              "2023-01-12  133.410004   71379600  \n",
              "2023-01-13  134.759995   57758000  \n",
              "2023-01-17  135.940002   63646600  \n",
              "2023-01-18  135.210007   69672800  \n",
              "2023-01-19  135.270004   58280400  \n",
              "2023-01-20  137.869995   79972200  \n",
              "2023-01-23  141.110001   81760300  \n",
              "2023-01-24  142.529999   66435100  \n",
              "2023-01-25  141.860001   65799300  \n",
              "2023-01-26  143.960007   54105100  \n",
              "2023-01-27  145.929993   70492800  \n",
              "2023-01-30  143.000000   63947600  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getMultiStockDataDaily(symbols, day):\n",
        "    if len(symbols) > 1:\n",
        "        print(\"Length of symbols array is more than 1. STARTING ARRAYTOSTRING\")\n",
        "        symbols = arrayToString(symbols)\n",
        "    print(\"Getting stock data for stock $\"+symbols)\n",
        "    df = yf.download(symbols, start=day, period = \"1d\", group_by='ticker')\n",
        "    return df\n",
        "\n",
        "getMultiStockDataDaily(['AAPL', 'TSLA'], \"2022-12-21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getMonthlyStockData(symbol, day = datetime.date.today() - datetime.timedelta(days = 1), interval = '1mo'):\n",
        "    print(\"Getting stock data for stock $\"+symbol)\n",
        "    df = yf.download(symbol, start=day, period = interval, group_by='ticker')\n",
        "    return df\n",
        "\n",
        "#getMonthlyStockData('AAPL', \"2022-11-21\", '1mo')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathering FinViz Data (Today's News) #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters \n",
        "n = 3 #the # of article headlines displayed per ticker\n",
        "tickers = ['AAPL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'news':        Date                                              Title  \\\n",
              " 0   12:53AM  Putin's former speechwriter says a military co...   \n",
              " 1   12:47AM                          Morning Bid: Mind the gap   \n",
              " 2   12:04AM  Thailand Hands Out 95 Million Condoms to Beat ...   \n",
              " 3   12:03AM  A radioactive capsule is missing in Australia....   \n",
              " 4   12:01AM  India's Adani Enterprises enters final day of ...   \n",
              " ..      ...                                                ...   \n",
              " 85   Jan-30  : Gold futures end lower after posting gains f...   \n",
              " 86   Jan-30  JPMorgan reviews oversight of traders amid boo...   \n",
              " 87   Jan-30  Twitter Makes First Interest Payment on Musk B...   \n",
              " 88   Jan-30  Biden's new student loan repayment plan would ...   \n",
              " 89   Jan-30  Russia boosts China trade to counter Western s...   \n",
              " \n",
              "                  Source                                               Link  \n",
              " 0       edition.cnn.com  https://edition.cnn.com/webview/europe/live-ne...  \n",
              " 1       www.reuters.com  https://www.reuters.com/markets/global-markets...  \n",
              " 2     www.bloomberg.com  https://www.bloomberg.com/news/articles/2023-0...  \n",
              " 3           www.cnn.com  https://www.cnn.com/2023/01/31/business/missin...  \n",
              " 4       www.reuters.com  https://www.reuters.com/markets/deals/indias-a...  \n",
              " ..                  ...                                                ...  \n",
              " 85  www.marketwatch.com  http://www.marketwatch.com/news/story/gold-fut...  \n",
              " 86      www.reuters.com  https://www.reuters.com/business/finance/jpmor...  \n",
              " 87    www.bloomberg.com  https://www.bloomberg.com/news/articles/2023-0...  \n",
              " 88      foxbusiness.com  https://foxbusiness.com/politics/bidens-new-st...  \n",
              " 89      foxbusiness.com  https://foxbusiness.com/economy/russia-boosts-...  \n",
              " \n",
              " [90 rows x 4 columns],\n",
              " 'blogs':        Date                                              Title  \\\n",
              " 0   12:08AM                               Time To Study Abroad   \n",
              " 1    Jan-30  Buy Superbly Managed, Fast Growing, Deep Moate...   \n",
              " 2    Jan-30                 Tuesday: Case-Shiller House Prices   \n",
              " 3    Jan-30  Unvaccinated Kidney And Heart Patients Denied ...   \n",
              " 4    Jan-30  Vail Resorts Record An Abundance Of Snow Despi...   \n",
              " ..      ...                                                ...   \n",
              " 85   Dec-18                           Your Mental Sharpe Ratio   \n",
              " 86   Dec-06   The Three Essential Sources of Your Trading Edge   \n",
              " 87   Nov-24                                Trading Consciously   \n",
              " 88   Nov-18  Relapse Prevention:  A Neglected Topic In Trad...   \n",
              " 89   May-21  New Issue Now Available: What Hedge Funds Boug...   \n",
              " \n",
              "                         Source  \\\n",
              " 0             seekingalpha.com   \n",
              " 1             seekingalpha.com   \n",
              " 2   www.calculatedriskblog.com   \n",
              " 3            www.zerohedge.com   \n",
              " 4            www.zerohedge.com   \n",
              " ..                         ...   \n",
              " 85     traderfeed.blogspot.com   \n",
              " 86     traderfeed.blogspot.com   \n",
              " 87     traderfeed.blogspot.com   \n",
              " 88     traderfeed.blogspot.com   \n",
              " 89         www.marketfolly.com   \n",
              " \n",
              "                                                  Link  \n",
              " 0   https://seekingalpha.com/article/4573718-time-...  \n",
              " 1   https://seekingalpha.com/article/4573697-atkor...  \n",
              " 2   http://www.calculatedriskblog.com/2023/01/tues...  \n",
              " 3   https://www.zerohedge.com/medical/unvaccinated...  \n",
              " 4   https://www.zerohedge.com/weather/vail-resorts...  \n",
              " ..                                                ...  \n",
              " 85  http://traderfeed.blogspot.com/2022/12/your-me...  \n",
              " 86  http://traderfeed.blogspot.com/2022/12/the-thr...  \n",
              " 87  http://traderfeed.blogspot.com/2022/11/trading...  \n",
              " 88  http://traderfeed.blogspot.com/2022/11/relapse...  \n",
              " 89  http://www.marketfolly.com/2022/05/new-issue-n...  \n",
              " \n",
              " [90 rows x 4 columns]}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from finvizfinance.news import News\n",
        "fnews = News()\n",
        "all_news = fnews.get_news()\n",
        "all_news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current url is: https://finviz.com/quote.ashx?t=AAPL\n",
            "\n",
            "\n",
            "Recent News Headlines for AAPL: \n",
            "Apple violated work rules according to US labour watchdog ( Jan-30-23 10:50PM )\n",
            "Apple Executives Violated Worker Rights, Labor Officials Say ( 08:13PM )\n",
            "Time to Take Another Bite of Apple Before Q1 Earnings? ( 05:48PM )\n"
          ]
        }
      ],
      "source": [
        "# Get Data\n",
        "finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
        "news_tables = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    url = finwiz_url + ticker\n",
        "    print(\"current url is: \" +url)\n",
        "    header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36.\"}\n",
        "    req = Request(url=url,headers=header) \n",
        "    resp = urlopen(req)    \n",
        "    html = BeautifulSoup(resp, features=\"lxml\")\n",
        "    news_table = html.find(id='news-table')\n",
        "    news_tables[ticker] = news_table\n",
        "\n",
        "try:\n",
        "    for ticker in tickers:\n",
        "        df = news_tables[ticker]\n",
        "        df_tr = df.findAll('tr')\n",
        "    \n",
        "        print ('\\n')\n",
        "        print ('Recent News Headlines for {}: '.format(ticker))\n",
        "        \n",
        "        for i, table_row in enumerate(df_tr):\n",
        "            a_text = table_row.a.text\n",
        "            td_text = table_row.td.text\n",
        "            td_text = td_text.strip()\n",
        "            print(a_text,'(',td_text,')')\n",
        "            if i == n-1:\n",
        "                break\n",
        "except KeyError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jan-30-23 10:50PMApple violated work rules according to US labour watchdog Financial Times\n",
            "08:13PMApple Executives Violated Worker Rights, Labor Officials Say Bloomberg\n",
            "05:48PMTime to Take Another Bite of Apple Before Q1 Earnings? Zacks\n",
            "04:49PMApple Profit Could Fall on China Production, Demand Slowdown Investopedia\n",
            "04:44PMWhat some of the factors driving tech industry layoffs are Yahoo Finance Video\n",
            "\n",
            "04:31PM\n",
            "Loading\n",
            "\n",
            "04:31PMCould Big Tech layoffs grow? Apple, Amazon, Facebook and Google may give hints in biggest week of holiday earnings. MarketWatch\n",
            "03:46PMApple earnings may rely on an unlikely hero amid iPhone uncertainty MarketWatch\n",
            "03:21PMApple says using its own chips gives it a 'unique advantage' over PC industry Yahoo Finance\n",
            "03:21PMApple says ditching Intel gives it a 'unique advantage' over PC industry Yahoo Finance\n",
            "03:17PMBig Tech stocks fall amid speculation of this weeks Fed decision Yahoo Finance Video\n",
            "03:16PMHow some of the Big Tech stocks usually perform after reporting earnings Yahoo Finance Video\n",
            "02:36PMApple's Tim Cook is 'a Hall of Fame CEO' who will avoid layoffs, analyst predicts Yahoo Finance\n",
            "01:50PMApple May Soon Be Next to Bet on Foldable Tech TheStreet.com\n",
            "12:50PMUS STOCKS-Nasdaq falls as megacaps drop ahead of earnings, Fed meet in focus Reuters\n",
            "12:04PMEarnings this week: Meta, Peloton, Starbucks, Apple among companies reporting results Yahoo Finance Video\n",
            "\n",
            "12:00PM\n",
            "Loading\n",
            "\n",
            "12:00PMWith a Busy Week Ahead We Look at Several Portfolio Stocks TheStreet.com\n",
            "11:15AMApple Music launches Rihannas Road to Halftime ahead of Super Bowl LVII Business Wire\n",
            "10:59AMUS STOCKS-Nasdaq falls as megacaps drop ahead of earnings, Fed meet in focus Reuters\n",
            "10:35AMApple Plans 2024 Launch for Foldable iPad, Analyst Says Barrons.com\n",
            "10:29AMTech Stocks, on Best Run Since 2001, Face Stern Test With Megacap Earnings on Deck TheStreet.com\n",
            "10:17AMWhen Your Dog Eats Your Apple AirTag The Wall Street Journal\n",
            "10:08AMPC demand: Intel, HP, Apple will have some hard times in first half of 2023, IDC VP says Yahoo Finance Video\n",
            "10:07AMApple stock: Investors brace for tough earnings report Yahoo Finance Video\n",
            "09:55AMDow Jones Falls 100 Points With Fed Meeting In Sight; Tesla Stock Upgraded To Buy After 33% Surge Investor's Business Daily\n",
            "09:39AMWhy Apple is no different than Rocky ahead of earnings: Dan Ives Yahoo Finance Video\n",
            "09:34AMDollars Decline Is a Rare Nasdaq Tailwind as Earnings Loom Bloomberg\n",
            "09:33AMDow Jones Falls With Fed Meeting In Sight; Tesla Upgraded To Buy After 33% Surge Investor's Business Daily\n",
            "09:15AMThe best GPS running watches for 2023 Engadget\n",
            "09:15AMWhere Will Verizon Communications Stock Be in 1 Year? Motley Fool\n",
            "09:12AMApple files for more construction in NW Austin American City Business Journals\n",
            "\n",
            "09:12AM\n",
            "Loading\n",
            "\n",
            "09:12AMBig Tech Earnings Are Almost Here. Microsoft Has Investors on Edge. Barrons.com\n",
            "08:58AMDow Jones Futures Fall With Fed Meeting In Sight; Tesla Upgraded To Buy After 33% Surge Investor's Business Daily\n",
            "08:15AMFutures Fall Ahead Of Fed Meeting, Big Earnings; Why This May Be A 'Life Changing' Market Rally Investor's Business Daily\n",
            "08:02AMiPhone Sales, ZuckerbergsMetaverse Bet, Spotify Pricing: Earnings to Watch Bloomberg\n",
            "08:00AMThink Chevron's Profit Was Obscene? 5 Companies Will Blow It Away Investor's Business Daily\n",
            "07:30AMApple Stock Climbs Off Lows As Earnings Optimism Builds: 3 Other FAANG Stocks Dominate Earnings Calendar Investor's Business Daily\n",
            "07:13AMGLOBAL MARKETS-Shares and bonds nervy as rate-hike week looms Reuters\n",
            "06:56AMApple Supplier Jabil Starts Making AirPods Components In India, Reduce Dependence On China Benzinga\n",
            "06:46AMMarkets Say Rate Hikes Can Stop Soon. Why the Feds Not So Sure. Barrons.com\n",
            "06:00AMApple set to report earnings amid wave of tech layoffs Yahoo Finance Video\n",
            "05:52AMNearly 43% of Warren Buffett's Portfolio Is Invested in These 5 Tech Stocks Motley Fool\n",
            "05:29AMWhy it's such a bizarre moment for investors rights now: Morning Brief Yahoo Finance\n",
            "05:00AMAmazon, Alphabet, Apple, Intel and Microsoft are part of Zacks Earnings Preview Zacks\n",
            "04:19AMGLOBAL MARKETS-Shares shaky as rate-hike week looms Reuters\n",
            "12:47AMApple's India supplier Jabil making AirPods parts for export-Bloomberg Reuters\n",
            "12:45AMRPT-Apple's India supplier Jabil making AirPods parts for export-Bloomberg Reuters\n",
            "12:14AMHuawei Spinoff Is Lone Winner in Dire Year for China Smartphones Bloomberg\n",
            "12:13AMApple Supplier in India Begins Making Components for AirPods Bloomberg\n",
            "Jan-29-23 11:59PMUPDATE 1-China's 2022 smartphone sales plunge to lowest level in a decade Reuters\n",
            "11:26PMGLOBAL MARKETS-Asia shares turn cagey as rate hikes, earnings loom Reuters\n",
            "10:18PMFutures Await Fed Meeting, Big Earnings; Why This May Be A 'Life Changing' Market Rally Investor's Business Daily\n",
            "09:30PMGLOBAL MARKETS-Asia shares welcome China back, ready for rate hikes Reuters\n",
            "07:33PMAsia shares turn cagey as rate hikes, earnings loom Reuters\n",
            "07:28PMGLOBAL MARKETS-Asia shares brace for rate hikes, earnings rush Reuters\n",
            "06:41PMCould Big Tech layoffs keep growing? Apple, Amazon, Facebook and Google may give hints in biggest week of earnings. MarketWatch\n",
            "06:38PMWhy This May Be A 'Life Changing' Market Rally; Apple, Fed Meeting Loom As Tesla Run Hits 75% Investor's Business Daily\n",
            "02:35PM15 Most Famous Hedge Fund Managers and Their Top Stock Picks Insider Monkey\n",
            "10:30AMTarget, Amazon and 4 More Retailers That Will Reward You for Turning in Your Old Stuff GOBankingRates\n",
            "07:53AMFed meeting, jobs data, Apple earnings: What to know this week Yahoo Finance\n",
            "07:00AM$50 AirPods Pro? Nope. Heres How to Spot Fake Apple Earbuds. The Wall Street Journal\n",
            "06:00AMApple (NASDAQ:AAPL) stock performs better than its underlying earnings growth over last five years Simply Wall St.\n",
            "05:45AM5 Top Stocks for February Motley Fool\n",
            "01:09AMChina's 2022 smartphone shipments the lowest in 10 years - research firm Reuters\n",
            "01:00AMChina's 2022 smartphone shipments the lowest in 10 years - research firm Reuters\n",
            "Jan-28-23 10:00AMHow to Build Great Wealth With the Power of Compounding TheStreet.com\n",
            "08:26AMAmazon, Apple, Alphabet Headline Another Busy Earnings Week The Wall Street Journal\n",
            "Jan-27-23 06:34PMWeekly Roundup TheStreet.com\n",
            "06:20PMStock Market Investing Action Plan  January Wrap: Apple, OPEC, Exxon And The Fed Investor's Business Daily\n",
            "05:05PMTech earnings, Fed decision, economic data expected out next week Yahoo Finance Video\n",
            "04:48PMApple Takes The Cake Again In China As Top Smartphone Seller Amid Odds Benzinga\n",
            "04:10PMApple Stock Climbs Wall Of Worry Ahead Of Earnings Report Investor's Business Daily\n",
            "02:42PMGoldman Sachs David Solomon latest CEO hit with pay cut Fox Business\n",
            "01:31PMPutting Chevrons $75 Billion Stock Buyback in Context Investopedia\n",
            "11:47AMApple, ServiceNow avoid job cuts amid mass tech layoffs Yahoo Finance Video\n",
            "11:11AMApple developing software to help users build apps for upcoming headset - The Information Reuters\n",
            "10:35AMApple Q1 earnings: 3 things to watch for Yahoo Finance Video\n",
            "10:11AMDow Jones Reverses After Inflation Data; Intel Plunges 10% On Earnings Investor's Business Daily\n",
            "09:36AMDow Jones Falls After Inflation Data; Intel Plunges 10% On Earnings Investor's Business Daily\n",
            "09:18AMDow Jones Futures Dip After Inflation Data; Intel Plunges On Earnings Investor's Business Daily\n",
            "09:02AM67.65% of Warren Buffett's Berkshire Hathaway Portfolio is in These 4 Stocks Motley Fool\n",
            "08:36AMBig Tech got the pandemic wrong but one company emerged on top Financial Times\n",
            "08:20AMDow Jones Futures Dip Ahead Of Inflation Data; Intel Plunges On Earnings Investor's Business Daily\n",
            "06:10AMGot $1,000? 5 Buffett Stocks to Buy in 2023 and Hold Forever Motley Fool\n",
            "05:52AM4 FAANG Stocks Wall Street Thinks Will Be Big Winners in 2023 -- and 1 Analysts Aren't So Bullish About Motley Fool\n",
            "05:06AM80% of Warren Buffett's Portfolio Is Invested in These 7 Stocks Motley Fool\n",
            "04:00AMApples iPhone Dominated China Last Quarter Despite Disruptions Bloomberg\n",
            "Jan-26-23 03:53PMApple Earnings Preview: Time to Buy AAPL Stock? Zacks\n",
            "03:51PMApple iPhone shipments declined almost 15% year-over-year in 2022 Yahoo Finance Video\n",
            "02:44PMUPDATE 1-U.S. lawsuit against Google could benefit Apple and others Reuters\n",
            "12:25PMApple Avoids Layoffs Hitting the Rest of Tech, for Now WSJ\n",
            "12:09PMU.S. lawsuit against Google could benefit Apple and others Reuters\n",
            "12:04PMU.S. lawsuit against Google could benefit Apple and others Reuters\n",
            "10:01AMEarnings Preview: Apple (AAPL) Q1 Earnings Expected to Decline Zacks\n",
            "09:36AM30 of the Worlds Most Valuable Private Companies Insider Monkey\n",
            "09:00AMDoes This VR News Make Apple Stock a Buy for 2023? Motley Fool\n",
            "08:06AMIf Cash Is King, These Nasdaq Stocks Reign Supreme Motley Fool\n",
            "07:35AMSmartphones: better kit could depress long-term growth Financial Times\n",
            "06:07AM1 Growth Stock Down 15% to Buy Right Now Motley Fool\n",
            "05:17AM2 Warren Buffett Stocks That Could Crush the Market in 2023 Motley Fool\n",
            "01:45AMApple couldnt save the smartphone industry from its worst year since 2013 MarketWatch\n"
          ]
        }
      ],
      "source": [
        "# Iterate through the news\n",
        "parsed_news = []\n",
        "for file_name, news_table in news_tables.items():\n",
        "    for x in news_table.findAll('tr'):\n",
        "        print(x.get_text())\n",
        "        text = x.get_text() \n",
        "        date_scrape = x.td.text.split()\n",
        "\n",
        "        if len(date_scrape) == 1:\n",
        "            time = date_scrape[0]\n",
        "            \n",
        "        else:\n",
        "            date = date_scrape[0]\n",
        "            time = date_scrape[1]\n",
        "\n",
        "        ticker = file_name.split('_')[0]\n",
        "        \n",
        "        parsed_news.append([ticker, date, time, text ])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathering Data From AlphaAdvantage for Historical News #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "from decouple import config\n",
        "import requests\n",
        "import urllib.parse\n",
        "import json\n",
        "import datetime\n",
        "AAapikey = config('AAKey')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to convert user provided date to date required by AlphaAdvantage\n",
        "def toAADate(oldDate):\n",
        "    newDate = oldDate.strftime(\"%Y%m%dT0130\")\n",
        "    return str(newDate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "endDate is: 2023-01-29\n",
            "startDate is: 2022-11-30\n",
            "startDate is: 20221130T0130\n",
            "endDate is: 20230129T0130\n",
            "           Date                                           Headline Ticker\n",
            "0    2022-11-30  Market Volatility Eases Slightly Following Hop...   AAPL\n",
            "1    2022-11-30  Fraud Detection and Prevention Market Size [20...   AAPL\n",
            "2    2022-11-30  Smart Investors Should Buy These 3 Stocks, Dow...   AAPL\n",
            "3    2022-11-30  Mindfulness Meditation Application Market to R...   AAPL\n",
            "4    2022-11-30  3 Reasons I'm Avoiding Meta Platforms Stock Fo...   AAPL\n",
            "..          ...                                                ...    ...\n",
            "195  2022-12-06  Here is What to Know Beyond Why Apple Inc.  ( ...   AAPL\n",
            "196  2022-12-06  Billionaire Mark Cuban Becomes Elon Musk's Mos...   AAPL\n",
            "197  2022-12-06  Taiwan Semiconductor Boosts US Investment Afte...   AAPL\n",
            "198  2022-12-06  4 Stocks You'll Regret Not Buying at Their Cur...   AAPL\n",
            "199  2022-12-06  Dow Jones Slips; Microsoft Ups Battle For Acti...   AAPL\n",
            "\n",
            "[200 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Get data from AlphaAdvantage for one ticker for a particular day\n",
        "def getHistoricNewsData(ticker, endDate = datetime.date.today() - datetime.timedelta(days = 1) , interval = '1mo'):\n",
        "    url = 'https://www.alphavantage.co/query?'\n",
        "    print(\"endDate is: \" +str(endDate))\n",
        "    if interval == '1mo':\n",
        "        days_to_add = 30\n",
        "    else:\n",
        "        days_to_add = 60\n",
        "    delta_days = datetime.timedelta(days = days_to_add)\n",
        "    startDate = endDate - delta_days\n",
        "    print(\"startDate is: \" +str(startDate))\n",
        "    if startDate and endDate:\n",
        "        startDate = toAADate(startDate)\n",
        "        endDate = toAADate(endDate)\n",
        "        print(\"startDate is: \" +str(startDate))\n",
        "        print(\"endDate is: \" +str(endDate))\n",
        "        Myparams = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'time_from': startDate, 'time_to': endDate, 'sort': 'EARLIEST','limit': 200, 'apikey': AAapikey}\n",
        "    else:\n",
        "        print(\"NEED DATES\")\n",
        "        #Myparams = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'sort': 'LATEST','limit': 100, 'apikey': AAapikey}\n",
        "    r = requests.get(url, params = Myparams)\n",
        "    data = r.json()\n",
        "    #return data\n",
        "    historic_news = pd.DataFrame(columns=['Date', 'Headline', 'Ticker'])\n",
        "    for i in data.get(\"feed\"):\n",
        "        test_date = i.get(\"time_published\")\n",
        "        test_date = test_date[:8]\n",
        "        newDate = datetime.datetime.strptime(test_date, '%Y%m%d').date()\n",
        "        row = [newDate, i.get(\"title\"), ticker]\n",
        "        new_df = pd.DataFrame([row],columns=['Date', 'Headline', 'Ticker'])\n",
        "        historic_news = pd.concat([historic_news, new_df], axis=0, ignore_index=True)\n",
        "    return historic_news\n",
        "\n",
        "#historic_news = getHistoricNewsData('AAPL', '2022-10-10', '2mo')\n",
        "historic_news = getHistoricNewsData('AAPL', interval = '2mo')\n",
        "print(historic_news)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis of News data #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def SentimentAnalysisNewsData(parsedNews, printOut = False):\n",
        "    #Downloading Vader Lexicon for Sentiment Analysis\n",
        "    nltk.download('vader_lexicon')\n",
        "    # Initializing Sentiment Analysis\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    #Declaring Column Names\n",
        "    columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
        "    #Creating dataframe from news\n",
        "    news = pd.DataFrame(parsedNews, columns=columns)\n",
        "    #Getting scores for headlines\n",
        "    scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
        "\n",
        "    #Creating Dataframe of Scores\n",
        "    df_scores = pd.DataFrame(scores)\n",
        "    #Joining scores to news dataframe\n",
        "    news = news.join(df_scores, rsuffix='_right')\n",
        "    #Converting Date column to pd datetime date\n",
        "    news['Date'] = pd.to_datetime(news.Date).dt.date\n",
        "\n",
        "    #List of unique tickers\n",
        "    unique_ticker = news['Ticker'].unique().tolist()\n",
        "    #Creating dict for news based on ticker\n",
        "    news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}\n",
        "    #Initializing List of values\n",
        "    # og values = []\n",
        "    values = pd.DataFrame(columns = ['Ticker', 'Date', 'Compound'])\n",
        "    for ticker in tickers: \n",
        "        dataframe = news_dict[ticker]\n",
        "        dataframe = dataframe.set_index('Ticker')\n",
        "        #Dropping headlines column since we only need scores now\n",
        "        dataframe = dataframe.drop(columns = ['Headline'])\n",
        "        #if printOut:\n",
        "            #print ('\\n')\n",
        "            #print (dataframe.head())\n",
        "        \n",
        "        #mean = round(dataframe['compound'].mean(), 2)\n",
        "        #Finding compound number for news of every day\n",
        "        testdf = pd.DataFrame(columns = ['Date', 'Mean Sentiment'])\n",
        "        testdf = round(dataframe.groupby('Date')['compound'].mean(), 2)\n",
        "        print(testdf)\n",
        "        #Adding values to values list\n",
        "        #og values.append(mean)\n",
        "    \n",
        "   \n",
        "    #print(round(dataframe.groupby('Date')['compound'].mean(), 2))\n",
        "    #print(\"VALUES------------\")\n",
        "    print(values)\n",
        "        \n",
        "    #Combining tickers and values into new dataframe\n",
        "    #df = pd.DataFrame(list(zip(tickers, values)), columns =['Ticker', 'Mean Sentiment']) \n",
        "    #df = df.set_index('Ticker')\n",
        "    #df = df.sort_values('date', ascending=False)\n",
        "    if printOut:\n",
        "        print(\"-----------DF\")\n",
        "        #print(df.head())\n",
        "        #print(df.shape)\n",
        "    #Returning the dataframe\n",
        "    return df\n",
        "    #if printOut:\n",
        "        #print ('\\n')\n",
        "        #display (df)\n",
        "    #return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Date\n",
            "2022-11-30    0.04\n",
            "2022-12-01    0.04\n",
            "2022-12-02    0.12\n",
            "2022-12-03   -0.06\n",
            "2022-12-04   -0.03\n",
            "2022-12-05    0.13\n",
            "2022-12-06   -0.07\n",
            "Name: compound, dtype: float64\n",
            "Empty DataFrame\n",
            "Columns: [Ticker, Date, Compound]\n",
            "Index: []\n",
            "-----------DF\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\Ishaan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#print(\"HISTORIC SENTIMENT\")\n",
        "HistoricSentiment = SentimentAnalysisNewsData(historic_news, True)\n",
        "#print(\"\\n\")\n",
        "#print(\"TODAYS SENTIMENT\")\n",
        "#TodaysSentiment = SentimentAnalysisNewsData(parsed_news)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating Dataset #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dataset for $AAPL\n",
            "Getting stock data for stock $AAPL\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "                  Open        High         Low  Close  Adj Close    Volume\n",
            "Date                                                                      \n",
            "2023-01-30  144.960007  145.550003  142.850006  143.0      143.0  63947600\n",
            "endDate is: 2023-01-29\n",
            "startDate is: 2022-11-30\n",
            "startDate is: 20221130T0130\n",
            "endDate is: 20230129T0130\n",
            "           Date                                           Headline Ticker\n",
            "0    2022-11-30  Market Volatility Eases Slightly Following Hop...   AAPL\n",
            "1    2022-11-30  Fraud Detection and Prevention Market Size [20...   AAPL\n",
            "2    2022-11-30  Smart Investors Should Buy These 3 Stocks, Dow...   AAPL\n",
            "3    2022-11-30  Mindfulness Meditation Application Market to R...   AAPL\n",
            "4    2022-11-30  3 Reasons I'm Avoiding Meta Platforms Stock Fo...   AAPL\n",
            "..          ...                                                ...    ...\n",
            "195  2022-12-06  Here is What to Know Beyond Why Apple Inc.  ( ...   AAPL\n",
            "196  2022-12-06  Billionaire Mark Cuban Becomes Elon Musk's Mos...   AAPL\n",
            "197  2022-12-06  Taiwan Semiconductor Boosts US Investment Afte...   AAPL\n",
            "198  2022-12-06  4 Stocks You'll Regret Not Buying at Their Cur...   AAPL\n",
            "199  2022-12-06  Dow Jones Slips; Microsoft Ups Battle For Acti...   AAPL\n",
            "\n",
            "[200 rows x 3 columns]\n",
            "Date\n",
            "2022-11-30    0.04\n",
            "2022-12-01    0.04\n",
            "2022-12-02    0.12\n",
            "2022-12-03   -0.06\n",
            "2022-12-04   -0.03\n",
            "2022-12-05    0.13\n",
            "2022-12-06   -0.07\n",
            "Name: compound, dtype: float64\n",
            "Empty DataFrame\n",
            "Columns: [Ticker, Date, Compound]\n",
            "Index: []\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\Ishaan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "def createDataset(date_from, int):\n",
        "    for i in tickers:\n",
        "        print(\"Creating dataset for $\" +i)\n",
        "        #Get historic stock data\n",
        "        historic_stock = getMonthlyStockData(i, interval = int)\n",
        "        print(historic_stock.head())\n",
        "        #Get historic news data\n",
        "        historic_news = getHistoricNewsData(i, interval = int)\n",
        "        print(historic_news)\n",
        "        #Use news to get sentiment\n",
        "        HistoricSentiment = SentimentAnalysisNewsData(historic_news)\n",
        "        print(HistoricSentiment.shape)\n",
        "        #Merge as training set\n",
        "        #Get today's stock data\n",
        "        #Get today's news data\n",
        "        #Use news to get sentiment\n",
        "\n",
        "\n",
        "createDataset('2022-10-10', '2mo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO2ChGGwJkijmmb0vDcCR40",
      "include_colab_link": true,
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
