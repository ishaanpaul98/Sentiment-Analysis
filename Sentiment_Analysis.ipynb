{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishaanpaul98/Sentiment-Analysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "pGQVQfr0b3SS"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen, Request\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "import time\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "WSgZEvuikgTn"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "9hbdUWDKkgv_"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Eqvj106lkgyU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stock Data Helper Functions #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting stock data for stock $AAPL\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-21</th>\n",
              "      <td>132.979996</td>\n",
              "      <td>136.809998</td>\n",
              "      <td>132.750000</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>85928000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-22</th>\n",
              "      <td>134.350006</td>\n",
              "      <td>134.559998</td>\n",
              "      <td>130.300003</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>77852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-23</th>\n",
              "      <td>130.919998</td>\n",
              "      <td>132.419998</td>\n",
              "      <td>129.639999</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>63814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>131.380005</td>\n",
              "      <td>131.410004</td>\n",
              "      <td>128.720001</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>69007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>129.669998</td>\n",
              "      <td>131.029999</td>\n",
              "      <td>125.870003</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>85438400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>127.989998</td>\n",
              "      <td>130.479996</td>\n",
              "      <td>127.730003</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>75703700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>128.410004</td>\n",
              "      <td>129.949997</td>\n",
              "      <td>127.430000</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>76960600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>130.279999</td>\n",
              "      <td>130.899994</td>\n",
              "      <td>124.169998</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>112117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>126.889999</td>\n",
              "      <td>128.660004</td>\n",
              "      <td>125.080002</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>89113600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>127.129997</td>\n",
              "      <td>127.769997</td>\n",
              "      <td>124.760002</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>80962700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>126.010002</td>\n",
              "      <td>130.289993</td>\n",
              "      <td>124.889999</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>87686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>130.470001</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>129.889999</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>70790800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-10</th>\n",
              "      <td>130.259995</td>\n",
              "      <td>131.259995</td>\n",
              "      <td>128.119995</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>63896200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-11</th>\n",
              "      <td>131.250000</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>130.460007</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>69458900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-12</th>\n",
              "      <td>133.880005</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>71379600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-13</th>\n",
              "      <td>132.029999</td>\n",
              "      <td>134.919998</td>\n",
              "      <td>131.660004</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>57758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17</th>\n",
              "      <td>134.830002</td>\n",
              "      <td>137.289993</td>\n",
              "      <td>134.130005</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>63646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-18</th>\n",
              "      <td>136.820007</td>\n",
              "      <td>138.610001</td>\n",
              "      <td>135.029999</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>69672800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-19</th>\n",
              "      <td>134.080002</td>\n",
              "      <td>136.250000</td>\n",
              "      <td>133.770004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>58280400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20</th>\n",
              "      <td>135.279999</td>\n",
              "      <td>138.020004</td>\n",
              "      <td>134.220001</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>79972200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-23</th>\n",
              "      <td>138.119995</td>\n",
              "      <td>143.320007</td>\n",
              "      <td>137.899994</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>81760300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-24</th>\n",
              "      <td>140.309998</td>\n",
              "      <td>143.160004</td>\n",
              "      <td>140.300003</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>66435100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-25</th>\n",
              "      <td>140.889999</td>\n",
              "      <td>142.429993</td>\n",
              "      <td>138.809998</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>65799300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-26</th>\n",
              "      <td>143.169998</td>\n",
              "      <td>144.250000</td>\n",
              "      <td>141.899994</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>54105100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-27</th>\n",
              "      <td>143.160004</td>\n",
              "      <td>147.229996</td>\n",
              "      <td>143.080002</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>70492800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-30</th>\n",
              "      <td>144.960007</td>\n",
              "      <td>145.550003</td>\n",
              "      <td>142.850006</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>64015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-31</th>\n",
              "      <td>142.699997</td>\n",
              "      <td>144.339996</td>\n",
              "      <td>142.279999</td>\n",
              "      <td>144.289993</td>\n",
              "      <td>144.289993</td>\n",
              "      <td>65874500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-01</th>\n",
              "      <td>143.970001</td>\n",
              "      <td>146.610001</td>\n",
              "      <td>141.320007</td>\n",
              "      <td>145.429993</td>\n",
              "      <td>145.429993</td>\n",
              "      <td>77663600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-02</th>\n",
              "      <td>148.899994</td>\n",
              "      <td>151.179993</td>\n",
              "      <td>148.169998</td>\n",
              "      <td>150.820007</td>\n",
              "      <td>150.820007</td>\n",
              "      <td>118339000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-03</th>\n",
              "      <td>148.029999</td>\n",
              "      <td>157.380005</td>\n",
              "      <td>147.830002</td>\n",
              "      <td>154.500000</td>\n",
              "      <td>154.500000</td>\n",
              "      <td>154279900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-06</th>\n",
              "      <td>152.574997</td>\n",
              "      <td>153.100006</td>\n",
              "      <td>150.779999</td>\n",
              "      <td>151.729996</td>\n",
              "      <td>151.729996</td>\n",
              "      <td>67990412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High         Low       Close   Adj Close  \\\n",
              "Date                                                                     \n",
              "2022-12-21  132.979996  136.809998  132.750000  135.449997  135.449997   \n",
              "2022-12-22  134.350006  134.559998  130.300003  132.229996  132.229996   \n",
              "2022-12-23  130.919998  132.419998  129.639999  131.860001  131.860001   \n",
              "2022-12-27  131.380005  131.410004  128.720001  130.029999  130.029999   \n",
              "2022-12-28  129.669998  131.029999  125.870003  126.040001  126.040001   \n",
              "2022-12-29  127.989998  130.479996  127.730003  129.610001  129.610001   \n",
              "2022-12-30  128.410004  129.949997  127.430000  129.929993  129.929993   \n",
              "2023-01-03  130.279999  130.899994  124.169998  125.070000  125.070000   \n",
              "2023-01-04  126.889999  128.660004  125.080002  126.360001  126.360001   \n",
              "2023-01-05  127.129997  127.769997  124.760002  125.019997  125.019997   \n",
              "2023-01-06  126.010002  130.289993  124.889999  129.619995  129.619995   \n",
              "2023-01-09  130.470001  133.410004  129.889999  130.149994  130.149994   \n",
              "2023-01-10  130.259995  131.259995  128.119995  130.729996  130.729996   \n",
              "2023-01-11  131.250000  133.509995  130.460007  133.490005  133.490005   \n",
              "2023-01-12  133.880005  134.259995  131.440002  133.410004  133.410004   \n",
              "2023-01-13  132.029999  134.919998  131.660004  134.759995  134.759995   \n",
              "2023-01-17  134.830002  137.289993  134.130005  135.940002  135.940002   \n",
              "2023-01-18  136.820007  138.610001  135.029999  135.210007  135.210007   \n",
              "2023-01-19  134.080002  136.250000  133.770004  135.270004  135.270004   \n",
              "2023-01-20  135.279999  138.020004  134.220001  137.869995  137.869995   \n",
              "2023-01-23  138.119995  143.320007  137.899994  141.110001  141.110001   \n",
              "2023-01-24  140.309998  143.160004  140.300003  142.529999  142.529999   \n",
              "2023-01-25  140.889999  142.429993  138.809998  141.860001  141.860001   \n",
              "2023-01-26  143.169998  144.250000  141.899994  143.960007  143.960007   \n",
              "2023-01-27  143.160004  147.229996  143.080002  145.929993  145.929993   \n",
              "2023-01-30  144.960007  145.550003  142.850006  143.000000  143.000000   \n",
              "2023-01-31  142.699997  144.339996  142.279999  144.289993  144.289993   \n",
              "2023-02-01  143.970001  146.610001  141.320007  145.429993  145.429993   \n",
              "2023-02-02  148.899994  151.179993  148.169998  150.820007  150.820007   \n",
              "2023-02-03  148.029999  157.380005  147.830002  154.500000  154.500000   \n",
              "2023-02-06  152.574997  153.100006  150.779999  151.729996  151.729996   \n",
              "\n",
              "               Volume  \n",
              "Date                   \n",
              "2022-12-21   85928000  \n",
              "2022-12-22   77852100  \n",
              "2022-12-23   63814900  \n",
              "2022-12-27   69007800  \n",
              "2022-12-28   85438400  \n",
              "2022-12-29   75703700  \n",
              "2022-12-30   76960600  \n",
              "2023-01-03  112117500  \n",
              "2023-01-04   89113600  \n",
              "2023-01-05   80962700  \n",
              "2023-01-06   87686600  \n",
              "2023-01-09   70790800  \n",
              "2023-01-10   63896200  \n",
              "2023-01-11   69458900  \n",
              "2023-01-12   71379600  \n",
              "2023-01-13   57758000  \n",
              "2023-01-17   63646600  \n",
              "2023-01-18   69672800  \n",
              "2023-01-19   58280400  \n",
              "2023-01-20   79972200  \n",
              "2023-01-23   81760300  \n",
              "2023-01-24   66435100  \n",
              "2023-01-25   65799300  \n",
              "2023-01-26   54105100  \n",
              "2023-01-27   70492800  \n",
              "2023-01-30   64015300  \n",
              "2023-01-31   65874500  \n",
              "2023-02-01   77663600  \n",
              "2023-02-02  118339000  \n",
              "2023-02-03  154279900  \n",
              "2023-02-06   67990412  "
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getStockDataDaily(symbol, day):\n",
        "    print(\"Getting stock data for stock $\"+symbol)\n",
        "    df = yf.download(symbol, start=day, period = \"1d\")\n",
        "    return df\n",
        "\n",
        "getStockDataDaily('AAPL', \"2022-12-21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "def arrayToString(arr):\n",
        "    print(\"Starting array to list\")\n",
        "    listToStr = ' '.join([str(elem) for elem in arr])\n",
        "    return listToStr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of symbols array is more than 1. STARTING ARRAYTOSTRING\n",
            "Starting array to list\n",
            "Getting stock data for stock $AAPL TSLA\n",
            "[*********************100%***********************]  2 of 2 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">TSLA</th>\n",
              "      <th colspan=\"6\" halign=\"left\">AAPL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-21</th>\n",
              "      <td>139.339996</td>\n",
              "      <td>141.259995</td>\n",
              "      <td>135.889999</td>\n",
              "      <td>137.570007</td>\n",
              "      <td>137.570007</td>\n",
              "      <td>145417400</td>\n",
              "      <td>132.979996</td>\n",
              "      <td>136.809998</td>\n",
              "      <td>132.750000</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>85928000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-22</th>\n",
              "      <td>136.000000</td>\n",
              "      <td>136.630005</td>\n",
              "      <td>122.260002</td>\n",
              "      <td>125.349998</td>\n",
              "      <td>125.349998</td>\n",
              "      <td>210090300</td>\n",
              "      <td>134.350006</td>\n",
              "      <td>134.559998</td>\n",
              "      <td>130.300003</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>77852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-23</th>\n",
              "      <td>126.370003</td>\n",
              "      <td>128.619995</td>\n",
              "      <td>121.019997</td>\n",
              "      <td>123.150002</td>\n",
              "      <td>123.150002</td>\n",
              "      <td>166989700</td>\n",
              "      <td>130.919998</td>\n",
              "      <td>132.419998</td>\n",
              "      <td>129.639999</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>63814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>117.500000</td>\n",
              "      <td>119.669998</td>\n",
              "      <td>108.760002</td>\n",
              "      <td>109.099998</td>\n",
              "      <td>109.099998</td>\n",
              "      <td>208643400</td>\n",
              "      <td>131.380005</td>\n",
              "      <td>131.410004</td>\n",
              "      <td>128.720001</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>69007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>110.349998</td>\n",
              "      <td>116.269997</td>\n",
              "      <td>108.239998</td>\n",
              "      <td>112.709999</td>\n",
              "      <td>112.709999</td>\n",
              "      <td>221070500</td>\n",
              "      <td>129.669998</td>\n",
              "      <td>131.029999</td>\n",
              "      <td>125.870003</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>85438400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>120.389999</td>\n",
              "      <td>123.570000</td>\n",
              "      <td>117.500000</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>221923300</td>\n",
              "      <td>127.989998</td>\n",
              "      <td>130.479996</td>\n",
              "      <td>127.730003</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>75703700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>119.949997</td>\n",
              "      <td>124.480003</td>\n",
              "      <td>119.750000</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>157304500</td>\n",
              "      <td>128.410004</td>\n",
              "      <td>129.949997</td>\n",
              "      <td>127.430000</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>76960600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>118.470001</td>\n",
              "      <td>118.800003</td>\n",
              "      <td>104.639999</td>\n",
              "      <td>108.099998</td>\n",
              "      <td>108.099998</td>\n",
              "      <td>231402800</td>\n",
              "      <td>130.279999</td>\n",
              "      <td>130.899994</td>\n",
              "      <td>124.169998</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>112117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>109.110001</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>113.639999</td>\n",
              "      <td>113.639999</td>\n",
              "      <td>180389000</td>\n",
              "      <td>126.889999</td>\n",
              "      <td>128.660004</td>\n",
              "      <td>125.080002</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>89113600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>110.510002</td>\n",
              "      <td>111.750000</td>\n",
              "      <td>107.160004</td>\n",
              "      <td>110.339996</td>\n",
              "      <td>110.339996</td>\n",
              "      <td>157986300</td>\n",
              "      <td>127.129997</td>\n",
              "      <td>127.769997</td>\n",
              "      <td>124.760002</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>80962700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>103.000000</td>\n",
              "      <td>114.389999</td>\n",
              "      <td>101.809998</td>\n",
              "      <td>113.059998</td>\n",
              "      <td>113.059998</td>\n",
              "      <td>220575900</td>\n",
              "      <td>126.010002</td>\n",
              "      <td>130.289993</td>\n",
              "      <td>124.889999</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>87686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>118.959999</td>\n",
              "      <td>123.519997</td>\n",
              "      <td>117.110001</td>\n",
              "      <td>119.769997</td>\n",
              "      <td>119.769997</td>\n",
              "      <td>190284000</td>\n",
              "      <td>130.470001</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>129.889999</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>70790800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-10</th>\n",
              "      <td>121.070000</td>\n",
              "      <td>122.760002</td>\n",
              "      <td>114.919998</td>\n",
              "      <td>118.849998</td>\n",
              "      <td>118.849998</td>\n",
              "      <td>167642500</td>\n",
              "      <td>130.259995</td>\n",
              "      <td>131.259995</td>\n",
              "      <td>128.119995</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>63896200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-11</th>\n",
              "      <td>122.089996</td>\n",
              "      <td>125.949997</td>\n",
              "      <td>120.510002</td>\n",
              "      <td>123.220001</td>\n",
              "      <td>123.220001</td>\n",
              "      <td>183810800</td>\n",
              "      <td>131.250000</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>130.460007</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>69458900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-12</th>\n",
              "      <td>122.559998</td>\n",
              "      <td>124.129997</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>123.559998</td>\n",
              "      <td>123.559998</td>\n",
              "      <td>169400900</td>\n",
              "      <td>133.880005</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>71379600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-13</th>\n",
              "      <td>116.550003</td>\n",
              "      <td>122.629997</td>\n",
              "      <td>115.599998</td>\n",
              "      <td>122.400002</td>\n",
              "      <td>122.400002</td>\n",
              "      <td>180439300</td>\n",
              "      <td>132.029999</td>\n",
              "      <td>134.919998</td>\n",
              "      <td>131.660004</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>57758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17</th>\n",
              "      <td>125.699997</td>\n",
              "      <td>131.699997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>131.490005</td>\n",
              "      <td>131.490005</td>\n",
              "      <td>186477000</td>\n",
              "      <td>134.830002</td>\n",
              "      <td>137.289993</td>\n",
              "      <td>134.130005</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>63646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-18</th>\n",
              "      <td>136.559998</td>\n",
              "      <td>136.679993</td>\n",
              "      <td>127.010002</td>\n",
              "      <td>128.779999</td>\n",
              "      <td>128.779999</td>\n",
              "      <td>195680300</td>\n",
              "      <td>136.820007</td>\n",
              "      <td>138.610001</td>\n",
              "      <td>135.029999</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>69672800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-19</th>\n",
              "      <td>127.260002</td>\n",
              "      <td>129.990005</td>\n",
              "      <td>124.309998</td>\n",
              "      <td>127.169998</td>\n",
              "      <td>127.169998</td>\n",
              "      <td>170291900</td>\n",
              "      <td>134.080002</td>\n",
              "      <td>136.250000</td>\n",
              "      <td>133.770004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>58280400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20</th>\n",
              "      <td>128.679993</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>127.349998</td>\n",
              "      <td>133.419998</td>\n",
              "      <td>133.419998</td>\n",
              "      <td>138429900</td>\n",
              "      <td>135.279999</td>\n",
              "      <td>138.020004</td>\n",
              "      <td>134.220001</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>79972200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-23</th>\n",
              "      <td>135.869995</td>\n",
              "      <td>145.380005</td>\n",
              "      <td>134.270004</td>\n",
              "      <td>143.750000</td>\n",
              "      <td>143.750000</td>\n",
              "      <td>203119200</td>\n",
              "      <td>138.119995</td>\n",
              "      <td>143.320007</td>\n",
              "      <td>137.899994</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>81760300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-24</th>\n",
              "      <td>143.000000</td>\n",
              "      <td>146.500000</td>\n",
              "      <td>141.100006</td>\n",
              "      <td>143.889999</td>\n",
              "      <td>143.889999</td>\n",
              "      <td>158699100</td>\n",
              "      <td>140.309998</td>\n",
              "      <td>143.160004</td>\n",
              "      <td>140.300003</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>66435100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-25</th>\n",
              "      <td>141.910004</td>\n",
              "      <td>146.410004</td>\n",
              "      <td>138.070007</td>\n",
              "      <td>144.429993</td>\n",
              "      <td>144.429993</td>\n",
              "      <td>192734300</td>\n",
              "      <td>140.889999</td>\n",
              "      <td>142.429993</td>\n",
              "      <td>138.809998</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>65799300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-26</th>\n",
              "      <td>159.970001</td>\n",
              "      <td>161.419998</td>\n",
              "      <td>154.759995</td>\n",
              "      <td>160.270004</td>\n",
              "      <td>160.270004</td>\n",
              "      <td>234815100</td>\n",
              "      <td>143.169998</td>\n",
              "      <td>144.250000</td>\n",
              "      <td>141.899994</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>54105100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-27</th>\n",
              "      <td>162.429993</td>\n",
              "      <td>180.679993</td>\n",
              "      <td>161.169998</td>\n",
              "      <td>177.899994</td>\n",
              "      <td>177.899994</td>\n",
              "      <td>305632100</td>\n",
              "      <td>143.160004</td>\n",
              "      <td>147.229996</td>\n",
              "      <td>143.080002</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>70492800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-30</th>\n",
              "      <td>178.050003</td>\n",
              "      <td>179.770004</td>\n",
              "      <td>166.500000</td>\n",
              "      <td>166.660004</td>\n",
              "      <td>166.660004</td>\n",
              "      <td>230878800</td>\n",
              "      <td>144.960007</td>\n",
              "      <td>145.550003</td>\n",
              "      <td>142.850006</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>64015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-31</th>\n",
              "      <td>164.570007</td>\n",
              "      <td>174.300003</td>\n",
              "      <td>162.779999</td>\n",
              "      <td>173.220001</td>\n",
              "      <td>173.220001</td>\n",
              "      <td>196813500</td>\n",
              "      <td>142.699997</td>\n",
              "      <td>144.339996</td>\n",
              "      <td>142.279999</td>\n",
              "      <td>144.289993</td>\n",
              "      <td>144.289993</td>\n",
              "      <td>65874500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-01</th>\n",
              "      <td>173.889999</td>\n",
              "      <td>183.809998</td>\n",
              "      <td>169.929993</td>\n",
              "      <td>181.410004</td>\n",
              "      <td>181.410004</td>\n",
              "      <td>213806300</td>\n",
              "      <td>143.970001</td>\n",
              "      <td>146.610001</td>\n",
              "      <td>141.320007</td>\n",
              "      <td>145.429993</td>\n",
              "      <td>145.429993</td>\n",
              "      <td>77663600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-02</th>\n",
              "      <td>187.330002</td>\n",
              "      <td>196.750000</td>\n",
              "      <td>182.610001</td>\n",
              "      <td>188.270004</td>\n",
              "      <td>188.270004</td>\n",
              "      <td>217448300</td>\n",
              "      <td>148.899994</td>\n",
              "      <td>151.179993</td>\n",
              "      <td>148.169998</td>\n",
              "      <td>150.820007</td>\n",
              "      <td>150.820007</td>\n",
              "      <td>118339000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-03</th>\n",
              "      <td>183.949997</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>183.690002</td>\n",
              "      <td>189.979996</td>\n",
              "      <td>189.979996</td>\n",
              "      <td>231684200</td>\n",
              "      <td>148.029999</td>\n",
              "      <td>157.380005</td>\n",
              "      <td>147.830002</td>\n",
              "      <td>154.500000</td>\n",
              "      <td>154.500000</td>\n",
              "      <td>154279900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-06</th>\n",
              "      <td>193.009995</td>\n",
              "      <td>198.160004</td>\n",
              "      <td>189.919998</td>\n",
              "      <td>194.759995</td>\n",
              "      <td>194.759995</td>\n",
              "      <td>184368254</td>\n",
              "      <td>152.574997</td>\n",
              "      <td>153.100006</td>\n",
              "      <td>150.779999</td>\n",
              "      <td>151.729996</td>\n",
              "      <td>151.729996</td>\n",
              "      <td>67990412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  TSLA                                                  \\\n",
              "                  Open        High         Low       Close   Adj Close   \n",
              "Date                                                                     \n",
              "2022-12-21  139.339996  141.259995  135.889999  137.570007  137.570007   \n",
              "2022-12-22  136.000000  136.630005  122.260002  125.349998  125.349998   \n",
              "2022-12-23  126.370003  128.619995  121.019997  123.150002  123.150002   \n",
              "2022-12-27  117.500000  119.669998  108.760002  109.099998  109.099998   \n",
              "2022-12-28  110.349998  116.269997  108.239998  112.709999  112.709999   \n",
              "2022-12-29  120.389999  123.570000  117.500000  121.820000  121.820000   \n",
              "2022-12-30  119.949997  124.480003  119.750000  123.180000  123.180000   \n",
              "2023-01-03  118.470001  118.800003  104.639999  108.099998  108.099998   \n",
              "2023-01-04  109.110001  114.589996  107.519997  113.639999  113.639999   \n",
              "2023-01-05  110.510002  111.750000  107.160004  110.339996  110.339996   \n",
              "2023-01-06  103.000000  114.389999  101.809998  113.059998  113.059998   \n",
              "2023-01-09  118.959999  123.519997  117.110001  119.769997  119.769997   \n",
              "2023-01-10  121.070000  122.760002  114.919998  118.849998  118.849998   \n",
              "2023-01-11  122.089996  125.949997  120.510002  123.220001  123.220001   \n",
              "2023-01-12  122.559998  124.129997  117.000000  123.559998  123.559998   \n",
              "2023-01-13  116.550003  122.629997  115.599998  122.400002  122.400002   \n",
              "2023-01-17  125.699997  131.699997  125.019997  131.490005  131.490005   \n",
              "2023-01-18  136.559998  136.679993  127.010002  128.779999  128.779999   \n",
              "2023-01-19  127.260002  129.990005  124.309998  127.169998  127.169998   \n",
              "2023-01-20  128.679993  133.509995  127.349998  133.419998  133.419998   \n",
              "2023-01-23  135.869995  145.380005  134.270004  143.750000  143.750000   \n",
              "2023-01-24  143.000000  146.500000  141.100006  143.889999  143.889999   \n",
              "2023-01-25  141.910004  146.410004  138.070007  144.429993  144.429993   \n",
              "2023-01-26  159.970001  161.419998  154.759995  160.270004  160.270004   \n",
              "2023-01-27  162.429993  180.679993  161.169998  177.899994  177.899994   \n",
              "2023-01-30  178.050003  179.770004  166.500000  166.660004  166.660004   \n",
              "2023-01-31  164.570007  174.300003  162.779999  173.220001  173.220001   \n",
              "2023-02-01  173.889999  183.809998  169.929993  181.410004  181.410004   \n",
              "2023-02-02  187.330002  196.750000  182.610001  188.270004  188.270004   \n",
              "2023-02-03  183.949997  199.000000  183.690002  189.979996  189.979996   \n",
              "2023-02-06  193.009995  198.160004  189.919998  194.759995  194.759995   \n",
              "\n",
              "                             AAPL                                      \\\n",
              "               Volume        Open        High         Low       Close   \n",
              "Date                                                                    \n",
              "2022-12-21  145417400  132.979996  136.809998  132.750000  135.449997   \n",
              "2022-12-22  210090300  134.350006  134.559998  130.300003  132.229996   \n",
              "2022-12-23  166989700  130.919998  132.419998  129.639999  131.860001   \n",
              "2022-12-27  208643400  131.380005  131.410004  128.720001  130.029999   \n",
              "2022-12-28  221070500  129.669998  131.029999  125.870003  126.040001   \n",
              "2022-12-29  221923300  127.989998  130.479996  127.730003  129.610001   \n",
              "2022-12-30  157304500  128.410004  129.949997  127.430000  129.929993   \n",
              "2023-01-03  231402800  130.279999  130.899994  124.169998  125.070000   \n",
              "2023-01-04  180389000  126.889999  128.660004  125.080002  126.360001   \n",
              "2023-01-05  157986300  127.129997  127.769997  124.760002  125.019997   \n",
              "2023-01-06  220575900  126.010002  130.289993  124.889999  129.619995   \n",
              "2023-01-09  190284000  130.470001  133.410004  129.889999  130.149994   \n",
              "2023-01-10  167642500  130.259995  131.259995  128.119995  130.729996   \n",
              "2023-01-11  183810800  131.250000  133.509995  130.460007  133.490005   \n",
              "2023-01-12  169400900  133.880005  134.259995  131.440002  133.410004   \n",
              "2023-01-13  180439300  132.029999  134.919998  131.660004  134.759995   \n",
              "2023-01-17  186477000  134.830002  137.289993  134.130005  135.940002   \n",
              "2023-01-18  195680300  136.820007  138.610001  135.029999  135.210007   \n",
              "2023-01-19  170291900  134.080002  136.250000  133.770004  135.270004   \n",
              "2023-01-20  138429900  135.279999  138.020004  134.220001  137.869995   \n",
              "2023-01-23  203119200  138.119995  143.320007  137.899994  141.110001   \n",
              "2023-01-24  158699100  140.309998  143.160004  140.300003  142.529999   \n",
              "2023-01-25  192734300  140.889999  142.429993  138.809998  141.860001   \n",
              "2023-01-26  234815100  143.169998  144.250000  141.899994  143.960007   \n",
              "2023-01-27  305632100  143.160004  147.229996  143.080002  145.929993   \n",
              "2023-01-30  230878800  144.960007  145.550003  142.850006  143.000000   \n",
              "2023-01-31  196813500  142.699997  144.339996  142.279999  144.289993   \n",
              "2023-02-01  213806300  143.970001  146.610001  141.320007  145.429993   \n",
              "2023-02-02  217448300  148.899994  151.179993  148.169998  150.820007   \n",
              "2023-02-03  231684200  148.029999  157.380005  147.830002  154.500000   \n",
              "2023-02-06  184368254  152.574997  153.100006  150.779999  151.729996   \n",
              "\n",
              "                                   \n",
              "             Adj Close     Volume  \n",
              "Date                               \n",
              "2022-12-21  135.449997   85928000  \n",
              "2022-12-22  132.229996   77852100  \n",
              "2022-12-23  131.860001   63814900  \n",
              "2022-12-27  130.029999   69007800  \n",
              "2022-12-28  126.040001   85438400  \n",
              "2022-12-29  129.610001   75703700  \n",
              "2022-12-30  129.929993   76960600  \n",
              "2023-01-03  125.070000  112117500  \n",
              "2023-01-04  126.360001   89113600  \n",
              "2023-01-05  125.019997   80962700  \n",
              "2023-01-06  129.619995   87686600  \n",
              "2023-01-09  130.149994   70790800  \n",
              "2023-01-10  130.729996   63896200  \n",
              "2023-01-11  133.490005   69458900  \n",
              "2023-01-12  133.410004   71379600  \n",
              "2023-01-13  134.759995   57758000  \n",
              "2023-01-17  135.940002   63646600  \n",
              "2023-01-18  135.210007   69672800  \n",
              "2023-01-19  135.270004   58280400  \n",
              "2023-01-20  137.869995   79972200  \n",
              "2023-01-23  141.110001   81760300  \n",
              "2023-01-24  142.529999   66435100  \n",
              "2023-01-25  141.860001   65799300  \n",
              "2023-01-26  143.960007   54105100  \n",
              "2023-01-27  145.929993   70492800  \n",
              "2023-01-30  143.000000   64015300  \n",
              "2023-01-31  144.289993   65874500  \n",
              "2023-02-01  145.429993   77663600  \n",
              "2023-02-02  150.820007  118339000  \n",
              "2023-02-03  154.500000  154279900  \n",
              "2023-02-06  151.729996   67990412  "
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getMultiStockDataDaily(symbols, day):\n",
        "    if len(symbols) > 1:\n",
        "        print(\"Length of symbols array is more than 1. STARTING ARRAYTOSTRING\")\n",
        "        symbols = arrayToString(symbols)\n",
        "    print(\"Getting stock data for stock $\"+symbols)\n",
        "    df = yf.download(symbols, start=day, period = \"1d\", group_by='ticker')\n",
        "    return df\n",
        "\n",
        "getMultiStockDataDaily(['AAPL', 'TSLA'], \"2022-12-21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getMonthlyStockData(symbol, day = datetime.date.today() - datetime.timedelta(days = 1), interval = '1mo'):\n",
        "    print(\"Getting stock data for stock $\"+symbol)\n",
        "    df = yf.download(symbol, start=day, period = interval, group_by='ticker')\n",
        "    return df\n",
        "\n",
        "#getMonthlyStockData('AAPL', \"2022-11-21\", '1mo')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathering FinViz Data (Today's News) #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters \n",
        "n = 3 #the # of article headlines displayed per ticker\n",
        "tickers = ['AAPL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'news':        Date                                              Title  \\\n",
              " 0   07:26PM  Adani Group still eligible for CEMBI, JACI, JE...   \n",
              " 1   07:21PM  Disney's Reedy Creek Improvement District to g...   \n",
              " 2   07:05PM   Stocks moving after hours: Chegg, Blizzard, more   \n",
              " 3   07:04PM  One in five homes have not cashed energy vouchers   \n",
              " 4   07:03PM  Stocks End Lower as Investors Ponder Fed Rate ...   \n",
              " ..      ...                                                ...   \n",
              " 85  07:49AM  Stocks making the biggest moves premarket: Tys...   \n",
              " 86  07:47AM  Tyson Foods misses profit estimates as lower b...   \n",
              " 87  07:37AM     Stocks Poised for Losses, Treasury Yields Rise   \n",
              " 88  07:27AM  India Government Plans to Oppose Vedanta Zinc ...   \n",
              " 89  07:24AM  Former UK PM Liz Truss is blaming the left-win...   \n",
              " \n",
              "                Source                                               Link  \n",
              " 0     www.reuters.com  https://www.reuters.com/business/adani-group-s...  \n",
              " 1     foxbusiness.com  https://foxbusiness.com/markets/disney-reedy-c...  \n",
              " 2   finance.yahoo.com  https://finance.yahoo.com/news/stocks-moving-i...  \n",
              " 3       www.bbc.co.uk  https://www.bbc.co.uk/news/business-64541204?a...  \n",
              " 4         www.wsj.com  https://www.wsj.com/articles/global-stocks-mar...  \n",
              " ..                ...                                                ...  \n",
              " 85       www.cnbc.com  https://www.cnbc.com/2023/02/06/stocks-making-...  \n",
              " 86    www.reuters.com  https://www.reuters.com/business/tyson-foods-m...  \n",
              " 87        www.wsj.com  https://www.wsj.com/articles/global-stocks-mar...  \n",
              " 88  www.bloomberg.com  https://www.bloomberg.com/news/articles/2023-0...  \n",
              " 89       www.cnbc.com  https://www.cnbc.com/2023/02/06/former-uk-pm-l...  \n",
              " \n",
              " [90 rows x 4 columns],\n",
              " 'blogs':        Date                                              Title  \\\n",
              " 0   07:15PM                  Tentative steps lower for markets   \n",
              " 1   07:10PM  Fed Survey: Banks reported Tighter Standards, ...   \n",
              " 2   06:50PM                             The 5% Solution - Cash   \n",
              " 3   05:40PM  Peter Schiff: The Fed Can't Fight What It Does...   \n",
              " 4   05:09PM  Bed Bath & Beyond Belief: 'Bankrupt' Retailer ...   \n",
              " ..      ...                                                ...   \n",
              " 85   Dec-25  Evidence-Based Spirituality:  Finding Personal...   \n",
              " 86   Dec-18                           Your Mental Sharpe Ratio   \n",
              " 87   Dec-06   The Three Essential Sources of Your Trading Edge   \n",
              " 88   Nov-24                                Trading Consciously   \n",
              " 89   May-21  New Issue Now Available: What Hedge Funds Boug...   \n",
              " \n",
              "                           Source  \\\n",
              " 0   www.markets.fallondpicks.com   \n",
              " 1     www.calculatedriskblog.com   \n",
              " 2               seekingalpha.com   \n",
              " 3              www.zerohedge.com   \n",
              " 4              www.zerohedge.com   \n",
              " ..                           ...   \n",
              " 85       traderfeed.blogspot.com   \n",
              " 86       traderfeed.blogspot.com   \n",
              " 87       traderfeed.blogspot.com   \n",
              " 88       traderfeed.blogspot.com   \n",
              " 89           www.marketfolly.com   \n",
              " \n",
              "                                                  Link  \n",
              " 0   https://www.markets.fallondpicks.com/2023/02/t...  \n",
              " 1   http://www.calculatedriskblog.com/2023/02/fed-...  \n",
              " 2   https://seekingalpha.com/article/4575723-the-5...  \n",
              " 3   https://www.zerohedge.com/markets/peter-schiff...  \n",
              " 4   https://www.zerohedge.com/markets/bed-bath-bey...  \n",
              " ..                                                ...  \n",
              " 85  http://traderfeed.blogspot.com/2022/12/evidenc...  \n",
              " 86  http://traderfeed.blogspot.com/2022/12/your-me...  \n",
              " 87  http://traderfeed.blogspot.com/2022/12/the-thr...  \n",
              " 88  http://traderfeed.blogspot.com/2022/11/trading...  \n",
              " 89  http://www.marketfolly.com/2022/05/new-issue-n...  \n",
              " \n",
              " [90 rows x 4 columns]}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from finvizfinance.news import News\n",
        "fnews = News()\n",
        "all_news = fnews.get_news()\n",
        "all_news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current url is: https://finviz.com/quote.ashx?t=AAPL\n",
            "\n",
            "\n",
            "Recent News Headlines for AAPL: \n",
            "Why Taiwan Semiconductor Manufacturing Is Falling Today ( Feb-06-23 11:14AM )\n",
            "Stock market today: Dow slips as Treasury yields jump to dent tech; Powell eyed ( 11:04AM )\n",
            "Apple iPhone 14 being sold at discount in China: Report ( 11:00AM )\n"
          ]
        }
      ],
      "source": [
        "# Get Data\n",
        "finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
        "news_tables = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    url = finwiz_url + ticker\n",
        "    print(\"current url is: \" +url)\n",
        "    header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36.\"}\n",
        "    req = Request(url=url,headers=header) \n",
        "    resp = urlopen(req)    \n",
        "    html = BeautifulSoup(resp, features=\"lxml\")\n",
        "    news_table = html.find(id='news-table')\n",
        "    news_tables[ticker] = news_table\n",
        "\n",
        "try:\n",
        "    for ticker in tickers:\n",
        "        df = news_tables[ticker]\n",
        "        df_tr = df.findAll('tr')\n",
        "    \n",
        "        print ('\\n')\n",
        "        print ('Recent News Headlines for {}: '.format(ticker))\n",
        "        \n",
        "        for i, table_row in enumerate(df_tr):\n",
        "            a_text = table_row.a.text\n",
        "            td_text = table_row.td.text\n",
        "            td_text = td_text.strip()\n",
        "            print(a_text,'(',td_text,')')\n",
        "            if i == n-1:\n",
        "                break\n",
        "except KeyError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['AAPL', 'Feb-06-23', '11:14AM', 'Feb-06-23 11:14AMWhy Taiwan Semiconductor Manufacturing Is Falling Today Motley Fool'], ['AAPL', 'Feb-06-23', '11:04AM', '11:04AMStock market today: Dow slips as Treasury yields jump to dent tech; Powell eyed Investing.com'], ['AAPL', 'Feb-06-23', '11:00AM', '11:00AMApple iPhone 14 being sold at discount in China: Report Yahoo Finance Video'], ['AAPL', 'Feb-06-23', '10:57AM', '10:57AM1 Supercharged Nasdaq Stock to Buy Hand Over Fist Before It Jumps Higher Motley Fool'], ['AAPL', 'Feb-06-23', '10:48AM', '10:48AMS&P 500 off lows but remains pressured as Fed jitters drive up Treasury yields Investing.com'], ['AAPL', 'Feb-06-23', '10:00AM', '\\n10:00AM\\nLoading…\\n'], ['AAPL', 'Feb-06-23', '10:00AM', '10:00AMApple Heads the Management Top 250 All-Stars The Wall Street Journal'], ['AAPL', 'Feb-06-23', '09:50AM', '09:50AMStocks open lower, Tesla stock climbs as Apple and Microsoft slide Yahoo Finance Video'], ['AAPL', 'Feb-06-23', '09:33AM', '09:33AMApples Latest iPhones Sell at $100-Plus Discounts in China Bloomberg'], ['AAPL', 'Feb-06-23', '09:32AM', '09:32AMCompany News for Feb 6, 2023 Zacks'], ['AAPL', 'Feb-06-23', '09:00AM', '09:00AMIs Trending Stock Apple Inc. (AAPL) a Buy Now? Zacks'], ['AAPL', 'Feb-06-23', '08:22AM', \"08:22AMApple's Chinese Retailers Use Discounts For Premium iPhones To Spur Demand, Analyst Snubs Move Benzinga\"], ['AAPL', 'Feb-06-23', '08:15AM', '08:15AM3 Stocks to Avoid This Week Motley Fool'], ['AAPL', 'Feb-06-23', '07:40AM', '07:40AM3 Stocks I Will Never Sell Motley Fool'], ['AAPL', 'Feb-06-23', '06:13AM', '06:13AMStock market is basically going nowhere for the rest of the year: Goldman Sachs Yahoo Finance'], ['AAPL', 'Feb-06-23', '05:08AM', '05:08AMWhy the red hot stock market is ripe for a cooldown: Morning Brief Yahoo Finance'], ['AAPL', 'Feb-06-23', '04:26AM', '\\n04:26AM\\nLoading…\\n'], ['AAPL', 'Feb-06-23', '04:26AM', '04:26AMAmazon, Alphabet, Apple, Meta and Microsoft are part of Zacks Earnings Preview Zacks'], ['AAPL', 'Feb-06-23', '12:40AM', \"12:40AMShakeup at AIG, Ryan Cohen's Nordstrom stake: Hedge funds and C-suites weekly Investing.com\"], ['AAPL', 'Feb-05-23', '10:42PM', 'Feb-05-23 10:42PMUPDATE 1-Retailers offering discounts on high-end iPhones in China Reuters'], ['AAPL', 'Feb-05-23', '10:23PM', '10:23PMRetailers offering discounts on high-end iPhones in China Reuters'], ['AAPL', 'Feb-05-23', '03:17PM', '03:17PMTech Earnings Werent Great. Stocks Are Soaring Anyway. Barrons.com'], ['AAPL', 'Feb-05-23', '10:31AM', '10:31AMTarget, Amazon and 4 More Retailers That Will Reward You for Turning in Your Old Stuff GOBankingRates'], ['AAPL', 'Feb-05-23', '07:07AM', '07:07AMApple First Quarter 2023 Earnings: Misses Expectations Simply Wall St.'], ['AAPL', 'Feb-05-23', '03:06AM', \"03:06AMUPDATE 1-Foxconn's January sales surge as China COVID disruption shaken off Reuters\"], ['AAPL', 'Feb-05-23', '02:52AM', \"02:52AMFoxconn's January sales surge as China COVID disruption shaken off Reuters\"], ['AAPL', 'Feb-05-23', '02:45AM', \"02:45AMFoxconn's January sales surge COVID disruption shaken off Reuters\"], ['AAPL', 'Feb-05-23', '12:00AM', '12:00AMApple blundered when it killed off Dark Sky Financial Times'], ['AAPL', 'Feb-04-23', '10:00AM', 'Feb-04-23 10:00AMThe Fed Is All That Matters to Stock Analysts Ignoring Earnings Bloomberg'], ['AAPL', 'Feb-04-23', '09:40AM', '09:40AMTech execs cant stop talking about AI after success of ChatGPT MarketWatch'], ['AAPL', 'Feb-03-23', '06:29PM', 'Feb-03-23 06:29PMWeekly Roundup TheStreet.com'], ['AAPL', 'Feb-03-23', '05:55PM', \"05:55PMIs Apple Stock A Buy After December-Quarter Earnings Miss? Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '05:53PM', '\\n05:53PM\\nLoading…\\n'], ['AAPL', 'Feb-03-23', '05:53PM', '05:53PMApple Earnings Miss, But the Stock Rallies Anyway Zacks'], ['AAPL', 'Feb-03-23', '05:33PM', '05:33PMTech Stocks Are Soaring Despite Weak Earnings. Heres What It Means. Barrons.com'], ['AAPL', 'Feb-03-23', '05:15PM', '05:15PMWhy Apple Stock Gained 11% in January Motley Fool'], ['AAPL', 'Feb-03-23', '04:27PM', '04:27PMTech Megacaps See Red as Earnings Disappoint Investopedia'], ['AAPL', 'Feb-03-23', '04:17PM', '04:17PMUS STOCKS-Wall Street ends down after stunning jobs growth raises Fed questions Reuters'], ['AAPL', 'Feb-03-23', '04:03PM', \"04:03PMApple Sees Improved Outlook; Here's How It's Helping The Stock Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '04:01PM', '04:01PMStock market news live updates: Stocks slide after jobs report shocks, Big Tech results disappoint Yahoo Finance'], ['AAPL', 'Feb-03-23', '04:00PM', '04:00PMUS STOCKS-Wall Street ends down after stunning jobs growth raises Fed questions Reuters'], ['AAPL', 'Feb-03-23', '03:37PM', '03:37PMApples earnings were a lot better than they look Yahoo Finance'], ['AAPL', 'Feb-03-23', '03:32PM', '03:32PMBig Tech stocks: How Meta, Apple, Amazon are trading after earnings Yahoo Finance Video'], ['AAPL', 'Feb-03-23', '02:59PM', '02:59PMWhy FAANG Stocks Made Big Moves Friday Motley Fool'], ['AAPL', 'Feb-03-23', '02:51PM', \"02:51PMWe've Dug Deeper Into 4 High Profile Portfolio Earnings Reports TheStreet.com\"], ['AAPL', 'Feb-03-23', '02:45PM', '02:45PMMaking Sense of Apple, Amazon and Big Tech Earnings Zacks'], ['AAPL', 'Feb-03-23', '02:31PM', \"02:31PM2023 Top Dow Jones Stocks To Buy And Watch In February: Apple Surges On Earnings Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '02:26PM', '02:26PMUS STOCKS-Wall Street sinks after stunning jobs growth raises questions about Fed Reuters'], ['AAPL', 'Feb-03-23', '01:51PM', '01:51PMBerkshire Hathaway Stock Is Losing to the S&P 500 This Year Barrons.com'], ['AAPL', 'Feb-03-23', '01:50PM', '01:50PMMarket Update: AAPL, AMZN, BA, BYD, HSY, SKX, WEC, BMI, GM Argus Research'], ['AAPL', 'Feb-03-23', '01:43PM', \"01:43PMMarket Rally Powers Higher On Tame Fed, Meta Earnings; Apple, Google, Amazon In Focus: Weekly Review Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '01:34PM', '01:34PMApple Inc. (NASDAQ:AAPL) Q1 2023 Earnings Call Transcript Insider Monkey'], ['AAPL', 'Feb-03-23', '01:27PM', '01:27PM10 Hot Tech Stocks To Buy Now Insider Monkey'], ['AAPL', 'Feb-03-23', '01:10PM', \"01:10PMStock Market Turns Lower After Strong Jobs Report; Apple Stock Reverses Higher Despite Sluggish Quarter Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '12:45PM', '12:45PMWhy Apple Stock Was Up on Friday Motley Fool'], ['AAPL', 'Feb-03-23', '12:20PM', \"12:20PMApple Is Far Better Positioned Than Amazon or Alphabet: Here's the Trade TheStreet.com\"], ['AAPL', 'Feb-03-23', '12:11PM', \"12:11PMStock Market Trims Losses After Strong Jobs Report; Apple Stock Surges 4%, Tesla Reverses Higher Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '12:04PM', '12:04PMQualcomm Stock Rises. The Company Is Diversifying Away From Smartphones and Apple. Barrons.com'], ['AAPL', 'Feb-03-23', '11:17AM', '11:17AMJanuary jobs report, Apple Q1 earnings, Nerdy stock surges on AI products: 3 things to watch markets Yahoo Finance Video'], ['AAPL', 'Feb-03-23', '11:10AM', \"11:10AMETFs in Focus on Apple's First Earnings Miss Since 2016 Zacks\"], ['AAPL', 'Feb-03-23', '11:09AM', '11:09AMApple stock rallies even as CEO Tim Cook spooks with one phrase Yahoo Finance'], ['AAPL', 'Feb-03-23', '11:09AM', '11:09AMApple stock in focus as CEO Tim Cook spooks with one phrase Yahoo Finance'], ['AAPL', 'Feb-03-23', '10:45AM', \"10:45AMStock Market Recovers After Blowout Jobs Report; Apple, Google, AMZN, QCOM Earnings In Focus Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '10:38AM', '10:38AMApple Blames Rotten Holiday Quarter on Supply Chain, Economy Bloomberg'], ['AAPL', 'Feb-03-23', '10:36AM', \"10:36AMGRAPHIC-Tech trillion club's wobble in four charts Reuters\"], ['AAPL', 'Feb-03-23', '10:30AM', \"10:30AMStock Market Takes Heat After Blowout Jobs Report; Apple, Google, AMZN, QCOM Earnings In Focus Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '10:26AM', \"10:26AMApple Sees Improved Outlook After iPhone Supply Issues Resolved Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '10:01AM', '10:01AMApple is producing more. But now the worries are who will buy? MarketWatch'], ['AAPL', 'Feb-03-23', '10:00AM', '10:00AMApple Stock Turns Higher As iPhone Outlook Offsets Rare Earnings Miss From China Disruptions TheStreet.com'], ['AAPL', 'Feb-03-23', '09:54AM', \"09:54AMDow Jones Slides On Strong January Jobs Report; Apple Reverses Higher; Alphabet, Amazon Drop On Earnings Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '09:39AM', '09:39AMNasdaq Rally Gets a Reality Check as Megacaps Miss Bloomberg'], ['AAPL', 'Feb-03-23', '09:39AM', \"09:39AMHere's Our Take on the Latest Earnings and the Jobs Report TheStreet.com\"], ['AAPL', 'Feb-03-23', '09:31AM', '09:31AMApple cant supply enough  and thats a good problem, analyst says Yahoo Finance Video'], ['AAPL', 'Feb-03-23', '09:29AM', \"09:29AMTech trillion club's wobble in four charts Reuters\"], ['AAPL', 'Feb-03-23', '09:22AM', \"09:22AMGRAPHIC-Tech trillion club's wobble in four charts Reuters\"], ['AAPL', 'Feb-03-23', '09:15AM', \"09:15AMDow Jones Futures Slide On Strong January Jobs Report; Alphabet, Amazon, Apple Drop On Earnings Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '09:11AM', \"09:11AMAnalysis-From Meta to Microsoft, AI's big moment is here Reuters\"], ['AAPL', 'Feb-03-23', '08:53AM', '08:53AM2 Top Stocks to Buy in February Motley Fool'], ['AAPL', 'Feb-03-23', '08:35AM', \"08:35AMDow Jones Futures Drop On Strong January Jobs Report; Alphabet, Amazon, Apple Drop On Earnings Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '08:27AM', '08:27AMApple Misses Earnings and Revenue Estimates. The Stock Is Falling. Barrons.com'], ['AAPL', 'Feb-03-23', '08:23AM', \"08:23AMDow Jones Futures Fall Ahead Of January Jobs Report; Alphabet, Amazon, Apple Drop On Earnings Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '08:19AM', '08:19AM10 Best Dividend Stocks To Buy in February Motley Fool'], ['AAPL', 'Feb-03-23', '08:15AM', \"08:15AMDow Jones Futures Fall As Apple, Google, Amazon Skid, Jobs Report Looms; Market Rally Due For Pullback? Investor's Business Daily\"], ['AAPL', 'Feb-03-23', '07:28AM', '07:28AMApple, Alphabet and Amazon stock selloff would reduce their market caps by more than $150 billion combined MarketWatch'], ['AAPL', 'Feb-03-23', '07:14AM', '07:14AMApple Stock Falls After Earnings Motley Fool'], ['AAPL', 'Feb-03-23', '07:10AM', '07:10AMUPDATE 1-Tech earnings hit pause button on market rally Reuters'], ['AAPL', 'Feb-03-23', '07:09AM', '07:09AMWhy Apples Demand Problem May Not Be That Bad Barrons.com'], ['AAPL', 'Feb-03-23', '06:32AM', '06:32AMApple Is Not the Economy. Why the Feds More Bullish Than Tech. Barrons.com'], ['AAPL', 'Feb-03-23', '06:30AM', '06:30AMTheyre baaaaack. Retail participation in the stock market just surpassed the GameStop days. MarketWatch'], ['AAPL', 'Feb-03-23', '06:24AM', '06:24AMApple Stock Slumps After Rare Earnings Miss As China Disruptions Weaken iPhone Sales TheStreet.com'], ['AAPL', 'Feb-03-23', '06:18AM', '06:18AMApple stock gets nailed as CEO Tim Cook spooks investors with one phrase Yahoo Finance'], ['AAPL', 'Feb-03-23', '06:00AM', '06:00AMMORNING BID AMERICAS-Runaway Tech arrested Reuters'], ['AAPL', 'Feb-03-23', '05:54AM', \"05:54AMIndia's customs duty change to dial up local phone production-tax official Reuters\"], ['AAPL', 'Feb-03-23', '05:42AM', '05:42AMApple Sales Fall for First Time Since 2019. Just How Bad Is Its Demand Problem? Barrons.com'], ['AAPL', 'Feb-03-23', '05:21AM', \"05:21AMThis Is Warren Buffett's No. 1 Stock to Buy (and You Won't Find It in Berkshire Hathaway's Portfolio) Motley Fool\"], ['AAPL', 'Feb-03-23', '05:20AM', '05:20AMFutures fall as megacaps slide on downbeat earnings Reuters'], ['AAPL', 'Feb-03-23', '05:16AM', '05:16AMUS STOCKS-Futures fall as megacaps slide on downbeat earnings Reuters'], ['AAPL', 'Feb-03-23', '05:13AM', '05:13AMStocks Lower Ahead of Jobs Data, Apple, Amazon, Google, Nordstrom - Five Things To Know TheStreet.com'], ['AAPL', 'Feb-03-23', '05:06AM', '05:06AMApple and Starbucks couldnt rise above Chinas zero-covid policy Quartz'], ['AAPL', 'Feb-03-23', '01:30AM', '01:30AM$5tn of meh earnings Financial Times'], ['AAPL', 'Feb-03-23', '12:00AM', '12:00AMMarkets dove-coloured glasses Financial Times'], ['AAPL', 'Feb-02-23', '11:05PM', 'Feb-02-23 11:05PMApple offers breadcrumbs for a forecast, but is that enough to reassure Wall Street? MarketWatch'], ['AAPL', 'Feb-02-23', '10:15PM', '10:15PMApple Again Dominates Smartphone Profit, Taking Record 85% Share Bloomberg']]\n"
          ]
        }
      ],
      "source": [
        "# Iterate through the news\n",
        "parsed_news = []\n",
        "for file_name, news_table in news_tables.items():\n",
        "    for x in news_table.findAll('tr'):\n",
        "        #print(x.get_text())\n",
        "        text = x.get_text() \n",
        "        date_scrape = x.td.text.split()\n",
        "\n",
        "        if len(date_scrape) == 1:\n",
        "            time = date_scrape[0]\n",
        "            \n",
        "        else:\n",
        "            date = date_scrape[0]\n",
        "            time = date_scrape[1]\n",
        "\n",
        "        ticker = file_name.split('_')[0]\n",
        "        \n",
        "        parsed_news.append([ticker, date, time, text ])\n",
        "print(parsed_news)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathering Data From AlphaAdvantage for Historical News #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "from decouple import config\n",
        "import requests\n",
        "import urllib.parse\n",
        "import json\n",
        "import datetime\n",
        "AAapikey = config('AAKey')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to convert user provided date to date required by AlphaAdvantage\n",
        "def toAADate(oldDate):\n",
        "    newDate = oldDate.strftime(\"%Y%m%dT0130\")\n",
        "    return str(newDate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the breakdown\n",
            "Current Start Date is: 2023-01-06\n",
            "Current End Date is: 2023-01-11\n",
            "[]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#End Date is yesterday\n",
        "def breakdownofhistoric(ticker, endDate = datetime.date.today() - datetime.timedelta(days = 1), interval = 30, runs = 1):\n",
        "    print(\"Starting the breakdown\")\n",
        "    columns = ['parsed_news']\n",
        "    # Format for parsed_news is [Ticker, Date, Time, Headlines]\n",
        "    historic_parsed_news = []\n",
        "    window = 5\n",
        "    startDate = endDate - datetime.timedelta(days = interval)\n",
        "    rollingEndDate = startDate + datetime.timedelta(days = window)\n",
        "    while rollingEndDate <= endDate:\n",
        "        print(\"Current Start Date is: \"+str(startDate))\n",
        "        print(\"Current End Date is: \"+str(rollingEndDate))\n",
        "        startDate = endDate + datetime.timedelta(days = window)\n",
        "        rollingEndDate = startDate + datetime.timedelta(days = window)\n",
        "    print(historic_parsed_news)\n",
        "    return historic_parsed_news\n",
        "\n",
        "\n",
        "breakdownofhistoric('AAPL', interval = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "endDate is: 2023-02-05\n",
            "startDate is: 2023-01-06\n",
            "startDate is: 20230106T0130\n",
            "endDate is: 20230205T0130\n",
            "           Date                                           Headline Ticker\n",
            "0    2023-01-06  Samsung profit slumps by most in decade on wea...   AAPL\n",
            "1    2023-01-06  Samsung estimates quarterly profit sank to 8-y...   AAPL\n",
            "2    2023-01-06  Apple's Iconic 1970s Trade Sign, Steve Wozniak...   AAPL\n",
            "3    2023-01-06  Apple's Mixed Reality Headset 'Behind Schedule...   AAPL\n",
            "4    2023-01-06  My Top Stock to Buy for 2023  ( and It's Not E...   AAPL\n",
            "..          ...                                                ...    ...\n",
            "195  2023-01-12  TSMC Stock Higher On Record Profits, But Muted...   AAPL\n",
            "196  2023-01-12  Is Meta Platforms Sitting on a $1 Trillion Opp...   AAPL\n",
            "197  2023-01-12  Should You Invest in the Invesco DWA Technolog...   AAPL\n",
            "198  2023-01-12                  My Top Tech IPO to Buy in January   AAPL\n",
            "199  2023-01-12  Taiwan Semiconductor Posts Mixed Fourth-Quarte...   AAPL\n",
            "\n",
            "[200 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Get data from AlphaAdvantage for one ticker for a particular day\n",
        "def getHistoricNewsData(ticker, endDate = datetime.date.today() - datetime.timedelta(days = 1) , interval = '1mo'):\n",
        "    url = 'https://www.alphavantage.co/query?'\n",
        "    print(\"endDate is: \" +str(endDate))\n",
        "    if interval == '1mo':\n",
        "        days_to_add = 30\n",
        "    else:\n",
        "        days_to_add = 60\n",
        "    delta_days = datetime.timedelta(days = days_to_add)\n",
        "    startDate = endDate - delta_days\n",
        "    print(\"startDate is: \" +str(startDate))\n",
        "    if startDate and endDate:\n",
        "        startDate = toAADate(startDate)\n",
        "        endDate = toAADate(endDate)\n",
        "        print(\"startDate is: \" +str(startDate))\n",
        "        print(\"endDate is: \" +str(endDate))\n",
        "        Myparams = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'time_from': startDate, 'time_to': endDate, 'sort': 'EARLIEST','limit': 200, 'apikey': AAapikey}\n",
        "    else:\n",
        "        print(\"NEED DATES\")\n",
        "        #Myparams = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'sort': 'LATEST','limit': 100, 'apikey': AAapikey}\n",
        "    r = requests.get(url, params = Myparams)\n",
        "    data = r.json()\n",
        "    #return data\n",
        "    historic_news = pd.DataFrame(columns=['Date', 'Headline', 'Ticker'])\n",
        "    for i in data.get(\"feed\"):\n",
        "        test_date = i.get(\"time_published\")\n",
        "        test_date = test_date[:8]\n",
        "        newDate = datetime.datetime.strptime(test_date, '%Y%m%d').date()\n",
        "        row = [newDate, i.get(\"title\"), ticker]\n",
        "        new_df = pd.DataFrame([row],columns=['Date', 'Headline', 'Ticker'])\n",
        "        historic_news = pd.concat([historic_news, new_df], axis=0, ignore_index=True)\n",
        "    return historic_news\n",
        "\n",
        "#historic_news = getHistoricNewsData('AAPL', '2022-10-10', '2mo')\n",
        "historic_news = getHistoricNewsData('AAPL', interval = '1mo')\n",
        "print(historic_news)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis of News data #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "def SentimentAnalysisNewsData(parsedNews, printOut = False):\n",
        "    #Downloading Vader Lexicon for Sentiment Analysis\n",
        "    nltk.download('vader_lexicon')\n",
        "    # Initializing Sentiment Analysis\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    #Declaring Column Names\n",
        "    columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
        "    #Creating dataframe from news\n",
        "    news = pd.DataFrame(parsedNews, columns=columns)\n",
        "    print(news)\n",
        "    #Getting scores for headlines\n",
        "    scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
        "\n",
        "    #Creating Dataframe of Scores\n",
        "    df_scores = pd.DataFrame(scores)\n",
        "    #Joining scores to news dataframe\n",
        "    news = news.join(df_scores, rsuffix='_right')\n",
        "    #Converting Date column to pd datetime date\n",
        "    news['Date'] = pd.to_datetime(news.Date).dt.date\n",
        "\n",
        "    #List of unique tickers\n",
        "    unique_ticker = news['Ticker'].unique().tolist()\n",
        "    #Creating dict for news based on ticker\n",
        "    news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}\n",
        "    #Initializing List of values\n",
        "    # og values = []\n",
        "    values = pd.DataFrame(columns = ['Ticker', 'Date', 'Compound'])\n",
        "    for ticker in tickers: \n",
        "        dataframe = news_dict[ticker]\n",
        "        dataframe = dataframe.set_index('Ticker')\n",
        "        #Dropping headlines column since we only need scores now\n",
        "        dataframe = dataframe.drop(columns = ['Headline'])\n",
        "        #if printOut:\n",
        "            #print ('\\n')\n",
        "            #print (dataframe.head())\n",
        "        \n",
        "        #mean = round(dataframe['compound'].mean(), 2)\n",
        "        #Finding compound number for news of every day\n",
        "        testdf = pd.DataFrame(columns = ['Date', 'Mean Sentiment'])\n",
        "        testdf = round(dataframe.groupby('Date')['compound'].mean(), 2)\n",
        "        print(testdf.shape)\n",
        "        #Adding values to values list\n",
        "        #og values.append(mean)\n",
        "    \n",
        "   \n",
        "    #print(round(dataframe.groupby('Date')['compound'].mean(), 2))\n",
        "    #print(\"VALUES------------\")\n",
        "    #print(values)\n",
        "        \n",
        "    #Combining tickers and values into new dataframe\n",
        "    #df = pd.DataFrame(list(zip(tickers, values)), columns =['Ticker', 'Mean Sentiment']) \n",
        "    #df = df.set_index('Ticker')\n",
        "    #df = df.sort_values('date', ascending=False)\n",
        "    if printOut:\n",
        "        print(\"-----------DF\")\n",
        "        #print(df.head())\n",
        "        #print(df.shape)\n",
        "    #Returning the dataframe\n",
        "    return df\n",
        "    #if printOut:\n",
        "        #print ('\\n')\n",
        "        #display (df)\n",
        "    #return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Ticker        Date  Time  \\\n",
            "0     AAPL  2023-01-06   NaN   \n",
            "1     AAPL  2023-01-06   NaN   \n",
            "2     AAPL  2023-01-06   NaN   \n",
            "3     AAPL  2023-01-06   NaN   \n",
            "4     AAPL  2023-01-06   NaN   \n",
            "..     ...         ...   ...   \n",
            "195   AAPL  2023-01-12   NaN   \n",
            "196   AAPL  2023-01-12   NaN   \n",
            "197   AAPL  2023-01-12   NaN   \n",
            "198   AAPL  2023-01-12   NaN   \n",
            "199   AAPL  2023-01-12   NaN   \n",
            "\n",
            "                                              Headline  \n",
            "0    Samsung profit slumps by most in decade on wea...  \n",
            "1    Samsung estimates quarterly profit sank to 8-y...  \n",
            "2    Apple's Iconic 1970s Trade Sign, Steve Wozniak...  \n",
            "3    Apple's Mixed Reality Headset 'Behind Schedule...  \n",
            "4    My Top Stock to Buy for 2023  ( and It's Not E...  \n",
            "..                                                 ...  \n",
            "195  TSMC Stock Higher On Record Profits, But Muted...  \n",
            "196  Is Meta Platforms Sitting on a $1 Trillion Opp...  \n",
            "197  Should You Invest in the Invesco DWA Technolog...  \n",
            "198                  My Top Tech IPO to Buy in January  \n",
            "199  Taiwan Semiconductor Posts Mixed Fourth-Quarte...  \n",
            "\n",
            "[200 rows x 4 columns]\n",
            "(7,)\n",
            "-----------DF\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\Ishaan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#print(\"HISTORIC SENTIMENT\")\n",
        "HistoricSentiment = SentimentAnalysisNewsData(historic_news, True)\n",
        "#print(\"\\n\")\n",
        "#print(\"TODAYS SENTIMENT\")\n",
        "#TodaysSentiment = SentimentAnalysisNewsData(parsed_news)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating Dataset #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dataset for $AAPL\n",
            "Getting stock data for stock $AAPL\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "                  Open        High         Low       Close   Adj Close  \\\n",
            "Date                                                                     \n",
            "2023-02-06  152.574997  153.100006  150.779999  151.729996  151.729996   \n",
            "\n",
            "              Volume  \n",
            "Date                  \n",
            "2023-02-06  67990412  \n",
            "endDate is: 2023-02-05\n",
            "startDate is: 2022-12-07\n",
            "startDate is: 20221207T0130\n",
            "endDate is: 20230205T0130\n"
          ]
        },
        {
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python310\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Python310\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
            "File \u001b[1;32mc:\\Python310\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
            "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [93], line 19\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[39mprint\u001b[39m(HistoricSentiment\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     13\u001b[0m         \u001b[39m#Merge as training set\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[39m#Get today's stock data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         \u001b[39m#Get today's news data\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         \u001b[39m#Use news to get sentiment\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m createDataset(\u001b[39m'\u001b[39;49m\u001b[39m2022-10-10\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m2mo\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "Cell \u001b[1;32mIn [93], line 8\u001b[0m, in \u001b[0;36mcreateDataset\u001b[1;34m(date_from, int)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(historic_stock\u001b[39m.\u001b[39mhead())\n\u001b[0;32m      7\u001b[0m \u001b[39m#Get historic news data\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m historic_news \u001b[39m=\u001b[39m getHistoricNewsData(i, interval \u001b[39m=\u001b[39;49m \u001b[39mint\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(historic_news)\n\u001b[0;32m     10\u001b[0m \u001b[39m#Use news to get sentiment\u001b[39;00m\n",
            "Cell \u001b[1;32mIn [90], line 22\u001b[0m, in \u001b[0;36mgetHistoricNewsData\u001b[1;34m(ticker, endDate, interval)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[39m#Myparams = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'sort': 'LATEST','limit': 100, 'apikey': AAapikey}\u001b[39;00m\n\u001b[0;32m     21\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url, params \u001b[39m=\u001b[39m Myparams)\n\u001b[1;32m---> 22\u001b[0m data \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mjson()\n\u001b[0;32m     23\u001b[0m \u001b[39m#return data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m historic_news \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mHeadline\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTicker\u001b[39m\u001b[39m'\u001b[39m])\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmsg, e\u001b[39m.\u001b[39mdoc, e\u001b[39m.\u001b[39mpos)\n",
            "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ],
      "source": [
        "def createDataset(date_from, int):\n",
        "    for i in tickers:\n",
        "        print(\"Creating dataset for $\" +i)\n",
        "        #Get historic stock data\n",
        "        historic_stock = getMonthlyStockData(i, interval = int)\n",
        "        print(historic_stock.head())\n",
        "        #Get historic news data\n",
        "        historic_news = getHistoricNewsData(i, interval = int)\n",
        "        print(historic_news)\n",
        "        #Use news to get sentiment\n",
        "        HistoricSentiment = SentimentAnalysisNewsData(historic_news)\n",
        "        print(HistoricSentiment.shape)\n",
        "        #Merge as training set\n",
        "        #Get today's stock data\n",
        "        #Get today's news data\n",
        "        #Use news to get sentiment\n",
        "\n",
        "\n",
        "createDataset('2022-10-10', '2mo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO2ChGGwJkijmmb0vDcCR40",
      "include_colab_link": true,
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
