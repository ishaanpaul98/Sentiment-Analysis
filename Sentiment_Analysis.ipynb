{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishaanpaul98/Sentiment-Analysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 665,
      "metadata": {
        "id": "pGQVQfr0b3SS"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen, Request\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "import time\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 666,
      "metadata": {
        "id": "WSgZEvuikgTn"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 667,
      "metadata": {
        "id": "9hbdUWDKkgv_"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 668,
      "metadata": {
        "id": "Eqvj106lkgyU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stock Data Helper Functions #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 669,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting stock data for stock $AAPL\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-21</th>\n",
              "      <td>132.979996</td>\n",
              "      <td>136.809998</td>\n",
              "      <td>132.750000</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>85928000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-22</th>\n",
              "      <td>134.350006</td>\n",
              "      <td>134.559998</td>\n",
              "      <td>130.300003</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>77852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-23</th>\n",
              "      <td>130.919998</td>\n",
              "      <td>132.419998</td>\n",
              "      <td>129.639999</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>63814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>131.380005</td>\n",
              "      <td>131.410004</td>\n",
              "      <td>128.720001</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>69007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>129.669998</td>\n",
              "      <td>131.029999</td>\n",
              "      <td>125.870003</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>85438400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>127.989998</td>\n",
              "      <td>130.479996</td>\n",
              "      <td>127.730003</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>75703700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>128.410004</td>\n",
              "      <td>129.949997</td>\n",
              "      <td>127.430000</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>76960600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>130.279999</td>\n",
              "      <td>130.899994</td>\n",
              "      <td>124.169998</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>112117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>126.889999</td>\n",
              "      <td>128.660004</td>\n",
              "      <td>125.080002</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>89113600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>127.129997</td>\n",
              "      <td>127.769997</td>\n",
              "      <td>124.760002</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>80962700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>126.010002</td>\n",
              "      <td>130.289993</td>\n",
              "      <td>124.889999</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>87686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>130.470001</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>129.889999</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>70790800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-10</th>\n",
              "      <td>130.259995</td>\n",
              "      <td>131.259995</td>\n",
              "      <td>128.119995</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>63896200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-11</th>\n",
              "      <td>131.250000</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>130.460007</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>69458900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-12</th>\n",
              "      <td>133.880005</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>71379600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-13</th>\n",
              "      <td>132.029999</td>\n",
              "      <td>134.919998</td>\n",
              "      <td>131.660004</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>57758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17</th>\n",
              "      <td>134.830002</td>\n",
              "      <td>137.289993</td>\n",
              "      <td>134.130005</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>63646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-18</th>\n",
              "      <td>136.820007</td>\n",
              "      <td>138.610001</td>\n",
              "      <td>135.029999</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>69672800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-19</th>\n",
              "      <td>134.080002</td>\n",
              "      <td>136.250000</td>\n",
              "      <td>133.770004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>58280400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20</th>\n",
              "      <td>135.279999</td>\n",
              "      <td>138.020004</td>\n",
              "      <td>134.220001</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>79972200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-23</th>\n",
              "      <td>138.119995</td>\n",
              "      <td>143.320007</td>\n",
              "      <td>137.899994</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>81760300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-24</th>\n",
              "      <td>140.309998</td>\n",
              "      <td>143.160004</td>\n",
              "      <td>140.300003</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>66435100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-25</th>\n",
              "      <td>140.889999</td>\n",
              "      <td>142.429993</td>\n",
              "      <td>138.809998</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>65799300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-26</th>\n",
              "      <td>143.169998</td>\n",
              "      <td>144.250000</td>\n",
              "      <td>141.899994</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>54105100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-27</th>\n",
              "      <td>143.160004</td>\n",
              "      <td>147.229996</td>\n",
              "      <td>143.080002</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>70492800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High         Low       Close   Adj Close  \\\n",
              "Date                                                                     \n",
              "2022-12-21  132.979996  136.809998  132.750000  135.449997  135.449997   \n",
              "2022-12-22  134.350006  134.559998  130.300003  132.229996  132.229996   \n",
              "2022-12-23  130.919998  132.419998  129.639999  131.860001  131.860001   \n",
              "2022-12-27  131.380005  131.410004  128.720001  130.029999  130.029999   \n",
              "2022-12-28  129.669998  131.029999  125.870003  126.040001  126.040001   \n",
              "2022-12-29  127.989998  130.479996  127.730003  129.610001  129.610001   \n",
              "2022-12-30  128.410004  129.949997  127.430000  129.929993  129.929993   \n",
              "2023-01-03  130.279999  130.899994  124.169998  125.070000  125.070000   \n",
              "2023-01-04  126.889999  128.660004  125.080002  126.360001  126.360001   \n",
              "2023-01-05  127.129997  127.769997  124.760002  125.019997  125.019997   \n",
              "2023-01-06  126.010002  130.289993  124.889999  129.619995  129.619995   \n",
              "2023-01-09  130.470001  133.410004  129.889999  130.149994  130.149994   \n",
              "2023-01-10  130.259995  131.259995  128.119995  130.729996  130.729996   \n",
              "2023-01-11  131.250000  133.509995  130.460007  133.490005  133.490005   \n",
              "2023-01-12  133.880005  134.259995  131.440002  133.410004  133.410004   \n",
              "2023-01-13  132.029999  134.919998  131.660004  134.759995  134.759995   \n",
              "2023-01-17  134.830002  137.289993  134.130005  135.940002  135.940002   \n",
              "2023-01-18  136.820007  138.610001  135.029999  135.210007  135.210007   \n",
              "2023-01-19  134.080002  136.250000  133.770004  135.270004  135.270004   \n",
              "2023-01-20  135.279999  138.020004  134.220001  137.869995  137.869995   \n",
              "2023-01-23  138.119995  143.320007  137.899994  141.110001  141.110001   \n",
              "2023-01-24  140.309998  143.160004  140.300003  142.529999  142.529999   \n",
              "2023-01-25  140.889999  142.429993  138.809998  141.860001  141.860001   \n",
              "2023-01-26  143.169998  144.250000  141.899994  143.960007  143.960007   \n",
              "2023-01-27  143.160004  147.229996  143.080002  145.929993  145.929993   \n",
              "\n",
              "               Volume  \n",
              "Date                   \n",
              "2022-12-21   85928000  \n",
              "2022-12-22   77852100  \n",
              "2022-12-23   63814900  \n",
              "2022-12-27   69007800  \n",
              "2022-12-28   85438400  \n",
              "2022-12-29   75703700  \n",
              "2022-12-30   76960600  \n",
              "2023-01-03  112117500  \n",
              "2023-01-04   89113600  \n",
              "2023-01-05   80962700  \n",
              "2023-01-06   87686600  \n",
              "2023-01-09   70790800  \n",
              "2023-01-10   63896200  \n",
              "2023-01-11   69458900  \n",
              "2023-01-12   71379600  \n",
              "2023-01-13   57758000  \n",
              "2023-01-17   63646600  \n",
              "2023-01-18   69672800  \n",
              "2023-01-19   58280400  \n",
              "2023-01-20   79972200  \n",
              "2023-01-23   81760300  \n",
              "2023-01-24   66435100  \n",
              "2023-01-25   65799300  \n",
              "2023-01-26   54105100  \n",
              "2023-01-27   70492800  "
            ]
          },
          "execution_count": 669,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getStockDataDaily(symbol, day):\n",
        "    print(\"Getting stock data for stock $\"+symbol)\n",
        "    df = yf.download(symbol, start=day, period = \"1d\")\n",
        "    return df\n",
        "\n",
        "getStockDataDaily('AAPL', \"2022-12-21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 670,
      "metadata": {},
      "outputs": [],
      "source": [
        "def arrayToString(arr):\n",
        "    print(\"Starting array to list\")\n",
        "    listToStr = ' '.join([str(elem) for elem in arr])\n",
        "    return listToStr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 671,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of symbols array is more than 1. STARTING ARRAYTOSTRING\n",
            "Starting array to list\n",
            "Getting stock data for stock $AAPL TSLA\n",
            "[*********************100%***********************]  2 of 2 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">AAPL</th>\n",
              "      <th colspan=\"6\" halign=\"left\">TSLA</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-21</th>\n",
              "      <td>132.979996</td>\n",
              "      <td>136.809998</td>\n",
              "      <td>132.750000</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>135.449997</td>\n",
              "      <td>85928000</td>\n",
              "      <td>139.339996</td>\n",
              "      <td>141.259995</td>\n",
              "      <td>135.889999</td>\n",
              "      <td>137.570007</td>\n",
              "      <td>137.570007</td>\n",
              "      <td>145417400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-22</th>\n",
              "      <td>134.350006</td>\n",
              "      <td>134.559998</td>\n",
              "      <td>130.300003</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>132.229996</td>\n",
              "      <td>77852100</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>136.630005</td>\n",
              "      <td>122.260002</td>\n",
              "      <td>125.349998</td>\n",
              "      <td>125.349998</td>\n",
              "      <td>210090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-23</th>\n",
              "      <td>130.919998</td>\n",
              "      <td>132.419998</td>\n",
              "      <td>129.639999</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>131.860001</td>\n",
              "      <td>63814900</td>\n",
              "      <td>126.370003</td>\n",
              "      <td>128.619995</td>\n",
              "      <td>121.019997</td>\n",
              "      <td>123.150002</td>\n",
              "      <td>123.150002</td>\n",
              "      <td>166989700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>131.380005</td>\n",
              "      <td>131.410004</td>\n",
              "      <td>128.720001</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>130.029999</td>\n",
              "      <td>69007800</td>\n",
              "      <td>117.500000</td>\n",
              "      <td>119.669998</td>\n",
              "      <td>108.760002</td>\n",
              "      <td>109.099998</td>\n",
              "      <td>109.099998</td>\n",
              "      <td>208643400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>129.669998</td>\n",
              "      <td>131.029999</td>\n",
              "      <td>125.870003</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>126.040001</td>\n",
              "      <td>85438400</td>\n",
              "      <td>110.349998</td>\n",
              "      <td>116.269997</td>\n",
              "      <td>108.239998</td>\n",
              "      <td>112.709999</td>\n",
              "      <td>112.709999</td>\n",
              "      <td>221070500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>127.989998</td>\n",
              "      <td>130.479996</td>\n",
              "      <td>127.730003</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>129.610001</td>\n",
              "      <td>75703700</td>\n",
              "      <td>120.389999</td>\n",
              "      <td>123.570000</td>\n",
              "      <td>117.500000</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>221923300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>128.410004</td>\n",
              "      <td>129.949997</td>\n",
              "      <td>127.430000</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>76960600</td>\n",
              "      <td>119.949997</td>\n",
              "      <td>124.480003</td>\n",
              "      <td>119.750000</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>157304500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>130.279999</td>\n",
              "      <td>130.899994</td>\n",
              "      <td>124.169998</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>125.070000</td>\n",
              "      <td>112117500</td>\n",
              "      <td>118.470001</td>\n",
              "      <td>118.800003</td>\n",
              "      <td>104.639999</td>\n",
              "      <td>108.099998</td>\n",
              "      <td>108.099998</td>\n",
              "      <td>231402800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>126.889999</td>\n",
              "      <td>128.660004</td>\n",
              "      <td>125.080002</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>126.360001</td>\n",
              "      <td>89113600</td>\n",
              "      <td>109.110001</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>113.639999</td>\n",
              "      <td>113.639999</td>\n",
              "      <td>180389000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>127.129997</td>\n",
              "      <td>127.769997</td>\n",
              "      <td>124.760002</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>80962700</td>\n",
              "      <td>110.510002</td>\n",
              "      <td>111.750000</td>\n",
              "      <td>107.160004</td>\n",
              "      <td>110.339996</td>\n",
              "      <td>110.339996</td>\n",
              "      <td>157986300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>126.010002</td>\n",
              "      <td>130.289993</td>\n",
              "      <td>124.889999</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>129.619995</td>\n",
              "      <td>87686600</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>114.389999</td>\n",
              "      <td>101.809998</td>\n",
              "      <td>113.059998</td>\n",
              "      <td>113.059998</td>\n",
              "      <td>220575900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>130.470001</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>129.889999</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>130.149994</td>\n",
              "      <td>70790800</td>\n",
              "      <td>118.959999</td>\n",
              "      <td>123.519997</td>\n",
              "      <td>117.110001</td>\n",
              "      <td>119.769997</td>\n",
              "      <td>119.769997</td>\n",
              "      <td>190284000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-10</th>\n",
              "      <td>130.259995</td>\n",
              "      <td>131.259995</td>\n",
              "      <td>128.119995</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>130.729996</td>\n",
              "      <td>63896200</td>\n",
              "      <td>121.070000</td>\n",
              "      <td>122.760002</td>\n",
              "      <td>114.919998</td>\n",
              "      <td>118.849998</td>\n",
              "      <td>118.849998</td>\n",
              "      <td>167642500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-11</th>\n",
              "      <td>131.250000</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>130.460007</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>133.490005</td>\n",
              "      <td>69458900</td>\n",
              "      <td>122.089996</td>\n",
              "      <td>125.949997</td>\n",
              "      <td>120.510002</td>\n",
              "      <td>123.220001</td>\n",
              "      <td>123.220001</td>\n",
              "      <td>183810800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-12</th>\n",
              "      <td>133.880005</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>133.410004</td>\n",
              "      <td>71379600</td>\n",
              "      <td>122.559998</td>\n",
              "      <td>124.129997</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>123.559998</td>\n",
              "      <td>123.559998</td>\n",
              "      <td>169400900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-13</th>\n",
              "      <td>132.029999</td>\n",
              "      <td>134.919998</td>\n",
              "      <td>131.660004</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>134.759995</td>\n",
              "      <td>57758000</td>\n",
              "      <td>116.550003</td>\n",
              "      <td>122.629997</td>\n",
              "      <td>115.599998</td>\n",
              "      <td>122.400002</td>\n",
              "      <td>122.400002</td>\n",
              "      <td>180439300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17</th>\n",
              "      <td>134.830002</td>\n",
              "      <td>137.289993</td>\n",
              "      <td>134.130005</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>135.940002</td>\n",
              "      <td>63646600</td>\n",
              "      <td>125.699997</td>\n",
              "      <td>131.699997</td>\n",
              "      <td>125.019997</td>\n",
              "      <td>131.490005</td>\n",
              "      <td>131.490005</td>\n",
              "      <td>186477000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-18</th>\n",
              "      <td>136.820007</td>\n",
              "      <td>138.610001</td>\n",
              "      <td>135.029999</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>135.210007</td>\n",
              "      <td>69672800</td>\n",
              "      <td>136.559998</td>\n",
              "      <td>136.679993</td>\n",
              "      <td>127.010002</td>\n",
              "      <td>128.779999</td>\n",
              "      <td>128.779999</td>\n",
              "      <td>195680300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-19</th>\n",
              "      <td>134.080002</td>\n",
              "      <td>136.250000</td>\n",
              "      <td>133.770004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>135.270004</td>\n",
              "      <td>58280400</td>\n",
              "      <td>127.260002</td>\n",
              "      <td>129.990005</td>\n",
              "      <td>124.309998</td>\n",
              "      <td>127.169998</td>\n",
              "      <td>127.169998</td>\n",
              "      <td>170291900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20</th>\n",
              "      <td>135.279999</td>\n",
              "      <td>138.020004</td>\n",
              "      <td>134.220001</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>137.869995</td>\n",
              "      <td>79972200</td>\n",
              "      <td>128.679993</td>\n",
              "      <td>133.509995</td>\n",
              "      <td>127.349998</td>\n",
              "      <td>133.419998</td>\n",
              "      <td>133.419998</td>\n",
              "      <td>138429900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-23</th>\n",
              "      <td>138.119995</td>\n",
              "      <td>143.320007</td>\n",
              "      <td>137.899994</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>141.110001</td>\n",
              "      <td>81760300</td>\n",
              "      <td>135.869995</td>\n",
              "      <td>145.380005</td>\n",
              "      <td>134.270004</td>\n",
              "      <td>143.750000</td>\n",
              "      <td>143.750000</td>\n",
              "      <td>203119200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-24</th>\n",
              "      <td>140.309998</td>\n",
              "      <td>143.160004</td>\n",
              "      <td>140.300003</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>142.529999</td>\n",
              "      <td>66435100</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>146.500000</td>\n",
              "      <td>141.100006</td>\n",
              "      <td>143.889999</td>\n",
              "      <td>143.889999</td>\n",
              "      <td>158699100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-25</th>\n",
              "      <td>140.889999</td>\n",
              "      <td>142.429993</td>\n",
              "      <td>138.809998</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>141.860001</td>\n",
              "      <td>65799300</td>\n",
              "      <td>141.910004</td>\n",
              "      <td>146.410004</td>\n",
              "      <td>138.070007</td>\n",
              "      <td>144.429993</td>\n",
              "      <td>144.429993</td>\n",
              "      <td>192734300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-26</th>\n",
              "      <td>143.169998</td>\n",
              "      <td>144.250000</td>\n",
              "      <td>141.899994</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>143.960007</td>\n",
              "      <td>54105100</td>\n",
              "      <td>159.970001</td>\n",
              "      <td>161.419998</td>\n",
              "      <td>154.759995</td>\n",
              "      <td>160.270004</td>\n",
              "      <td>160.270004</td>\n",
              "      <td>234815100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-27</th>\n",
              "      <td>143.160004</td>\n",
              "      <td>147.229996</td>\n",
              "      <td>143.080002</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>145.929993</td>\n",
              "      <td>70492800</td>\n",
              "      <td>162.429993</td>\n",
              "      <td>180.679993</td>\n",
              "      <td>161.169998</td>\n",
              "      <td>177.899994</td>\n",
              "      <td>177.899994</td>\n",
              "      <td>305632100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  AAPL                                                  \\\n",
              "                  Open        High         Low       Close   Adj Close   \n",
              "Date                                                                     \n",
              "2022-12-21  132.979996  136.809998  132.750000  135.449997  135.449997   \n",
              "2022-12-22  134.350006  134.559998  130.300003  132.229996  132.229996   \n",
              "2022-12-23  130.919998  132.419998  129.639999  131.860001  131.860001   \n",
              "2022-12-27  131.380005  131.410004  128.720001  130.029999  130.029999   \n",
              "2022-12-28  129.669998  131.029999  125.870003  126.040001  126.040001   \n",
              "2022-12-29  127.989998  130.479996  127.730003  129.610001  129.610001   \n",
              "2022-12-30  128.410004  129.949997  127.430000  129.929993  129.929993   \n",
              "2023-01-03  130.279999  130.899994  124.169998  125.070000  125.070000   \n",
              "2023-01-04  126.889999  128.660004  125.080002  126.360001  126.360001   \n",
              "2023-01-05  127.129997  127.769997  124.760002  125.019997  125.019997   \n",
              "2023-01-06  126.010002  130.289993  124.889999  129.619995  129.619995   \n",
              "2023-01-09  130.470001  133.410004  129.889999  130.149994  130.149994   \n",
              "2023-01-10  130.259995  131.259995  128.119995  130.729996  130.729996   \n",
              "2023-01-11  131.250000  133.509995  130.460007  133.490005  133.490005   \n",
              "2023-01-12  133.880005  134.259995  131.440002  133.410004  133.410004   \n",
              "2023-01-13  132.029999  134.919998  131.660004  134.759995  134.759995   \n",
              "2023-01-17  134.830002  137.289993  134.130005  135.940002  135.940002   \n",
              "2023-01-18  136.820007  138.610001  135.029999  135.210007  135.210007   \n",
              "2023-01-19  134.080002  136.250000  133.770004  135.270004  135.270004   \n",
              "2023-01-20  135.279999  138.020004  134.220001  137.869995  137.869995   \n",
              "2023-01-23  138.119995  143.320007  137.899994  141.110001  141.110001   \n",
              "2023-01-24  140.309998  143.160004  140.300003  142.529999  142.529999   \n",
              "2023-01-25  140.889999  142.429993  138.809998  141.860001  141.860001   \n",
              "2023-01-26  143.169998  144.250000  141.899994  143.960007  143.960007   \n",
              "2023-01-27  143.160004  147.229996  143.080002  145.929993  145.929993   \n",
              "\n",
              "                             TSLA                                      \\\n",
              "               Volume        Open        High         Low       Close   \n",
              "Date                                                                    \n",
              "2022-12-21   85928000  139.339996  141.259995  135.889999  137.570007   \n",
              "2022-12-22   77852100  136.000000  136.630005  122.260002  125.349998   \n",
              "2022-12-23   63814900  126.370003  128.619995  121.019997  123.150002   \n",
              "2022-12-27   69007800  117.500000  119.669998  108.760002  109.099998   \n",
              "2022-12-28   85438400  110.349998  116.269997  108.239998  112.709999   \n",
              "2022-12-29   75703700  120.389999  123.570000  117.500000  121.820000   \n",
              "2022-12-30   76960600  119.949997  124.480003  119.750000  123.180000   \n",
              "2023-01-03  112117500  118.470001  118.800003  104.639999  108.099998   \n",
              "2023-01-04   89113600  109.110001  114.589996  107.519997  113.639999   \n",
              "2023-01-05   80962700  110.510002  111.750000  107.160004  110.339996   \n",
              "2023-01-06   87686600  103.000000  114.389999  101.809998  113.059998   \n",
              "2023-01-09   70790800  118.959999  123.519997  117.110001  119.769997   \n",
              "2023-01-10   63896200  121.070000  122.760002  114.919998  118.849998   \n",
              "2023-01-11   69458900  122.089996  125.949997  120.510002  123.220001   \n",
              "2023-01-12   71379600  122.559998  124.129997  117.000000  123.559998   \n",
              "2023-01-13   57758000  116.550003  122.629997  115.599998  122.400002   \n",
              "2023-01-17   63646600  125.699997  131.699997  125.019997  131.490005   \n",
              "2023-01-18   69672800  136.559998  136.679993  127.010002  128.779999   \n",
              "2023-01-19   58280400  127.260002  129.990005  124.309998  127.169998   \n",
              "2023-01-20   79972200  128.679993  133.509995  127.349998  133.419998   \n",
              "2023-01-23   81760300  135.869995  145.380005  134.270004  143.750000   \n",
              "2023-01-24   66435100  143.000000  146.500000  141.100006  143.889999   \n",
              "2023-01-25   65799300  141.910004  146.410004  138.070007  144.429993   \n",
              "2023-01-26   54105100  159.970001  161.419998  154.759995  160.270004   \n",
              "2023-01-27   70492800  162.429993  180.679993  161.169998  177.899994   \n",
              "\n",
              "                                   \n",
              "             Adj Close     Volume  \n",
              "Date                               \n",
              "2022-12-21  137.570007  145417400  \n",
              "2022-12-22  125.349998  210090300  \n",
              "2022-12-23  123.150002  166989700  \n",
              "2022-12-27  109.099998  208643400  \n",
              "2022-12-28  112.709999  221070500  \n",
              "2022-12-29  121.820000  221923300  \n",
              "2022-12-30  123.180000  157304500  \n",
              "2023-01-03  108.099998  231402800  \n",
              "2023-01-04  113.639999  180389000  \n",
              "2023-01-05  110.339996  157986300  \n",
              "2023-01-06  113.059998  220575900  \n",
              "2023-01-09  119.769997  190284000  \n",
              "2023-01-10  118.849998  167642500  \n",
              "2023-01-11  123.220001  183810800  \n",
              "2023-01-12  123.559998  169400900  \n",
              "2023-01-13  122.400002  180439300  \n",
              "2023-01-17  131.490005  186477000  \n",
              "2023-01-18  128.779999  195680300  \n",
              "2023-01-19  127.169998  170291900  \n",
              "2023-01-20  133.419998  138429900  \n",
              "2023-01-23  143.750000  203119200  \n",
              "2023-01-24  143.889999  158699100  \n",
              "2023-01-25  144.429993  192734300  \n",
              "2023-01-26  160.270004  234815100  \n",
              "2023-01-27  177.899994  305632100  "
            ]
          },
          "execution_count": 671,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def getMultiStockDataDaily(symbols, day):\n",
        "    if len(symbols) > 1:\n",
        "        print(\"Length of symbols array is more than 1. STARTING ARRAYTOSTRING\")\n",
        "        symbols = arrayToString(symbols)\n",
        "    print(\"Getting stock data for stock $\"+symbols)\n",
        "    df = yf.download(symbols, start=day, period = \"1d\", group_by='ticker')\n",
        "    return df\n",
        "\n",
        "getMultiStockDataDaily(['AAPL', 'TSLA'], \"2022-12-21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 672,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getMonthlyStockData(symbol, day = datetime.date.today() - datetime.timedelta(days = 1), interval = '1mo'):\n",
        "    print(\"Getting stock data for stock $\"+symbol)\n",
        "    df = yf.download(symbol, start=day, period = interval, group_by='ticker')\n",
        "    return df\n",
        "\n",
        "#getMonthlyStockData('AAPL', \"2022-11-21\", '1mo')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathering FinViz Data (Today's News) #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 673,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters \n",
        "n = 3 #the # of article headlines displayed per ticker\n",
        "tickers = ['AAPL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 674,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'news':        Date                                              Title  \\\n",
              " 0   04:51PM                 Morning Bid: Calm before the storm   \n",
              " 1   04:22PM  Moving company tried to block negative reviews...   \n",
              " 2   04:22PM  Apple, Amazon earnings, jobs data and Fed deci...   \n",
              " 3   04:09PM  Could Big Tech layoffs keep growing? Apple, Am...   \n",
              " 4   04:00PM  Chinese Travel Is Set to Return. The Question ...   \n",
              " ..      ...                                                ...   \n",
              " 85   Jan-27  S&P 500 jumps to end at nearly 2-month high as...   \n",
              " 86   Jan-27  : Musk under SEC probe connected with Autopilo...   \n",
              " 87   Jan-27  FDA approves Eli Lilly's drug for rare blood c...   \n",
              " 88   Jan-27  China Stocks Veteran Hao Hong Sees Hong Kong S...   \n",
              " 89   Jan-27  : U.S. oil prices settle at their lowest in mo...   \n",
              " \n",
              "                  Source                                               Link  \n",
              " 0       www.reuters.com  https://www.reuters.com/markets/asia/global-ma...  \n",
              " 1       foxbusiness.com  https://foxbusiness.com/markets/moving-company...  \n",
              " 2       foxbusiness.com  https://foxbusiness.com/markets/apple-amazon-e...  \n",
              " 3   www.marketwatch.com  https://www.marketwatch.com/story/could-big-te...  \n",
              " 4       www.nytimes.com  https://www.nytimes.com/2023/01/29/travel/chin...  \n",
              " ..                  ...                                                ...  \n",
              " 85  www.marketwatch.com  http://www.marketwatch.com/news/story/sp-500-j...  \n",
              " 86  www.marketwatch.com  http://www.marketwatch.com/news/story/musk-und...  \n",
              " 87      www.reuters.com  https://www.reuters.com/business/healthcare-ph...  \n",
              " 88    www.bloomberg.com  https://www.bloomberg.com/news/articles/2023-0...  \n",
              " 89  www.marketwatch.com  http://www.marketwatch.com/news/story/us-oil-p...  \n",
              " \n",
              " [90 rows x 4 columns],\n",
              " 'blogs':        Date                                              Title  \\\n",
              " 0   04:27PM                                    Nasdaq Breakout   \n",
              " 1   02:00PM  Adani Publishes 413-Page Report Saying Hindenb...   \n",
              " 2   01:30PM  \"We Will Root Out The Deep State\" - Trump Begi...   \n",
              " 3   01:00PM  Watch: Inexperienced Trans Figure Skater Perfo...   \n",
              " 4   12:33PM  Taibbi: Hamilton 68 Stealth Edits Website Afte...   \n",
              " ..      ...                                                ...   \n",
              " 85   Dec-18                           Your Mental Sharpe Ratio   \n",
              " 86   Dec-06   The Three Essential Sources of Your Trading Edge   \n",
              " 87   Nov-24                                Trading Consciously   \n",
              " 88   Nov-18  Relapse Prevention:  A Neglected Topic In Trad...   \n",
              " 89   May-21  New Issue Now Available: What Hedge Funds Boug...   \n",
              " \n",
              "                           Source  \\\n",
              " 0   www.markets.fallondpicks.com   \n",
              " 1              www.zerohedge.com   \n",
              " 2              www.zerohedge.com   \n",
              " 3              www.zerohedge.com   \n",
              " 4              www.zerohedge.com   \n",
              " ..                           ...   \n",
              " 85       traderfeed.blogspot.com   \n",
              " 86       traderfeed.blogspot.com   \n",
              " 87       traderfeed.blogspot.com   \n",
              " 88       traderfeed.blogspot.com   \n",
              " 89           www.marketfolly.com   \n",
              " \n",
              "                                                  Link  \n",
              " 0   https://www.markets.fallondpicks.com/2023/01/n...  \n",
              " 1   https://www.zerohedge.com/markets/adani-publis...  \n",
              " 2   https://www.zerohedge.com/political/we-will-ro...  \n",
              " 3   https://www.zerohedge.com/political/inexperien...  \n",
              " 4   https://www.zerohedge.com/political/taibbi-shr...  \n",
              " ..                                                ...  \n",
              " 85  http://traderfeed.blogspot.com/2022/12/your-me...  \n",
              " 86  http://traderfeed.blogspot.com/2022/12/the-thr...  \n",
              " 87  http://traderfeed.blogspot.com/2022/11/trading...  \n",
              " 88  http://traderfeed.blogspot.com/2022/11/relapse...  \n",
              " 89  http://www.marketfolly.com/2022/05/new-issue-n...  \n",
              " \n",
              " [90 rows x 4 columns]}"
            ]
          },
          "execution_count": 674,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from finvizfinance.news import News\n",
        "fnews = News()\n",
        "all_news = fnews.get_news()\n",
        "all_news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 675,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current url is: https://finviz.com/quote.ashx?t=AAPL\n",
            "\n",
            "\n",
            "Recent News Headlines for AAPL: \n",
            "Why This May Be A 'Life Changing' Market Rally; Apple, Fed Meeting Loom As Tesla Run Hits 75% ( Jan-29-23 04:04PM )\n",
            "Could Big Tech layoffs keep growing? Apple, Amazon, Facebook and Google may give hints in biggest week of earnings ( 03:01PM )\n",
            "15 Most Famous Hedge Fund Managers and Their Top Stock Picks ( 02:35PM )\n"
          ]
        }
      ],
      "source": [
        "# Get Data\n",
        "finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
        "news_tables = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    url = finwiz_url + ticker\n",
        "    print(\"current url is: \" +url)\n",
        "    header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36.\"}\n",
        "    req = Request(url=url,headers=header) \n",
        "    resp = urlopen(req)    \n",
        "    html = BeautifulSoup(resp, features=\"lxml\")\n",
        "    news_table = html.find(id='news-table')\n",
        "    news_tables[ticker] = news_table\n",
        "\n",
        "try:\n",
        "    for ticker in tickers:\n",
        "        df = news_tables[ticker]\n",
        "        df_tr = df.findAll('tr')\n",
        "    \n",
        "        print ('\\n')\n",
        "        print ('Recent News Headlines for {}: '.format(ticker))\n",
        "        \n",
        "        for i, table_row in enumerate(df_tr):\n",
        "            a_text = table_row.a.text\n",
        "            td_text = table_row.td.text\n",
        "            td_text = td_text.strip()\n",
        "            print(a_text,'(',td_text,')')\n",
        "            if i == n-1:\n",
        "                break\n",
        "except KeyError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 676,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jan-29-23 04:04PMWhy This May Be A 'Life Changing' Market Rally; Apple, Fed Meeting Loom As Tesla Run Hits 75% Investor's Business Daily\n",
            "03:01PMCould Big Tech layoffs keep growing? Apple, Amazon, Facebook and Google may give hints in biggest week of earnings MarketWatch\n",
            "02:35PM15 Most Famous Hedge Fund Managers and Their Top Stock Picks Insider Monkey\n",
            "10:30AMTarget, Amazon and 4 More Retailers That Will Reward You for Turning in Your Old Stuff GOBankingRates\n",
            "07:53AMFed meeting, jobs data, Apple earnings: What to know this week Yahoo Finance\n",
            "\n",
            "07:00AM\n",
            "Loading…\n",
            "\n",
            "07:00AM$50 AirPods Pro? Nope. Heres How to Spot Fake Apple Earbuds. The Wall Street Journal\n",
            "06:00AMApple (NASDAQ:AAPL) stock performs better than its underlying earnings growth over last five years Simply Wall St.\n",
            "05:45AM5 Top Stocks for February Motley Fool\n",
            "01:09AMChina's 2022 smartphone shipments the lowest in 10 years - research firm Reuters\n",
            "01:00AMChina's 2022 smartphone shipments the lowest in 10 years - research firm Reuters\n",
            "Jan-28-23 10:00AMHow to Build Great Wealth With the Power of Compounding TheStreet.com\n",
            "08:26AMAmazon, Apple, Alphabet Headline Another Busy Earnings Week The Wall Street Journal\n",
            "Jan-27-23 06:34PMWeekly Roundup TheStreet.com\n",
            "06:20PMStock Market Investing Action Plan  January Wrap: Apple, OPEC, Exxon And The Fed Investor's Business Daily\n",
            "05:05PMTech earnings, Fed decision, economic data expected out next week Yahoo Finance Video\n",
            "\n",
            "04:48PM\n",
            "Loading…\n",
            "\n",
            "04:48PMApple Takes The Cake Again In China As Top Smartphone Seller Amid Odds Benzinga\n",
            "04:18PMBig Tech Earnings Are Almost Here. Microsoft Has Investors on Edge. Barrons.com\n",
            "04:10PMApple Stock Climbs Wall Of Worry Ahead Of Earnings Report Investor's Business Daily\n",
            "02:42PMGoldman Sachs David Solomon latest CEO hit with pay cut Fox Business\n",
            "01:31PMPutting Chevrons $75 Billion Stock Buyback in Context Investopedia\n",
            "11:47AMApple, ServiceNow avoid job cuts amid mass tech layoffs Yahoo Finance Video\n",
            "11:11AMApple developing software to help users build apps for upcoming headset - The Information Reuters\n",
            "10:35AMApple Q1 earnings: 3 things to watch for Yahoo Finance Video\n",
            "10:13AMApple Stock Climbs Off Lows As Earnings Optimism Builds: 3 Other FAANG Stocks Dominate Earnings Calendar Investor's Business Daily\n",
            "10:11AMDow Jones Reverses After Inflation Data; Intel Plunges 10% On Earnings Investor's Business Daily\n",
            "10:05AMiPhone Sales, Zuckerbergs Metaverse Bet, Spotify Pricing: Earnings to Watch Bloomberg\n",
            "09:36AMDow Jones Falls After Inflation Data; Intel Plunges 10% On Earnings Investor's Business Daily\n",
            "09:18AMDow Jones Futures Dip After Inflation Data; Intel Plunges On Earnings Investor's Business Daily\n",
            "09:02AM67.65% of Warren Buffett's Berkshire Hathaway Portfolio is in These 4 Stocks Motley Fool\n",
            "08:36AMBig Tech got the pandemic wrong but one company emerged on top Financial Times\n",
            "\n",
            "08:20AM\n",
            "Loading…\n",
            "\n",
            "08:20AMDow Jones Futures Dip Ahead Of Inflation Data; Intel Plunges On Earnings Investor's Business Daily\n",
            "06:10AMGot $1,000? 5 Buffett Stocks to Buy in 2023 and Hold Forever Motley Fool\n",
            "05:52AM4 FAANG Stocks Wall Street Thinks Will Be Big Winners in 2023 -- and 1 Analysts Aren't So Bullish About Motley Fool\n",
            "05:06AM80% of Warren Buffett's Portfolio Is Invested in These 7 Stocks Motley Fool\n",
            "04:00AMApples iPhone Dominated China Last Quarter Despite Disruptions Bloomberg\n",
            "Jan-26-23 03:53PMApple Earnings Preview: Time to Buy AAPL Stock? Zacks\n",
            "03:51PMApple iPhone shipments declined almost 15% year-over-year in 2022 Yahoo Finance Video\n",
            "02:44PMUPDATE 1-U.S. lawsuit against Google could benefit Apple and others Reuters\n",
            "12:25PMApple Avoids Layoffs Hitting the Rest of Tech, for Now WSJ\n",
            "12:09PMU.S. lawsuit against Google could benefit Apple and others Reuters\n",
            "12:04PMU.S. lawsuit against Google could benefit Apple and others Reuters\n",
            "10:01AMEarnings Preview: Apple (AAPL) Q1 Earnings Expected to Decline Zacks\n",
            "09:36AM30 of the Worlds Most Valuable Private Companies Insider Monkey\n",
            "09:00AMDoes This VR News Make Apple Stock a Buy for 2023? Motley Fool\n",
            "08:06AMIf Cash Is King, These Nasdaq Stocks Reign Supreme Motley Fool\n",
            "07:35AMSmartphones: better kit could depress long-term growth Financial Times\n",
            "06:07AM1 Growth Stock Down 15% to Buy Right Now Motley Fool\n",
            "05:17AM2 Warren Buffett Stocks That Could Crush the Market in 2023 Motley Fool\n",
            "01:45AMApple couldnt save the smartphone industry from its worst year since 2013 MarketWatch\n",
            "Jan-25-23 10:53PMGlobal Phone Shipments Plunge Most Ever as Consumers Spend Less Bloomberg\n",
            "10:45AMHere Are 2 Technology Stocks of the Future You Can Buy Today Motley Fool\n",
            "10:02AMDow Jones Falls 325 Points As Boeing, Microsoft Drop On Earnings; Tesla Skids Ahead Of Earnings Investor's Business Daily\n",
            "09:53AMDow Jones Falls 300 Points As Boeing, Microsoft Drop On Earnings; Tesla Skids Ahead Of Earnings Investor's Business Daily\n",
            "09:45AMBig Techs Job Cuts Spur Rallies Even as an Economic Slowdown Looms Bloomberg\n",
            "09:19AMDow Jones Futures Fall 300 Points As Boeing, Microsoft Drop On Earnings; Tesla Earnings Due Investor's Business Daily\n",
            "09:00AMA Look At The Intrinsic Value Of Apple Inc. (NASDAQ:AAPL) Simply Wall St.\n",
            "08:59AMWhy Streaming Services Win, No Matter Who Wins an Oscar Barrons.com\n",
            "08:57AMDow Jones Futures Fall 280 Points As Boeing, Microsoft Drop On Earnings; Tesla Earnings Due Investor's Business Daily\n",
            "08:35AMDow Jones Futures Fall 250 Points As Boeing, Microsoft Drop On Earnings; Tesla Earnings Due Investor's Business Daily\n",
            "08:30AMDow Jones Futures Fall 200 Points As Boeing, Microsoft Drop On Earnings; Tesla Earnings Due Investor's Business Daily\n",
            "07:05AMApple Expands Base In South East Asia To Reduce Dependence On China Benzinga\n",
            "06:30AMApple's Chip Strategy Is Great News for Shareholders, Bad News for Skyworks, Broadcom, and Qualcomm Motley Fool\n",
            "06:27AMBetter Buy: Apple Stock vs. Netflix Stock Motley Fool\n",
            "05:16AM3 No-Brainer Warren Buffett Stocks to Buy Right Now Motley Fool\n",
            "05:07AMBetter Buy in 2023: Apple Stock vs. Disney Stock Motley Fool\n",
            "12:00AMApple beefs up smartphone services in silent war against Google Financial Times\n",
            "Jan-24-23 10:19PMDeconstructing General Electric With Author William D. Cohan Motley Fool\n",
            "06:38PMApple Begins Hiring for Effort to Bring Retail Chain to Malaysia Bloomberg\n",
            "05:45PMApple (AAPL) Gains As Market Dips: What You Should Know Zacks\n",
            "04:22PMThe Oscar Nominees Are In. Why Streaming Services Win No Matter What. Barrons.com\n",
            "01:44PM2 No-Brainer Growth Stocks to Buy in 2023 Motley Fool\n",
            "01:31PMApple Could Be Headed for Down Sales Year in Fiscal 2023, Bernstein Analyst Contends Barrons.com\n",
            "01:05PMGoogle CEO Sundar Pichai says he will take less pay this year as he joins JPMorgans Jamie Dimon and Apples Tim Cook in taking a compensation hit Fortune\n",
            "11:01AMApple builds on privacy commitment by unveiling new education and awareness efforts on Data Privacy Day Business Wire\n",
            "11:00AMApple debuts programs highlighting data privacy and security Yahoo Finance\n",
            "11:00AMApple debuts new programs highlighting data privacy and security Yahoo Finance\n",
            "11:00AMWhat's in Store for Big Tech ETFs in Q4 Earnings? Zacks\n",
            "10:30AMIs Taiwan Semiconductor Manufacturing a Buy? Motley Fool\n",
            "09:40AMThe Zacks Analyst Blog Highlights Apple, Alphabet, NVIDIA, Microsoft and Meta Platforms Zacks\n",
            "09:36AMChatGPT Is Doing for AI What Apple's iPhone Did for Smartphones Benzinga\n",
            "09:22AM5G Stocks To Buy And Watch As Cloud Computing Plays Bigger Role Investor's Business Daily\n",
            "09:18AMTrump Beefs Up Defamation War Against New York Prosecutor, Apple Weighs Content Deals With Disney, Likely Lawsuit On Google For Influencing Online Ad Market: Today's Top Stories Benzinga\n",
            "09:10AMWill Meta Platforms Be a Trillion-Dollar Stock by 2030? Motley Fool\n",
            "09:00AMHow to Boost Your Portfolio with Top Computer and Technology Stocks Set to Beat Earnings Zacks\n",
            "07:21AMDow Jones Rallies 250 Points; What To Do Now; 10 Best Stocks To Buy And Watch Now Investor's Business Daily\n",
            "07:02AMApple Weighs Content Deals With Disney, Other Partners For VR Headset Benzinga\n",
            "07:00AM1 Warren Buffett Stock to Buy in 2023 and Hold Forever Motley Fool\n",
            "04:39AMApple Aims for About 25% of Production in India, Minister Says Bloomberg\n",
            "Jan-23-23 09:21PMBig Tech Layoffs; Signs of Trouble in the Housing Market Motley Fool\n",
            "05:18PM25 Largest Privately Held Companies in America Insider Monkey\n",
            "04:09PMApple reportedly to debut new line of VR headsets Yahoo Finance Video\n",
            "03:10PMWhy Apple Stock Was Climbing Today Motley Fool\n",
            "02:48PMApple in talks with Disney, others on VR content for new headset - Bloomberg News Reuters\n",
            "01:50PMThe big banks want to take on PayPal in e-commerce, but thats harder than it seems MarketWatch\n",
            "01:27PMHow Apples Upcoming Mixed-Reality Headset Will Work Bloomberg\n",
            "12:29PMApple, Disney, Salesforce: Why are the worlds best companies failing to innovate on the future of work? Fortune\n",
            "12:15PMBig Banks Are Coming After PayPal and Apple With Digital Wallet: WSJ Barrons.com\n",
            "12:10PMWhy Apple (AAPL) is Poised to Beat Earnings Estimates Again Zacks\n",
            "12:00PMStock Market Recovery: These 4 Stocks Have Been on the Rise in 2023 Motley Fool\n",
            "11:01AMWhy Buying This FAANG Stock Could Be a Genius Move Motley Fool\n"
          ]
        }
      ],
      "source": [
        "# Iterate through the news\n",
        "parsed_news = []\n",
        "for file_name, news_table in news_tables.items():\n",
        "    for x in news_table.findAll('tr'):\n",
        "        print(x.get_text())\n",
        "        text = x.get_text() \n",
        "        date_scrape = x.td.text.split()\n",
        "\n",
        "        if len(date_scrape) == 1:\n",
        "            time = date_scrape[0]\n",
        "            \n",
        "        else:\n",
        "            date = date_scrape[0]\n",
        "            time = date_scrape[1]\n",
        "\n",
        "        ticker = file_name.split('_')[0]\n",
        "        \n",
        "        parsed_news.append([ticker, date, time, text ])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathering Data From AlphaAdvantage for Historical News #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 677,
      "metadata": {},
      "outputs": [],
      "source": [
        "from decouple import config\n",
        "import requests\n",
        "import urllib.parse\n",
        "import json\n",
        "import datetime\n",
        "AAapikey = config('AAKey')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 678,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to convert user provided date to date required by AlphaAdvantage\n",
        "def toAADate(oldDate):\n",
        "    newDate = oldDate.strftime(\"%Y%m%dT0130\")\n",
        "    return str(newDate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 679,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "endDate is: 2023-01-28\n",
            "startDate is: 2022-11-29\n",
            "startDate is: 20221129T0130\n",
            "endDate is: 20230128T0130\n",
            "           Date                                           Headline Ticker\n",
            "0    2022-11-29   Asia shares take comfort in China property rally   AAPL\n",
            "1    2022-11-29  Asia shares take comfort in China property ral...   AAPL\n",
            "2    2022-11-29  Global markets: Asia shares take comfort in Ch...   AAPL\n",
            "3    2022-11-29  App Store Awards Celebrate the Best Apps and G...   AAPL\n",
            "4    2022-11-29  iPhone 15 Might Push HD Photography To New Hei...   AAPL\n",
            "..          ...                                                ...    ...\n",
            "195  2022-12-05  Foxconn says it's restoring production at the ...   AAPL\n",
            "196  2022-12-05  The 3 Most Popular Robinhood Stocks Right Now:...   AAPL\n",
            "197  2022-12-05  US Stocks Start New Trading Week On Negative N...   AAPL\n",
            "198  2022-12-05  Apple In A Rush To Diversify iPhone Production...   AAPL\n",
            "199  2022-12-05  Should SPDR S&P 500 ETF  ( SPY )  Be on Your I...   AAPL\n",
            "\n",
            "[200 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Get data from AlphaAdvantage for one ticker for a particular day\n",
        "def getHistoricNewsData(ticker, endDate = datetime.date.today() - datetime.timedelta(days = 1) , interval = '1mo'):\n",
        "    url = 'https://www.alphavantage.co/query?'\n",
        "    print(\"endDate is: \" +str(endDate))\n",
        "    if interval == '1mo':\n",
        "        days_to_add = 30\n",
        "    else:\n",
        "        days_to_add = 60\n",
        "    delta_days = datetime.timedelta(days = days_to_add)\n",
        "    startDate = endDate - delta_days\n",
        "    print(\"startDate is: \" +str(startDate))\n",
        "    if startDate and endDate:\n",
        "        startDate = toAADate(startDate)\n",
        "        endDate = toAADate(endDate)\n",
        "        print(\"startDate is: \" +str(startDate))\n",
        "        print(\"endDate is: \" +str(endDate))\n",
        "        Myparams = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'time_from': startDate, 'time_to': endDate, 'sort': 'EARLIEST','limit': 200, 'apikey': AAapikey}\n",
        "    else:\n",
        "        print(\"NEED DATES\")\n",
        "        #Myparams = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'sort': 'LATEST','limit': 100, 'apikey': AAapikey}\n",
        "    r = requests.get(url, params = Myparams)\n",
        "    data = r.json()\n",
        "    #return data\n",
        "    historic_news = pd.DataFrame(columns=['Date', 'Headline', 'Ticker'])\n",
        "    for i in data.get(\"feed\"):\n",
        "        test_date = i.get(\"time_published\")\n",
        "        test_date = test_date[:8]\n",
        "        newDate = datetime.datetime.strptime(test_date, '%Y%m%d').date()\n",
        "        row = [newDate, i.get(\"title\"), ticker]\n",
        "        new_df = pd.DataFrame([row],columns=['Date', 'Headline', 'Ticker'])\n",
        "        historic_news = pd.concat([historic_news, new_df], axis=0, ignore_index=True)\n",
        "    return historic_news\n",
        "\n",
        "#historic_news = getHistoricNewsData('AAPL', '2022-10-10', '2mo')\n",
        "historic_news = getHistoricNewsData('AAPL', interval = '2mo')\n",
        "print(historic_news)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis of News data #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 682,
      "metadata": {},
      "outputs": [],
      "source": [
        "def SentimentAnalysisNewsData(parsedNews, printOut = False):\n",
        "    #Downloading Vader Lexicon for Sentiment Analysis\n",
        "    nltk.download('vader_lexicon')\n",
        "    # Initializing Sentiment Analysis\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    #Declaring Column Names\n",
        "    columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
        "    #Creating dataframe from news\n",
        "    news = pd.DataFrame(parsedNews, columns=columns)\n",
        "    #Getting scores for headlines\n",
        "    scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
        "\n",
        "    #Creating Dataframe of Scores\n",
        "    df_scores = pd.DataFrame(scores)\n",
        "    #Joining scores to news dataframe\n",
        "    news = news.join(df_scores, rsuffix='_right')\n",
        "    #Converting Date column to pd datetime date\n",
        "    news['Date'] = pd.to_datetime(news.Date).dt.date\n",
        "\n",
        "    #List of unique tickers\n",
        "    unique_ticker = news['Ticker'].unique().tolist()\n",
        "    #Creating dict for news based on ticker\n",
        "    news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}\n",
        "    #Initializing List of values\n",
        "    values = []\n",
        "    for ticker in tickers: \n",
        "        dataframe = news_dict[ticker]\n",
        "        dataframe = dataframe.set_index('Ticker')\n",
        "        #Dropping headlines column since we only need scores now\n",
        "        dataframe = dataframe.drop(columns = ['Headline'])\n",
        "        #if printOut:\n",
        "            #print ('\\n')\n",
        "            #print (dataframe.head())\n",
        "        \n",
        "        #mean = round(dataframe['compound'].mean(), 2)\n",
        "        #Finding compound number for news of every day\n",
        "        mean = round(dataframe.groupby('Date')['compound'].mean(), 2)\n",
        "        #Adding values to values list\n",
        "        values.append(mean)\n",
        "    \n",
        "   \n",
        "    #print(round(dataframe.groupby('Date')['compound'].mean(), 2))\n",
        "    print(\"VALUES------------\")\n",
        "    print(values)\n",
        "        \n",
        "    #Combining tickers and values into new dataframe\n",
        "    #df = pd.DataFrame(list(zip(tickers, values)), columns =['Ticker', 'Mean Sentiment']) \n",
        "    #df = df.set_index('Ticker')\n",
        "    #df = df.sort_values('date', ascending=False)\n",
        "    if printOut:\n",
        "        print(\"-----------DF\")\n",
        "        print(df.head())\n",
        "        print(df.shape)\n",
        "    #Returning the dataframe\n",
        "    return df\n",
        "    #if printOut:\n",
        "        #print ('\\n')\n",
        "        #display (df)\n",
        "    #return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 681,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VALUES------------\n",
            "[Date\n",
            "2022-11-29    0.16\n",
            "2022-11-30    0.03\n",
            "2022-12-01    0.04\n",
            "2022-12-02    0.12\n",
            "2022-12-03   -0.06\n",
            "2022-12-04   -0.03\n",
            "2022-12-05   -0.02\n",
            "Name: compound, dtype: float64]\n",
            "-----------DF\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\Ishaan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [681], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#print(\"HISTORIC SENTIMENT\")\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m HistoricSentiment \u001b[39m=\u001b[39m SentimentAnalysisNewsData(historic_news, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      3\u001b[0m \u001b[39m#print(\"\\n\")\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#print(\"TODAYS SENTIMENT\")\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m#TodaysSentiment = SentimentAnalysisNewsData(parsed_news)\u001b[39;00m\n",
            "Cell \u001b[1;32mIn [680], line 40\u001b[0m, in \u001b[0;36mSentimentAnalysisNewsData\u001b[1;34m(parsedNews, printOut)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mif\u001b[39;00m printOut:\n\u001b[0;32m     39\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-----------DF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39;49mhead())\n\u001b[0;32m     41\u001b[0m     \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
            "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ],
      "source": [
        "#print(\"HISTORIC SENTIMENT\")\n",
        "HistoricSentiment = SentimentAnalysisNewsData(historic_news, True)\n",
        "#print(\"\\n\")\n",
        "#print(\"TODAYS SENTIMENT\")\n",
        "#TodaysSentiment = SentimentAnalysisNewsData(parsed_news)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating Dataset #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dataset for $AAPL\n",
            "Getting stock data for stock $AAPL\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "                  Open        High         Low       Close   Adj Close  \\\n",
            "Date                                                                     \n",
            "2023-01-25  140.889999  142.429993  138.809998  141.860001  141.860001   \n",
            "2023-01-26  143.169998  144.250000  141.899994  143.960007  143.960007   \n",
            "\n",
            "              Volume  \n",
            "Date                  \n",
            "2023-01-25  65799300  \n",
            "2023-01-26  54003800  \n",
            "endDate is: 2023-01-25\n",
            "startDate is: 2022-11-26\n",
            "startDate is: 20221126T0130\n",
            "endDate is: 20230125T0130\n",
            "           Date                                           Headline Ticker\n",
            "0    2022-11-26  10 exchange-traded funds to take exposure in U...   AAPL\n",
            "1    2022-11-26  Market Rally Strong, But Here's Why You Should...   AAPL\n",
            "2    2022-11-26  Motley Fool Investors Look Back at 2022 and Fo...   AAPL\n",
            "3    2022-11-26  Black Friday Online Sales Hit Record, But Grow...   AAPL\n",
            "4    2022-11-26  Manchester United Stock Spikes Higher On Repor...   AAPL\n",
            "..          ...                                                ...    ...\n",
            "195  2022-12-01  Futures: Inflation Data Due After S&P 500 Surg...   AAPL\n",
            "196  2022-12-01  Tesla Bull Says Time For Tim Cook To Step Down...   AAPL\n",
            "197  2022-12-01  Worried About a Bear Market? 1 Unstoppable ETF...   AAPL\n",
            "198  2022-12-01  Why Apple Stock Can Keep Delivering for Investors   AAPL\n",
            "199  2022-12-01  Futures flat after strong Wall Street rally; S...   AAPL\n",
            "\n",
            "[200 rows x 3 columns]\n",
            "(1, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\Ishaan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "def createDataset(date_from, int):\n",
        "    for i in tickers:\n",
        "        print(\"Creating dataset for $\" +i)\n",
        "        #Get historic stock data\n",
        "        historic_stock = getMonthlyStockData(i, interval = int)\n",
        "        print(historic_stock.head())\n",
        "        #Get historic news data\n",
        "        historic_news = getHistoricNewsData(i, interval = int)\n",
        "        print(historic_news)\n",
        "        #Use news to get sentiment\n",
        "        HistoricSentiment = SentimentAnalysisNewsData(historic_news)\n",
        "        print(HistoricSentiment.shape)\n",
        "        #Merge as training set\n",
        "        #Get today's stock data\n",
        "        #Get today's news data\n",
        "        #Use news to get sentiment\n",
        "\n",
        "\n",
        "createDataset('2022-10-10', '2mo')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO2ChGGwJkijmmb0vDcCR40",
      "include_colab_link": true,
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
